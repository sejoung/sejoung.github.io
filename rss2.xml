<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>폭간의 기술블로그</title>
    <link>https://sejoung.github.io/</link>
    <atom:link href="/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description>잘정리하자</description>
    <pubDate>Thu, 02 May 2024 02:47:11 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>Part 3 이론</title>
      <link>https://sejoung.github.io/2024/05/2024-05-02-tidy_first_PART3/</link>
      <guid>https://sejoung.github.io/2024/05/2024-05-02-tidy_first_PART3/</guid>
      <pubDate>Thu, 02 May 2024 00:55:00 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;Part-3-이론&quot;&gt;&lt;a href=&quot;#Part-3-이론&quot; class=&quot;headerlink&quot; title=&quot;Part 3 이론&quot;&gt;&lt;/a&gt;Part 3 이론&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;언제 소프트웨어 설계 결정을 시작해야 하는가?&lt;/li&gt;
&lt;li&gt;언
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Part-3-이론"><a href="#Part-3-이론" class="headerlink" title="Part 3 이론"></a>Part 3 이론</h1><ul><li>언제 소프트웨어 설계 결정을 시작해야 하는가?</li><li>언제 소프트웨어 걸계 결정을 중단하고 시스템의 동작을 변경해야 하는가?</li><li>다음 결정은 어떻게 내릴것인가?</li></ul><h2 id="Chapter-22-요소들을-유익하게-관계-맺는-일"><a href="#Chapter-22-요소들을-유익하게-관계-맺는-일" class="headerlink" title="Chapter 22 요소들을 유익하게 관계 맺는 일"></a>Chapter 22 요소들을 유익하게 관계 맺는 일</h2><ul><li>소프트웨어 설계는 인간관계 속에서 벌어지는 활동</li><li>요소<ul><li>요소에는 경계가 있다</li><li>계층 구조</li></ul></li><li>관계 맺기<ul><li>호출하고&#x2F;호출받는 관계</li><li>호출</li><li>발행</li><li>대기</li><li>참조</li></ul></li><li>유익하게<ul><li>시스템에는 필요하지만 기계를 위한 명령어가 아닌 일종의 중간 요소를 만들면 그 중간 요소들이 서로에게 도움이 되기 시작</li></ul></li><li>요소들을 유익하게 관계 맺는 일<ul><li>설계란? 구성하는 요소들과 그들의 관계 그리고 그 관계에서 파생되는 이점이 바로 설계</li></ul></li><li>시스템 구조<ul><li>요소 계층 구조</li><li>요소 사이의 관계</li><li>이러한 관계가 만들어내는 이점</li></ul></li></ul><h2 id="Chapter-23-구조와-동작"><a href="#Chapter-23-구조와-동작" class="headerlink" title="Chapter 23 구조와 동작"></a>Chapter 23 구조와 동작</h2><ul><li>소프트웨어의 가치를 만드는 두가지 방식<ul><li>현재 소프트웨어가 하는 일</li><li>미래에 새로운 일을 시킬수 있는 가능성</li></ul></li><li>동작을 규정하는 방식<ul><li>입출력 쌍</li><li>불변 조건</li></ul></li><li>동작은 가치를 만든다</li><li>더나은 기계에 도달하는 방법<ul><li>선택 가능성 (옵션)</li></ul></li><li>옵션의 멋진점<ul><li>환경의 변동성이 클수록 옵션의 가치가 더 커진다</li></ul></li><li>선택 가능성을 앗아가는 요소?<ul><li>핵심 직원의 퇴사</li><li>고객과 거리가 멀어진다</li><li>변경에 따른 비용이 치솟는다</li></ul></li><li>구조 변경과 동작 변경은 모두 가치를 만들어낸다</li><li>동작의 문제는 바로 드러나지만 구조의 문제는 잘 드러나지 않는다</li><li>동작 변경과 구조 변경의 차이점 가역성</li></ul><h2 id="Chapter-24-경제-이론-시간-가치와-선택-가능성"><a href="#Chapter-24-경제-이론-시간-가치와-선택-가능성" class="headerlink" title="Chapter 24 경제 이론: 시간 가치와 선택 가능성"></a>Chapter 24 경제 이론: 시간 가치와 선택 가능성</h2><ul><li><p>돈의 본성</p><ul><li>오늘의 1달러가 내일의 1달러보다 더 가치가 있기 때문에 버는 것은 빨리하고 쓰는 것은 가능한 뒤로 미룬다</li><li>혼란스러운 상황에서는 어떤 물건에 대한 옵션이 물건 자체보다 낫기 때문에 불확실성에 맞서는 옵션을 만든다</li></ul></li><li><p>순현재 가치(Net present value)</p></li><li><p>옵션 그릭스(option greeks)</p></li></ul><h2 id="Chapter-25-오늘의-1달러가-내일의-1달러보다-크다"><a href="#Chapter-25-오늘의-1달러가-내일의-1달러보다-크다" class="headerlink" title="Chapter 25 오늘의 1달러가 내일의 1달러보다 크다"></a>Chapter 25 오늘의 1달러가 내일의 1달러보다 크다</h2><ul><li>많고 적음의 의미? 돈에 대해선 아래의 두가지에 달림<ul><li>시점</li><li>확실성</li></ul></li><li>돈의 시간 가치는 코드 정리를 먼저 하기보다는 나중에 하는것을 권장</li></ul><h2 id="Chapter-26-옵션"><a href="#Chapter-26-옵션" class="headerlink" title="Chapter 26 옵션"></a>Chapter 26 옵션</h2><ul><li>옵션은 선택 가능성을 뜻한다</li><li>가치에 대한 예측이 불확실할수록 바로 구현하는 것보다 옵션이 지닌 가치가 더 커진다</li></ul><h2 id="Chapter-27-옵션과-현금흐름-비교"><a href="#Chapter-27-옵션과-현금흐름-비교" class="headerlink" title="Chapter 27 옵션과 현금흐름 비교"></a>Chapter 27 옵션과 현금흐름 비교</h2><ul><li>비용(코드정리) + 비용(코드 정리 후 동작 변경) &lt; 비용(바로 동작 변경)</li><li>자기 관리로서의 코드 정리는 어느정도 정당화 될수 있다</li></ul><h2 id="Chapter-28-되돌릴-수-있는-구조-변경"><a href="#Chapter-28-되돌릴-수-있는-구조-변경" class="headerlink" title="Chapter 28 되돌릴 수 있는 구조 변경"></a>Chapter 28 되돌릴 수 있는 구조 변경</h2><ul><li>구조 변경은 대체로 되돌리수 있다</li><li>동작 변경은 되돌리기 어렵다</li><li>결정을 되돌릴수 있게 만드는것이 중요하다</li></ul><h2 id="Chapter-29-결합도"><a href="#Chapter-29-결합도" class="headerlink" title="Chapter 29 결합도"></a>Chapter 29 결합도</h2><ul><li>변경 감염 특성을 결합도라고 한다<ul><li>한 요소를 변경하면 다른 요소도 함께 변경해야 하는 경우 두 요소는 특정 변경과 관련하여 서로 결합되어 있는것</li></ul></li><li>결합도 분석은 단순히 소스코드를 보는것만으로 부족<ul><li>하나의 커밋에서 어떤 파일이 쌍으로 나타나는 경향확인</li></ul></li><li>경합도(종속성)의 두가지 성질<ul><li>일대다</li><li>연쇄작용</li></ul></li><li>결합도는 소프트웨어 비용을 좌우한다</li></ul><h2 id="Chapter-30-콘스탄틴의-등가성"><a href="#Chapter-30-콘스탄틴의-등가성" class="headerlink" title="Chapter 30 콘스탄틴의 등가성"></a>Chapter 30 콘스탄틴의 등가성</h2><ul><li>소프트웨어 개발 비용의 70%가 유지보수에 들어간다</li><li>시스템의 가치는 어제의 추측이 아닌 오늘의 현실에서 드러난다</li><li>콘스탄틴의 등가성</li></ul><h2 id="Chapter-31-결합도와-결합도-제거"><a href="#Chapter-31-결합도와-결합도-제거" class="headerlink" title="Chapter 31 결합도와 결합도 제거"></a>Chapter 31 결합도와 결합도 제거</h2><ul><li>결합도는 잘 보이지 않는다</li><li>동작 변경하려다가 알아차린다</li><li>결합도가 있어야 하는 이유<ul><li>방금전 까지 문제가 되지 않았다</li></ul></li><li>한 종류의 코드 변경에 대한 결합도를 줄일수록 다른 종류의 코드 변경에 대한 결합도가 커진다</li></ul><h2 id="Chapter-32-응집도"><a href="#Chapter-32-응집도" class="headerlink" title="Chapter 32 응집도"></a>Chapter 32 응집도</h2><ul><li>결합된 요소들은 둘을 포함하는 같은 요소의 하위 요소여야 한다</li><li>결합되지 않은 요소는 이 더미가 아닌 다른 곳으로 이동해야 된다</li></ul><h2 id="Chapter-33-결론"><a href="#Chapter-33-결론" class="headerlink" title="Chapter 33 결론"></a>Chapter 33 결론</h2><ul><li>비용</li><li>수익</li><li>결합도</li><li>응집도</li></ul><h1 id="참조"><a href="#참조" class="headerlink" title="참조"></a>참조</h1><hr><ul><li><a href="https://www.yes24.com/Product/Goods/125921718">Tidy First?</a></li></ul>]]></content:encoded>
      
      <comments>https://sejoung.github.io/2024/05/2024-05-02-tidy_first_PART3/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Part 2 관리</title>
      <link>https://sejoung.github.io/2024/04/2024-04-29-tidy_first_PART2/</link>
      <guid>https://sejoung.github.io/2024/04/2024-04-29-tidy_first_PART2/</guid>
      <pubDate>Mon, 29 Apr 2024 01:17:00 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;Part-2-관리&quot;&gt;&lt;a href=&quot;#Part-2-관리&quot; class=&quot;headerlink&quot; title=&quot;Part 2 관리&quot;&gt;&lt;/a&gt;Part 2 관리&lt;/h1&gt;&lt;h2 id=&quot;Chapter-16-코드-정리-구분&quot;&gt;&lt;a href=&quot;#Chapte
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Part-2-관리"><a href="#Part-2-관리" class="headerlink" title="Part 2 관리"></a>Part 2 관리</h1><h2 id="Chapter-16-코드-정리-구분"><a href="#Chapter-16-코드-정리-구분" class="headerlink" title="Chapter 16 코드 정리 구분"></a>Chapter 16 코드 정리 구분</h2><ul><li>다양한 변경 필요성을 구분하지 않은 상태에서 변경 시도</li><li>동작 변경과 구조 변경</li><li>순서를 부여한 동작 변경과 구조 변경</li><li>별도의 pr 포함된 동작 변경과 구조 변경</li></ul><h2 id="Chapter-17-연쇄적인-정리"><a href="#Chapter-17-연쇄적인-정리" class="headerlink" title="Chapter 17 연쇄적인 정리"></a>Chapter 17 연쇄적인 정리</h2><ul><li>보호 구분<ul><li>보호 구분을 통해 코드 정리를 진행하면 조건이 설명하는 도우미로 드러나거나 설명하는 변수 추출을 돕는 혜택을 얻는다</li></ul></li><li>안 쓰는 코드<ul><li>코드를 읽는 순서에 맞춰 정렬하는 방법과 응집도를 높이는 배치가 보인다</li></ul></li><li>대칭으로 맞추기<ul><li>대칭으로 맞추면 매우 유사한 코드들이 묶여진 순서대로 읽을수 있다</li></ul></li><li>새로운 인터페이스로 기존 루틴 부르기<ul><li>하나를 정리하면 한 다발의 정리가 이러지고 뒤이어 각각의 정리가 또 다발로 이어짐</li></ul></li><li>읽는 순서<ul><li>읽는 순서를 정리하면 대칭으로 맞출 기회가 생김</li></ul></li><li>응집도를 높이는 배치<ul><li>응집도를 높이는 배치로 함께 묶인 요소는 하위 요소로 추출할 후보가 된다</li></ul></li><li>설명하는 변수<ul><li>할당하는 문장에서 좌변이 설명하는 변수라면 그에 대응하는 우변은 설명하는 도우미 후보</li></ul></li><li>설명하는 상수<ul><li>설명하는 상수 정리는 응집도를 높이는 배치를 이끔</li></ul></li><li>명시적인 매개변수<ul><li>매개변수 집합을 묶어 객체로 만들고 코드를 옴길 수 있다</li></ul></li><li>비슷한 코드끼리</li><li>도우미 추출</li><li>하나의 더미</li><li>설명하는 주석</li><li>불필요한 주석 지우기</li></ul><h2 id="Chapter-18-코드-정리의-일괄-처리량"><a href="#Chapter-18-코드-정리의-일괄-처리량" class="headerlink" title="Chapter 18 코드 정리의 일괄 처리량"></a>Chapter 18 코드 정리의 일괄 처리량</h2><ul><li>골디락스 딜레마(타협점을 찾아야 된다)</li><li>충돌<ul><li>일괄 처리하는 코드 정리 작업이 많을수록 통합 과정에서 지연 시간이 길어지고 코드 정리 작업이 다른 사람의 진행 중인 작업과 충돌할 가능성도 커진다</li></ul></li><li>상호 작용<ul><li>코드 정리 사이에 상호작용이 있으면 병합 비용은 급격히 증가한다</li></ul></li><li>추측<ul><li>한 번에 처리하는 코드 정리가 많을수록 자연스럽게 더 많은 코드를 정리하게 된다</li></ul></li><li>실천하고 실험하세요 오류를 팀과 함께 검토<h2 id="Chapter-19-리듬"><a href="#Chapter-19-리듬" class="headerlink" title="Chapter 19 리듬"></a>Chapter 19 리듬</h2></li><li>소프트웨어 설계는 프렉탁 이므로 설계는 크게도 작게도 할 수 있다</li><li>소프트웨어 설계는 길을 닦는 일의 성격이 매우 강함</li><li>동작 변경은 코드 안에 뭉쳐서 나타나는 경향이 있다<h2 id="Chapter-20-얽힘-풀기"><a href="#Chapter-20-얽힘-풀기" class="headerlink" title="Chapter 20 얽힘 풀기"></a>Chapter 20 얽힘 풀기</h2></li><li>코드 정리와 동작 변경 사이의 선후 문제는 보통 시간이 지나면 해결<h2 id="Chapter-21-코드-정리-시점"><a href="#Chapter-21-코드-정리-시점" class="headerlink" title="Chapter 21 코드 정리 시점"></a>Chapter 21 코드 정리 시점</h2></li><li>아예 안 한다면<ul><li>앞으로 다시는 코드를 변경하지 않을 때</li><li>설계를 개선하더라도 배울것이 없을때</li></ul></li><li>나중에 정리하기<ul><li>정리할 코드 분량이 많은데 보상이 바로 보이지 않을때</li><li>코드 정리에 대한 보상이 잠재적일때</li><li>작은 묶음으로 여러번에 나눠서 코드 정리를 할수 있을때</li></ul></li><li>동작 변경 후에 코드 정리<ul><li>다음 코드 정리까지 기다릴수록 비용이 더 불어날때</li><li>코드정리를 하지 않으면 일을 끝냈다는 느낌이 들지 않을때</li></ul></li><li>코드 정리 후에 동작 변경<ul><li>코드 정리했을때 코드 이해가 쉬워지거나 동작변경이 쉬워질때</li><li>어떤 코드를 어떻게 정리해야 하는지 알고 있을 때</li></ul></li></ul><h1 id="참조"><a href="#참조" class="headerlink" title="참조"></a>참조</h1><hr><ul><li><a href="https://www.yes24.com/Product/Goods/125921718">Tidy First?</a></li></ul>]]></content:encoded>
      
      <comments>https://sejoung.github.io/2024/04/2024-04-29-tidy_first_PART2/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Part 1 코드 정리법</title>
      <link>https://sejoung.github.io/2024/04/2024-04-26-tidy_first_PART1/</link>
      <guid>https://sejoung.github.io/2024/04/2024-04-26-tidy_first_PART1/</guid>
      <pubDate>Fri, 26 Apr 2024 01:38:00 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;Part-1-코드-정리법&quot;&gt;&lt;a href=&quot;#Part-1-코드-정리법&quot; class=&quot;headerlink&quot; title=&quot;Part 1 코드 정리법&quot;&gt;&lt;/a&gt;Part 1 코드 정리법&lt;/h1&gt;&lt;h2 id=&quot;Chapter-1-보호-구문&quot;&gt;&lt;a h
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Part-1-코드-정리법"><a href="#Part-1-코드-정리법" class="headerlink" title="Part 1 코드 정리법"></a>Part 1 코드 정리법</h1><h2 id="Chapter-1-보호-구문"><a href="#Chapter-1-보호-구문" class="headerlink" title="Chapter 1 보호 구문"></a>Chapter 1 보호 구문</h2><ul><li>중첩된 조건은 헷갈린다</li><li>보호 구문은 코드를 읽기 쉽게 만든다</li><li><a href="https://github.com/Bogdanp/dramatiq/pull/470">Add guard clause to stub.py</a></li></ul><h2 id="Chapter-2-안-쓰는-코드"><a href="#Chapter-2-안-쓰는-코드" class="headerlink" title="Chapter 2 안 쓰는 코드"></a>Chapter 2 안 쓰는 코드</h2><ul><li>삭제 하라</li></ul><h2 id="Chapter-3-대칭으로-맞추기"><a href="#Chapter-3-대칭으로-맞추기" class="headerlink" title="Chapter 3 대칭으로 맞추기"></a>Chapter 3 대칭으로 맞추기</h2><ul><li>같은 문제라도 시대와 사람에 따라 다른 모습으로 해결된다 자연스러운 일이지만 이것이 코드를 읽기 어렵게 만들기도 한다</li><li>코드를 읽는 사람 입장에선 일관성이 중요하다</li></ul><h2 id="Chapter-4-새로운-인터페이스로-기존-루틴-부르기"><a href="#Chapter-4-새로운-인터페이스로-기존-루틴-부르기" class="headerlink" title="Chapter 4 새로운 인터페이스로 기존 루틴 부르기"></a>Chapter 4 새로운 인터페이스로 기존 루틴 부르기</h2><ul><li>새로운 인터페이스를 만들어 기존 루틴을 부르는 방식으로 코드를 정리하자</li><li>거꾸로 코딩하기 : 루틴의 마지막 줄부터 시작해서 거꾸로 코드를 짜나가는 방식</li><li>테스트 우선 코딩</li><li>도우미 설계</li></ul><h2 id="Chapter-5-읽는-순서"><a href="#Chapter-5-읽는-순서" class="headerlink" title="Chapter 5 읽는 순서"></a>Chapter 5 읽는 순서</h2><ul><li>코드를 읽기 좋은 순서로 다시 정렬하면 그 순서대로 코드를 만날수 있다</li><li>코드를 읽는 사람 입장에서 코드를 작성하자</li></ul><h2 id="Chapter-6-응집도를-높이는-배치"><a href="#Chapter-6-응집도를-높이는-배치" class="headerlink" title="Chapter 6 응집도를 높이는 배치"></a>Chapter 6 응집도를 높이는 배치</h2><ul><li>코드를 읽다가 변경해야 할 동작을 찾았더니 여러 곳에 흩어져 있는 코드를 함께 바꿔야 한다면 그 코드는 응집도가 낮다</li><li>코드의 순서를 바꿔서 변경할 요소들을 가까이 두면된다</li><li>결합도가 있으면 서로 옆에 두자</li><li>두 파일에 결합도가 있으면 같은 디렉토리에 넣자</li><li>응집도를 높이는 순서로 정리하면 코드를 더 쉽게 변경할 수 있다</li></ul><h2 id="Chapter-7-선언과-초기화를-함께-옮기기"><a href="#Chapter-7-선언과-초기화를-함께-옮기기" class="headerlink" title="Chapter 7 선언과 초기화를 함께 옮기기"></a>Chapter 7 선언과 초기화를 함께 옮기기</h2><ul><li>변수 선언가 초기화 위치는 같이 붙어 있는게 좋다</li></ul><h2 id="Chapter-8-설명하는-변수"><a href="#Chapter-8-설명하는-변수" class="headerlink" title="Chapter 8 설명하는 변수"></a>Chapter 8 설명하는 변수</h2><ul><li>표현의 의도가 드러나도록 변수명을 지어야 된다</li><li>코드 정리 커밋과 동작 변경에 대한 커밋은 분리 해야 된다</li></ul><h2 id="Chapter-9-설명하는-상수"><a href="#Chapter-9-설명하는-상수" class="headerlink" title="Chapter 9 설명하는 상수"></a>Chapter 9 설명하는 상수</h2><ul><li>같은 리터럴 상수가 두 곳에서 나타날때는 다른 의미로 쓰이는지 확인</li></ul><h2 id="Chapter-10-명시적인-매개변수"><a href="#Chapter-10-명시적인-매개변수" class="headerlink" title="Chapter 10 명시적인 매개변수"></a>Chapter 10 명시적인 매개변수</h2><ul><li>매개변수를 암묵적으로 사용하지 말고 명시적으로 사용하자</li><li>명시적으로 하면 읽기 테스트 분석이 쉬워진다</li></ul><h2 id="Chapter-11-비슷한-코드끼리"><a href="#Chapter-11-비슷한-코드끼리" class="headerlink" title="Chapter 11 비슷한 코드끼리"></a>Chapter 11 비슷한 코드끼리</h2><ul><li>두 부분사이에 빈 줄을 넣어 분리</li><li>제대로 된 설계는 설계 유연성을 확보 잘못하면 소프트웨어 설계의 소용돌이에 빠질 수 있다</li></ul><h2 id="Chapter-12-도우미-추출"><a href="#Chapter-12-도우미-추출" class="headerlink" title="Chapter 12 도우미 추출"></a>Chapter 12 도우미 추출</h2><ul><li>시간적 결합을 표현하는 경우 도우미 함수를 추출하자</li></ul><h2 id="Chapter-13-하나의-더미"><a href="#Chapter-13-하나의-더미" class="headerlink" title="Chapter 13 하나의 더미"></a>Chapter 13 하나의 더미</h2><ul><li>필요한 만큼의 코드를 하나의 더미 처럼 느껴질 때 까지 흩어진 코드를 모으세요</li><li>길고 반복되는 인자 목록</li><li>반복되는 코드 그 중에서도 반복되는 조건문</li><li>도우미에 대한 부적절한 이름</li><li>공유되어 변경에 노출된 데이터 구조</li></ul><h2 id="Chapter-14-설명하는-주석"><a href="#Chapter-14-설명하는-주석" class="headerlink" title="Chapter 14 설명하는 주석"></a>Chapter 14 설명하는 주석</h2><ul><li>아 이건 이렇게 돌아가는 거구나 라는 생각이 드는 순간을 아시죠? 그 순간이 소중한 순간입니다 기록하세요</li><li>코드의 결합을 발견했다면 그 즉시 해당 위치에 주석을 달아야 한다</li></ul><h2 id="Chapter-15-불필요한-주석-지우기"><a href="#Chapter-15-불필요한-주석-지우기" class="headerlink" title="Chapter 15 불필요한 주석 지우기"></a>Chapter 15 불필요한 주석 지우기</h2><ul><li>코드만으로 내용을 모두 이해할 수 있다면 주석은 삭제 하세요</li></ul><h1 id="참조"><a href="#참조" class="headerlink" title="참조"></a>참조</h1><hr><ul><li><a href="https://www.yes24.com/Product/Goods/125921718">Tidy First?</a></li><li><a href="https://github.com/Bogdanp/dramatiq/pull/470">Add guard clause to stub.py</a></li><li><a href="https://jamie95.tistory.com/99">객체지향 생활체조 원칙 9가지</a></li></ul>]]></content:encoded>
      
      <comments>https://sejoung.github.io/2024/04/2024-04-26-tidy_first_PART1/#disqus_thread</comments>
    </item>
    
    <item>
      <title>LoRa 학습용 tool</title>
      <link>https://sejoung.github.io/2024/03/2024-03-18-lora_tool/</link>
      <guid>https://sejoung.github.io/2024/03/2024-03-18-lora_tool/</guid>
      <pubDate>Mon, 18 Mar 2024 01:16:00 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;LoRa-학습용-tool&quot;&gt;&lt;a href=&quot;#LoRa-학습용-tool&quot; class=&quot;headerlink&quot; title=&quot;LoRa 학습용 tool&quot;&gt;&lt;/a&gt;LoRa 학습용 tool&lt;/h1&gt;&lt;h2 id=&quot;lora-scripts-a-k-a-SD
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="LoRa-학습용-tool"><a href="#LoRa-학습용-tool" class="headerlink" title="LoRa 학습용 tool"></a>LoRa 학습용 tool</h1><h2 id="lora-scripts-a-k-a-SD-Trainer"><a href="#lora-scripts-a-k-a-SD-Trainer" class="headerlink" title="lora-scripts a.k.a SD-Trainer"></a>lora-scripts a.k.a SD-Trainer</h2><ul><li>중국에서 로라 학습용으로 만든 gui와 script를 동시에 지원하는 툴</li><li>중국어만 지원함</li></ul><h2 id="SD-script"><a href="#SD-script" class="headerlink" title="SD script"></a>SD script</h2><ul><li>accelerate 라이브러리를 활용해서 미세조정 스크립트</li><li>kohya_ss 툴에서 사용중</li></ul><h2 id="kohya-ss"><a href="#kohya-ss" class="headerlink" title="kohya_ss"></a>kohya_ss</h2><ul><li>windows에서 동작하는 툴</li><li>lora 학습용으로 만들어진 툴</li><li>linux는 커뮤니티를 통해서 지원</li></ul><h2 id=""><a href="#" class="headerlink" title=""></a></h2><h1 id="참조"><a href="#참조" class="headerlink" title="참조"></a>참조</h1><hr><ul><li><a href="https://github.com/LarryJane491/Lora-Training-in-Comfy">Lora-Training-in-Comfy</a></li><li><a href="https://github.com/Akegarasu/lora-scripts">lora-scripts a.k.a SD-Trainer</a></li><li><a href="https://github.com/kohya-ss/sd-scripts">sd-scripts</a></li><li><a href="https://github.com/bmaltais/kohya_ss">kohya_ss</a></li><li><a href="https://rentry.org/lora_train">LoRA 교육 가이드</a></li><li><a href="https://github.com/Linaqruf/kohya-trainer">kohya-trainer</a></li><li><a href="https://rentry.org/tohoaifaq#opinionated-lora-guide-for-colab">dongProject AI에 대한 대략적인 FAQ</a></li><li><a href="https://github.com/derrian-distro/LoRA_Easy_Training_Scripts">LoRA_Easy_Training_Scripts</a></li><li><a href="https://huggingface.co/hollowstrawberry/stable-diffusion-guide">hollowstrawberry_stable-diffusion-guide</a></li><li><a href="https://stable-diffusion-art.com/train-lora/">How to train Lora models</a></li><li><a href="https://civitai.com/models/22530">쉽고 무료로 나만의 로라스를 만들어보세요</a></li></ul>]]></content:encoded>
      
      <comments>https://sejoung.github.io/2024/03/2024-03-18-lora_tool/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Semantic Matching 2</title>
      <link>https://sejoung.github.io/2024/03/2024-03-12-Semantic_Matching_2/</link>
      <guid>https://sejoung.github.io/2024/03/2024-03-12-Semantic_Matching_2/</guid>
      <pubDate>Tue, 12 Mar 2024 02:38:00 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;Semantic-Matching-2&quot;&gt;&lt;a href=&quot;#Semantic-Matching-2&quot; class=&quot;headerlink&quot; title=&quot;Semantic Matching 2&quot;&gt;&lt;/a&gt;Semantic Matching 2&lt;/h1&gt;&lt;h2 i
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Semantic-Matching-2"><a href="#Semantic-Matching-2" class="headerlink" title="Semantic Matching 2"></a>Semantic Matching 2</h1><h2 id="Semantic-Flow"><a href="#Semantic-Flow" class="headerlink" title="Semantic Flow"></a>Semantic Flow</h2><ul><li>UCN(Universal Correspondence Networks)<ul><li>Fully convolutional NN -&gt; STNs -&gt; L2 Normalization</li></ul></li><li>Proposal Flow<ul><li>Comparisons </li><li>매칭 알고리즘</li></ul></li><li>Semantic Correspondence<ul><li>dense correspondence</li></ul></li><li>Hyperpixel representation<ul><li>Pixel : (𝑥, 𝑦, 𝑅, 𝐺, 𝐵)</li><li>Superpixel : 𝑛 ∗ (𝑥, 𝑦, 𝑅, 𝐺, 𝐵)</li><li>Hypercolumn :  (𝑥, 𝑦, 𝑑1, … , 𝑑n)</li><li>Hyperpixel : (𝑥, 𝑦, 𝑤, ℎ, 𝑑1, … , 𝑑n)</li></ul></li><li>Hyperpixel Flow<ul><li>Regularized Hough Matching (RHM)<ul><li>Classic computer vision 에서 사용하던 매칭 테크닉.</li><li>Re-parameterization technique : parametric space 를 변환 시켜 voting을 통해 가장 적절한 매칭을 찾는 방식</li><li>Hough transform</li></ul></li><li>summary<ul><li>Hyperpixel representation 제안 : geometry (region information; width, height …) 정보를 가진 hypercolumn 구조</li><li>모든 layer를 다 사용하지 않고, 특정 layer 만 사용하여 composing 하는 hypercolumn, hyperpixel 구조가 더 성능이 좋다.</li><li>GPU computation을 통해 기존의 matching technique인 probabilistic Hough matching 방식의 성능과 속도를 압도적으로 높일 수 있다. (regularized Hough matching) (정량적 결과 result section에 기록)</li></ul></li></ul></li><li>Dynamic feed-forward network<ul><li>Forward time : argmax  </li><li>Backward time : softmax</li><li>Local 영역을 중요하게 봐야하는 computer vision task (object detection, segmentation, tracking, matching …)에서 Multi-layer neural feature를 사용하자.</li><li>그런데 문제를 풀 때에 중요한 layer output을 잘 골라서 사용하자.</li><li>Beam search (Greedy algorithm)으로 찾을 수도 있지만 Data domain에 맞게 training하면 더 좋다</li><li>Trainable model을 만들 때에 layer 를 selection 해야하는데, argmax selection 은 differentiable 하지 않아 학습 불가능 하니, Gumbel-softmax trick을 사용해서 학습하자.</li></ul></li><li>SFNet</li></ul><h1 id="참조"><a href="#참조" class="headerlink" title="참조"></a>참조</h1><hr>]]></content:encoded>
      
      <comments>https://sejoung.github.io/2024/03/2024-03-12-Semantic_Matching_2/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Semantic Matching 1</title>
      <link>https://sejoung.github.io/2024/03/2024-03-11-Semantic_Matching/</link>
      <guid>https://sejoung.github.io/2024/03/2024-03-11-Semantic_Matching/</guid>
      <pubDate>Mon, 11 Mar 2024 00:40:00 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;Semantic-Matching-1&quot;&gt;&lt;a href=&quot;#Semantic-Matching-1&quot; class=&quot;headerlink&quot; title=&quot;Semantic Matching 1&quot;&gt;&lt;/a&gt;Semantic Matching 1&lt;/h1&gt;&lt;h2 i
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Semantic-Matching-1"><a href="#Semantic-Matching-1" class="headerlink" title="Semantic Matching 1"></a>Semantic Matching 1</h1><h2 id="Semantic-Alignment"><a href="#Semantic-Alignment" class="headerlink" title="Semantic Alignment"></a>Semantic Alignment</h2><ul><li><p>Spatial Transformer Networks</p><ul><li>Differentiable spatial transformation<ul><li>Localisation network</li><li>Parameterised Sampling Grid</li><li>Differentiable Image Sampling</li></ul></li></ul></li><li><p>GeoCNN, weakalign, A2Net</p></li><li><p>NC-Net, Sparse-NC-Net, CHM</p></li><li><p>Neighbourhood Consensus Networks (NCNet)</p><ul><li>Loss functions<ul><li>weakly supervised training</li></ul></li><li>Memory issue</li><li>Cannot handle high-resolution images</li></ul></li><li><p>Sparse-NCNet</p><ul><li>Minkowski Engine</li></ul></li><li><p>Convolutional Hough Matching Networks (CHM)</p></li></ul><h1 id="참조"><a href="#참조" class="headerlink" title="참조"></a>참조</h1><hr>]]></content:encoded>
      
      <comments>https://sejoung.github.io/2024/03/2024-03-11-Semantic_Matching/#disqus_thread</comments>
    </item>
    
    <item>
      <title>CHAPTER 8 행동 디자인 패턴 PART1</title>
      <link>https://sejoung.github.io/2024/03/2024-03-07-design_patterns_beauty_8_PART_1/</link>
      <guid>https://sejoung.github.io/2024/03/2024-03-07-design_patterns_beauty_8_PART_1/</guid>
      <pubDate>Thu, 07 Mar 2024 00:48:00 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;CHAPTER-8-행동-디자인-패턴-PART1&quot;&gt;&lt;a href=&quot;#CHAPTER-8-행동-디자인-패턴-PART1&quot; class=&quot;headerlink&quot; title=&quot;CHAPTER 8 행동 디자인 패턴 PART1&quot;&gt;&lt;/a&gt;CHAPTER 8 행
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="CHAPTER-8-행동-디자인-패턴-PART1"><a href="#CHAPTER-8-행동-디자인-패턴-PART1" class="headerlink" title="CHAPTER 8 행동 디자인 패턴 PART1"></a>CHAPTER 8 행동 디자인 패턴 PART1</h1><ul><li>생성 디자인 패턴 : 주로 객체의 생성에 관련된 문제 해결</li><li>구조 디자인 패턴 : 주로 클래스나 객체의 결합 문제를 해결</li><li>행동 디자인 패턴 : 주로 클래스나 객체의 상호작용 문제를 해결</li></ul><h2 id="8-1-옵서버-패턴"><a href="#8-1-옵서버-패턴" class="headerlink" title="8.1 옵서버 패턴"></a>8.1 옵서버 패턴</h2><h3 id="8-1-1-옵서버-패턴의-정의"><a href="#8-1-1-옵서버-패턴의-정의" class="headerlink" title="8.1.1 옵서버 패턴의 정의"></a>8.1.1 옵서버 패턴의 정의</h3><p>발행 구독 패턴이라고도 한다</p><ul><li>많은 객체들 사이에서 일대일 의존 관계가 정의되어 있을 때, 어느 한 객체의 상태가 변경되면 이 객체에 의존하고 있는 모든 객체는 자동으로 알림을 받는다</li><li>의존되는 객체를 피관찰자, 옵서버블 이라고 한다</li><li>의존하고 있는 객체를 관찰자, 옵서버라고 한다<h3 id="8-1-3-옵서버-패턴의-의미"><a href="#8-1-3-옵서버-패턴의-의미" class="headerlink" title="8.1.3 옵서버 패턴의 의미"></a>8.1.3 옵서버 패턴의 의미</h3></li><li>서로 다른 행동을 하는 코드를 디커플링</li><li>옵서버 코드와 옵서버블 코드를 디커플링<h3 id="8-1-4-옵서버-패턴의-적용"><a href="#8-1-4-옵서버-패턴의-적용" class="headerlink" title="8.1.4 옵서버 패턴의 적용"></a>8.1.4 옵서버 패턴의 적용</h3></li><li>동기식 차단 옵서버 패턴</li><li>비동기식 비차단 옵서버 패턴<h3 id="8-1-5-비동기식-비차단-옵서버-패턴"><a href="#8-1-5-비동기식-비차단-옵서버-패턴" class="headerlink" title="8.1.5 비동기식 비차단 옵서버 패턴"></a>8.1.5 비동기식 비차단 옵서버 패턴</h3></li><li>비동기식 비차단 옵서버 패턴은 EventBus 프레임워크를 사용하여 구현</li></ul><h1 id="참조"><a href="#참조" class="headerlink" title="참조"></a>참조</h1><hr><ul><li><a href="https://www.yes24.com/Product/Goods/118859035">디자인 패턴의 아름다움</a></li></ul>]]></content:encoded>
      
      <comments>https://sejoung.github.io/2024/03/2024-03-07-design_patterns_beauty_8_PART_1/#disqus_thread</comments>
    </item>
    
    <item>
      <title>CHAPTER 7 구조 디자인 패턴_PART_1</title>
      <link>https://sejoung.github.io/2024/03/2024-03-06-design_patterns_beauty_7_PART_2/</link>
      <guid>https://sejoung.github.io/2024/03/2024-03-06-design_patterns_beauty_7_PART_2/</guid>
      <pubDate>Wed, 06 Mar 2024 00:44:00 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;CHAPTER-7-구조-디자인-패턴-PART-2&quot;&gt;&lt;a href=&quot;#CHAPTER-7-구조-디자인-패턴-PART-2&quot; class=&quot;headerlink&quot; title=&quot;CHAPTER 7 구조 디자인 패턴_PART_2&quot;&gt;&lt;/a&gt;CHAPTER 
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="CHAPTER-7-구조-디자인-패턴-PART-2"><a href="#CHAPTER-7-구조-디자인-패턴-PART-2" class="headerlink" title="CHAPTER 7 구조 디자인 패턴_PART_2"></a>CHAPTER 7 구조 디자인 패턴_PART_2</h1><h3 id="7-3-4-래퍼-패턴"><a href="#7-3-4-래퍼-패턴" class="headerlink" title="7.3.4 래퍼 패턴"></a>7.3.4 래퍼 패턴</h3><ul><li>프록시 패턴</li><li>데커레이터 패턴</li><li>어뎁터 패턴</li></ul><p>코드 구조 측면에서 이 세가지 디자인 패턴을 통틀어 래퍼 패턴으로 구분</p><p>원본 클래스를 래퍼 클래스를 통해 두 번 캡슐화하는 패턴</p><h2 id="7-4-브리지-패턴"><a href="#7-4-브리지-패턴" class="headerlink" title="7.4 브리지 패턴"></a>7.4 브리지 패턴</h2><p>상속 대신 합성을 사용 복잡한 상속 관계를 간단한 합성 관계로 단순화</p><h3 id="7-4-1-브리지-패턴의-정의"><a href="#7-4-1-브리지-패턴의-정의" class="headerlink" title="7.4.1 브리지 패턴의 정의"></a>7.4.1 브리지 패턴의 정의</h3><p>추상화와 구현을 디커플링해야만 두 가지가 서로 독립적으로 변화할 수 있다</p><h2 id="7-5-퍼사드-패턴"><a href="#7-5-퍼사드-패턴" class="headerlink" title="7.5 퍼사드 패턴"></a>7.5 퍼사드 패턴</h2><h3 id="7-5-1-퍼사드-패턴과-인터페이스-설계"><a href="#7-5-1-퍼사드-패턴과-인터페이스-설계" class="headerlink" title="7.5.1 퍼사드 패턴과 인터페이스 설계"></a>7.5.1 퍼사드 패턴과 인터페이스 설계</h3><p>서브 시스템에 대한 통합 인터페이스 세트를 제공하고 하위 시스템을 더 쉽게 만들기 위한 상위 통합 인터페이스를 제공한다</p><h2 id="7-6-복합체-패턴"><a href="#7-6-복합체-패턴" class="headerlink" title="7.6 복합체 패턴"></a>7.6 복합체 패턴</h2><p>주로 트리 구조의 데이터를 처리하는데 사용된다 여기서 데이터는 단순한 객체의 모음으로 이해</p><h3 id="7-6-1-복합체-패턴-기반의-디렉터리-트리"><a href="#7-6-1-복합체-패턴-기반의-디렉터리-트리" class="headerlink" title="7.6.1 복합체 패턴 기반의 디렉터리 트리"></a>7.6.1 복합체 패턴 기반의 디렉터리 트리</h3><p>부분 - 전체 계층 구조로 인식하는 트리 구조로 구성된 객체 컬렉션, 복합체 패턴을 통해 코드 사용자로 대표되는 클라이언트가<br>개별 객체와 복합 객체의 처리 방식을 하나로 통합할 수 있다고 정의</p><h2 id="7-7-플라이웨이트-패턴"><a href="#7-7-플라이웨이트-패턴" class="headerlink" title="7.7 플라이웨이트 패턴"></a>7.7 플라이웨이트 패턴</h2><p>공유를 위해 사용하는 패턴 목적은 객체를 공유하여 메모리 사용량을 줄이는 것</p><h3 id="7-7-5-플라이웨이트-패턴과-싱글턴-패턴-캐시-오브젝트-풀의-차이"><a href="#7-7-5-플라이웨이트-패턴과-싱글턴-패턴-캐시-오브젝트-풀의-차이" class="headerlink" title="7.7.5 플라이웨이트 패턴과 싱글턴 패턴, 캐시, 오브젝트 풀의 차이"></a>7.7.5 플라이웨이트 패턴과 싱글턴 패턴, 캐시, 오브젝트 풀의 차이</h3><ul><li>플라이웨이트 패턴과 싱글턴 패턴의 차이<ul><li>싱글턴 패턴에서 클래스는 하나의 객체만 생성하고, 플라이웨이트 패턴에서는 여러 객체를 생성하고 여러 코드에서 공유된다</li><li>플라이웨이트 패턴은 다중 인스턴스 패턴과 다소 유사한 면이 있다</li></ul></li><li>플라이웨이트 패턴과 캐싱의 차이점<ul><li>플라이웨이트 패턴은 클래스를 사용하여 생성된 객체를 캐싱</li><li>캐시는 실제로 저장소를 의미</li></ul></li><li>플라이웨이트 패턴과 오브젝트 풀의 차이<ul><li>오브젝트 풀은 오프젝트 풀에서 객체를 꺼내서 사용하고 다시 풀에 넣는다</li></ul></li></ul><h1 id="참조"><a href="#참조" class="headerlink" title="참조"></a>참조</h1><hr><ul><li><a href="https://www.yes24.com/Product/Goods/118859035">디자인 패턴의 아름다움</a></li></ul>]]></content:encoded>
      
      <comments>https://sejoung.github.io/2024/03/2024-03-06-design_patterns_beauty_7_PART_2/#disqus_thread</comments>
    </item>
    
    <item>
      <title>CHAPTER 7 구조 디자인 패턴_PART_1</title>
      <link>https://sejoung.github.io/2024/03/2024-03-05-design_patterns_beauty_7_PART_1/</link>
      <guid>https://sejoung.github.io/2024/03/2024-03-05-design_patterns_beauty_7_PART_1/</guid>
      <pubDate>Tue, 05 Mar 2024 00:37:00 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;CHAPTER-7-구조-디자인-패턴-PART-1&quot;&gt;&lt;a href=&quot;#CHAPTER-7-구조-디자인-패턴-PART-1&quot; class=&quot;headerlink&quot; title=&quot;CHAPTER 7 구조 디자인 패턴_PART_1&quot;&gt;&lt;/a&gt;CHAPTER 
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="CHAPTER-7-구조-디자인-패턴-PART-1"><a href="#CHAPTER-7-구조-디자인-패턴-PART-1" class="headerlink" title="CHAPTER 7 구조 디자인 패턴_PART_1"></a>CHAPTER 7 구조 디자인 패턴_PART_1</h1><ul><li>프록시 패턴 : 원본기술가 연관 없는 기능을 추가할 때 사용</li><li>데커레이터 패턴: 원본 클래스와 관련 있거나 향산된 기능을 추가할 때 사용</li><li>어댑터 패턴: 코드 호환성 문제 해결</li><li>브리지 패턴 : 합성의 폭발문제를 해결하는 데 사용</li><li>퍼사드 패턴 : 인터페이스 설계에 사용</li><li>복합체 패턴 : 주로 트리 구조로 나타낼 수 있는 데이터에 사용</li><li>플라이웨이트 패턴 : 재사용 문제 해결</li></ul><h2 id="7-1-프록시-패턴"><a href="#7-1-프록시-패턴" class="headerlink" title="7.1 프록시 패턴"></a>7.1 프록시 패턴</h2><h3 id="7-1-1-인터페이스-기반의-프록시-패턴"><a href="#7-1-1-인터페이스-기반의-프록시-패턴" class="headerlink" title="7.1.1 인터페이스 기반의 프록시 패턴"></a>7.1.1 인터페이스 기반의 프록시 패턴</h3><p>프록시 클래스를 도입하여 원본 클래스와 관련 없는 새로운 기능을 추가하는 것</p><h3 id="7-1-2-상속-기반의-프록시-패턴"><a href="#7-1-2-상속-기반의-프록시-패턴" class="headerlink" title="7.1.2 상속 기반의 프록시 패턴"></a>7.1.2 상속 기반의 프록시 패턴</h3><p>인터페이스를 정의하지 않고 있어서 클래스를 직접 수정할수 없을때 상속을 통해서 외부 클래스를 확장</p><h3 id="7-1-3-리플렉션-기반의-동적-프록시"><a href="#7-1-3-리플렉션-기반의-동적-프록시" class="headerlink" title="7.1.3 리플렉션 기반의 동적 프록시"></a>7.1.3 리플렉션 기반의 동적 프록시</h3><p>동적 프록시 : 각 원본 클래스에 대한 프록시 클래스를 미리 작성하는 대신 코드를 실행하는 도중 원본 클래스에 대한 프록시 클래스를 동적으로 생성하고<br>코드 내의 원본 클래스를 프록시 클래스로 대체하는 것을 말한다</p><h3 id="7-1-4-프록시-패턴의-활용-방법"><a href="#7-1-4-프록시-패턴의-활용-방법" class="headerlink" title="7.1.4 프록시 패턴의 활용 방법"></a>7.1.4 프록시 패턴의 활용 방법</h3><ul><li>주요 비즈니스와 관련 없는 요구 사항의 개발에 활용될 수 있다</li><li>RPC에서 프록시 패턴을 적용할 수 있다</li><li>캐시에 프록시 패턴을 적용할 수 있다<h2 id="7-2-데커레이터-패턴"><a href="#7-2-데커레이터-패턴" class="headerlink" title="7.2 데커레이터 패턴"></a>7.2 데커레이터 패턴</h2>원본 클래스와 관련 있거나 향산된 기능을 추가할 때 사용<h2 id="7-3-어댑터-패턴"><a href="#7-3-어댑터-패턴" class="headerlink" title="7.3 어댑터 패턴"></a>7.3 어댑터 패턴</h2>조정에 따른 적응에 사용되며, 호환되지 않은 인터페이스를 호환 가능한 인터페이스로 변환하여 두 클래스를 함께 작동할 수 있게 한다</li></ul><h3 id="7-3-1-클래스-어댑터와-객체-어댑터"><a href="#7-3-1-클래스-어댑터와-객체-어댑터" class="headerlink" title="7.3.1 클래스 어댑터와 객체 어댑터"></a>7.3.1 클래스 어댑터와 객체 어댑터</h3><p>클래스 어댑터는 상속 관계를 사용한 방식<br>객체 어뎁터는 합성 관계를 사용한 방식</p><ul><li>인터페이스가 많지 않으면 두 방식중 어느 것을 사용해도 무방하다</li><li>인터페이스가 많지만 source 와 target 인터페이스의 정의가 대부분 같다면 클래스 어뎁터를 사용하는것이 좋다</li><li>인터페이스가 많고 source 와 target 인터페이스의 정의가 대부분 다르다면 객체 어뎁터를 사용하는것이 좋다</li></ul><h3 id="7-3-2-어댑터-패턴의-응용"><a href="#7-3-2-어댑터-패턴의-응용" class="headerlink" title="7.3.2 어댑터 패턴의 응용"></a>7.3.2 어댑터 패턴의 응용</h3><p>어댑터 패턴은 설계 결함을 교정하는 보상 패턴으로 볼 수 있다</p><ul><li>결함이 있는 인터페이스 설계가 캡슐화된 경우</li><li>여러 클래스의 인터페이스 설계를 통합할 경우</li><li>사용 중인 외부 시스템을 교체해야 할 경우</li><li>이전 버전 인터페이스와 호환성이 필요한 경우</li><li>다양한 형식의 데이터에 적응해야 할 경우</li></ul><h1 id="참조"><a href="#참조" class="headerlink" title="참조"></a>참조</h1><hr><ul><li><a href="https://www.yes24.com/Product/Goods/118859035">디자인 패턴의 아름다움</a></li></ul>]]></content:encoded>
      
      <comments>https://sejoung.github.io/2024/03/2024-03-05-design_patterns_beauty_7_PART_1/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Multiview geometry 2</title>
      <link>https://sejoung.github.io/2024/03/2024-03-04-Multiview_geometry_2/</link>
      <guid>https://sejoung.github.io/2024/03/2024-03-04-Multiview_geometry_2/</guid>
      <pubDate>Mon, 04 Mar 2024 04:09:00 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;Multiview-geometry-2&quot;&gt;&lt;a href=&quot;#Multiview-geometry-2&quot; class=&quot;headerlink&quot; title=&quot;Multiview geometry 2&quot;&gt;&lt;/a&gt;Multiview geometry 2&lt;/h1&gt;&lt;
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Multiview-geometry-2"><a href="#Multiview-geometry-2" class="headerlink" title="Multiview geometry 2"></a>Multiview geometry 2</h1><h2 id="Wide-Baseline-Matching"><a href="#Wide-Baseline-Matching" class="headerlink" title="Wide-Baseline Matching"></a>Wide-Baseline Matching</h2><h3 id="Patch-based-model"><a href="#Patch-based-model" class="headerlink" title="Patch-based model"></a>Patch-based model</h3><ul><li>L2-Net</li><li>HardNet</li><li>SOSNet</li><li>HyNet</li></ul><h3 id="Dense-Imaging-Model"><a href="#Dense-Imaging-Model" class="headerlink" title="Dense Imaging Model"></a>Dense Imaging Model</h3><ul><li>GIFT</li><li>GLU-Net</li></ul><h3 id="Joint-Detection-and-Description"><a href="#Joint-Detection-and-Description" class="headerlink" title="Joint Detection and Description"></a>Joint Detection and Description</h3><ul><li>LIFT</li><li>LF-Net</li><li>SuperPoint<ul><li>Self-supervised for local features</li><li>Loss funcVons<ul><li>Detector loss + Descriptor loss</li></ul></li></ul></li><li>D2-NET<ul><li>Feature descriptors: 이전에 DELF 나 CNNGeometric 처럼 Dense CNN Feature를 local descriptors로 본다. 이 descripctor vector는 Euclidean distance를 계산할 준비가 된 상태이다. 실제로는 채널 방향의 L2 norm을 한다.</li><li>feature detectors: raw CNN feature의 각 채널의 Post-processing을 통해 구한다</li></ul></li><li>R2D2</li></ul><h3 id="Local-Regional-Information-Estimation"><a href="#Local-Regional-Information-Estimation" class="headerlink" title="Local Regional Information Estimation"></a>Local Regional Information Estimation</h3><ul><li>OriNet<ul><li>Learning to assign the local orientation values in the image matching pipeline</li></ul></li><li>AﬀNet<ul><li>Learning local affine shape estimator</li></ul></li><li>Self-supervised learning of image scale and orientation estimation : SelfScaOri</li></ul><h3 id="Matching-Models"><a href="#Matching-Models" class="headerlink" title="Matching Models"></a>Matching Models</h3><ul><li>Learning to find good correspondences</li><li>SuperGlue<ul><li>context aggregation + matching + filtering</li></ul></li></ul><h3 id="End-to-End-Models"><a href="#End-to-End-Models" class="headerlink" title="End-to-End Models"></a>End-to-End Models</h3><ul><li>LoFTR<ul><li>Based on transformer blocks</li></ul></li><li>COTR<ul><li>Correspondence Transformer</li></ul></li><li>DKM</li></ul><h1 id="참조"><a href="#참조" class="headerlink" title="참조"></a>참조</h1><hr>]]></content:encoded>
      
      <comments>https://sejoung.github.io/2024/03/2024-03-04-Multiview_geometry_2/#disqus_thread</comments>
    </item>
    
    <item>
      <title>CHAPTER 6 생성 디자인 패턴</title>
      <link>https://sejoung.github.io/2024/02/2024-02-29-design_patterns_beauty_6/</link>
      <guid>https://sejoung.github.io/2024/02/2024-02-29-design_patterns_beauty_6/</guid>
      <pubDate>Thu, 29 Feb 2024 00:29:00 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;CHAPTER-6-생성-디자인-패턴&quot;&gt;&lt;a href=&quot;#CHAPTER-6-생성-디자인-패턴&quot; class=&quot;headerlink&quot; title=&quot;CHAPTER 6 생성 디자인 패턴&quot;&gt;&lt;/a&gt;CHAPTER 6 생성 디자인 패턴&lt;/h1&gt;&lt;h2 i
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="CHAPTER-6-생성-디자인-패턴"><a href="#CHAPTER-6-생성-디자인-패턴" class="headerlink" title="CHAPTER 6 생성 디자인 패턴"></a>CHAPTER 6 생성 디자인 패턴</h1><h2 id="6-1-싱글턴-패턴-1"><a href="#6-1-싱글턴-패턴-1" class="headerlink" title="6.1 싱글턴 패턴 (1)"></a>6.1 싱글턴 패턴 (1)</h2><h3 id="6-1-1-싱글턴-패턴의-정의"><a href="#6-1-1-싱글턴-패턴의-정의" class="headerlink" title="6.1.1 싱글턴 패턴의 정의"></a>6.1.1 싱글턴 패턴의 정의</h3><p>어떤 클래스의 객체 또는 인스턴스를 단 하나만 생성할 수 있다면, 해당 클래스는 싱글턴 클래스이며, 이 디자인 패턴을 싱글턴 패턴이라고 한다</p><p>클레스안에 시스템에 한 번만 저장되어야 하는 데이터가 포함된 경우 해당 클래스는 싱글턴 클래스로 설계해야 한다</p><h3 id="6-1-2-싱글턴-패턴의-구현"><a href="#6-1-2-싱글턴-패턴의-구현" class="headerlink" title="6.1.2 싱글턴 패턴의 구현"></a>6.1.2 싱글턴 패턴의 구현</h3><ul><li>즉시 초기화</li><li>늦은 초기화</li><li>이중 잠금</li><li>홀더에 의한 초기화</li></ul><h3 id="6-1-4-싱글턴-패턴의-단점"><a href="#6-1-4-싱글턴-패턴의-단점" class="headerlink" title="6.1.4 싱글턴 패턴의 단점"></a>6.1.4 싱글턴 패턴의 단점</h3><ul><li>클래스 간의 의존성을 감춘다</li><li>코드의 확장성에 영향을 미친다</li><li>코드의 테스트 용이성에 영향을 미친다</li><li>매개변수가 있는 생성자를 지원하지 않는다<ul><li>init 메서드를 사용하여 매개변수를 전달하는 방법이 있다</li><li>getinstance 메서드를 사용하여 매개변수를 전달하는 방법이 있다</li><li>전역 변수에 넣는 방법<h3 id="6-1-5-싱글턴-패턴의-대안"><a href="#6-1-5-싱글턴-패턴의-대안" class="headerlink" title="6.1.5 싱글턴 패턴의 대안"></a>6.1.5 싱글턴 패턴의 대안</h3></li></ul></li></ul><p>의존성 주입을 통해 해결해 보는것도 대안이다</p><h2 id="6-2-싱글턴-패턴-2"><a href="#6-2-싱글턴-패턴-2" class="headerlink" title="6.2 싱글턴 패턴 (2)"></a>6.2 싱글턴 패턴 (2)</h2><h3 id="6-2-1-싱글턴-패턴의-유일성"><a href="#6-2-1-싱글턴-패턴의-유일성" class="headerlink" title="6.2.1 싱글턴 패턴의 유일성"></a>6.2.1 싱글턴 패턴의 유일성</h3><p>싱글턴 객체의 유일성이 가지는 범위는? 스레드? 프로세스?</p><p>싱글턴 객체의 유일성이 영향을 미치는 범위는 프로세스 내로 한정</p><h3 id="6-2-2-스레드-전용-싱글턴-패턴"><a href="#6-2-2-스레드-전용-싱글턴-패턴" class="headerlink" title="6.2.2 스레드 전용 싱글턴 패턴"></a>6.2.2 스레드 전용 싱글턴 패턴</h3><ul><li>스레드 안에서 유일 : 스레드 하나하나 마다 유일함</li><li>프로세스에서 유일 : 같은 프로세스에 속한 모든 스레드에서 유일</li></ul><h3 id="6-2-3-클러스터-환경에서의-싱글턴-패턴"><a href="#6-2-3-클러스터-환경에서의-싱글턴-패턴" class="headerlink" title="6.2.3 클러스터 환경에서의 싱글턴 패턴"></a>6.2.3 클러스터 환경에서의 싱글턴 패턴</h3><ul><li>클러스터에서 유일 : 같은 클러스터에 속한 여러 프로세스에서 유일</li></ul><h3 id="6-2-4-다중-인스턴스-패턴"><a href="#6-2-4-다중-인스턴스-패턴" class="headerlink" title="6.2.4 다중 인스턴스 패턴"></a>6.2.4 다중 인스턴스 패턴</h3><ul><li>클래스가 여러개 생성될수 있지만 생성할 수 있는 개수가 제한되어 있음을 의미</li><li>팩터리 패턴과 유사</li></ul><h2 id="6-3-팩터리-패턴-1"><a href="#6-3-팩터리-패턴-1" class="headerlink" title="6.3 팩터리 패턴 (1)"></a>6.3 팩터리 패턴 (1)</h2><ul><li>단순 팩터리 패턴(simple factory pattern)</li><li>팩터리 메서드 패턴(factory method pattern)</li><li>추상 팩터리 패턴(abstract factory pattern)</li></ul><h3 id="6-3-1-단순-팩터리-패턴"><a href="#6-3-1-단순-팩터리-패턴" class="headerlink" title="6.3.1 단순 팩터리 패턴"></a>6.3.1 단순 팩터리 패턴</h3><p>분기 판단 논리 명령문이 모여 있는데 이 코드를 다형성이나 다른 디자인 패턴으로 대체해야 할지 고민이 될 수도 있다 하지만 if 분기가 매우 많은게 아니라면 if 분기가 있어도 된다</p><h3 id="6-3-2-팩터리-메서드-패턴"><a href="#6-3-2-팩터리-메서드-패턴" class="headerlink" title="6.3.2 팩터리 메서드 패턴"></a>6.3.2 팩터리 메서드 패턴</h3><p>팩터리 메서드 패턴은 단순 팩터리 패턴보다 개방 패쇄원리에 더 가깝다</p><p>코드가 충분히 단순하면 단순 팩터리 패턴으로 충분하며 팩터리 메서드 패턴을 사용할 필요가 없다</p><h3 id="6-3-3-추상-팩터리-패턴"><a href="#6-3-3-추상-팩터리-패턴" class="headerlink" title="6.3.3 추상 팩터리 패턴"></a>6.3.3 추상 팩터리 패턴</h3><p>팩터리가 한가지 유형의 만드는 대신 다양한 유형을 만들게 하는것</p><h3 id="6-3-4-팩터리-패턴의-적용-대상"><a href="#6-3-4-팩터리-패턴의-적용-대상" class="headerlink" title="6.3.4 팩터리 패턴의 적용 대상"></a>6.3.4 팩터리 패턴의 적용 대상</h3><ul><li>규칙 설정 분석과 유사하게 코드에 if 분기 판단 논리가 있으며 유형에 따라 다른 객체를 동적으로 생성하는 경우</li><li>유형에 따라 다른 객체를 생성할 필요는 없지만 단일 객체 자체의 생성 프로세스가 비교적 복잡한 경우</li></ul><h2 id="6-4-팩터리-패턴-2"><a href="#6-4-팩터리-패턴-2" class="headerlink" title="6.4 팩터리 패턴 (2)"></a>6.4 팩터리 패턴 (2)</h2><p>팩터리 패턴은 의존성 주입 컨테이너에서 널리 사용된다</p><h3 id="6-4-1-DI-컨테이너와-팩터리-패턴의-차이"><a href="#6-4-1-DI-컨테이너와-팩터리-패턴의-차이" class="headerlink" title="6.4.1 DI 컨테이너와 팩터리 패턴의 차이"></a>6.4.1 DI 컨테이너와 팩터리 패턴의 차이</h3><p>DI 컨테이너는 팩터리 패턴의 확장이다</p><p>DI 컨테이너는 많은 객체를 담을수 있어서 컨테이너라고 불린다</p><h3 id="6-4-2-DI-컨테이너의-핵심-기능"><a href="#6-4-2-DI-컨테이너의-핵심-기능" class="headerlink" title="6.4.2 DI 컨테이너의 핵심 기능"></a>6.4.2 DI 컨테이너의 핵심 기능</h3><ul><li>설정 분석<ul><li>DI 컨테이너가 생성해야 하는 객체를 알려주는 도구가 설정이다</li></ul></li><li>객체 생성<ul><li>리플렉션을 통해서 객체 생성</li></ul></li><li>객체 수명 주기 관리<ul><li>spring framework의 bean scope <ul><li>scope를 통해서 객체의 수명 주기를 관리</li><li>지연 적재를 lazy-init 속성으로 관리</li></ul></li></ul></li></ul><h2 id="6-5-빌더-패턴"><a href="#6-5-빌더-패턴" class="headerlink" title="6.5 빌더 패턴"></a>6.5 빌더 패턴</h2><p>생성기 패턴</p><h3 id="6-5-1-생성자를-사용한-객체-생성"><a href="#6-5-1-생성자를-사용한-객체-생성" class="headerlink" title="6.5.1 생성자를 사용한 객체 생성"></a>6.5.1 생성자를 사용한 객체 생성</h3><p>매개 변수 목록이 많아지면 가독성과 사용 편의성이 나빠진다</p><h3 id="6-5-2-setter-메서드를-사용한-멤버-변수-설정"><a href="#6-5-2-setter-메서드를-사용한-멤버-변수-설정" class="headerlink" title="6.5.2 setter 메서드를 사용한 멤버 변수 설정"></a>6.5.2 setter 메서드를 사용한 멤버 변수 설정</h3><p>코드의 가독성과 편의성이 증가 된다</p><h3 id="6-5-3-빌더-패턴을-이용한-매개변수-검증"><a href="#6-5-3-빌더-패턴을-이용한-매개변수-검증" class="headerlink" title="6.5.3 빌더 패턴을 이용한 매개변수 검증"></a>6.5.3 빌더 패턴을 이용한 매개변수 검증</h3><ul><li>필수 항목이 매우 많다면 생성자 매개 변수로 지정해야 되는데 가독성과 사용편의성 문제가 생긴다</li><li>설정 사이에 의존성이 존재 할때</li><li>클래스의 객체가 불변 객체여야 한다면</li></ul><h3 id="6-5-5-빌더-패턴과-팩터리-패턴의-차이"><a href="#6-5-5-빌더-패턴과-팩터리-패턴의-차이" class="headerlink" title="6.5.5 빌더 패턴과 팩터리 패턴의 차이"></a>6.5.5 빌더 패턴과 팩터리 패턴의 차이</h3><p>팩터리 패턴은 동일한 상위 클래스나 인터페이스를 상속하는 하위 클래스 그룹과 같이 유형은 다르지만 연관되어 있는 객체를 생성할 때 사용되며,<br>어떤 유형의 객체를 생성할지는 미리 지정된 매개변수에 의해 결정된다</p><p>빌더 패턴은 동일한 유형의 복잡도 높은 객체를 생성하는데 이때 선택적 매개변수를 설정하거나 사용자 정의를 통해 다른 객체를 생성한다</p><h2 id="6-6-프로토타입-패턴"><a href="#6-6-프로토타입-패턴" class="headerlink" title="6.6 프로토타입 패턴"></a>6.6 프로토타입 패턴</h2><h3 id="6-6-1-프로토타입-패턴의-정의"><a href="#6-6-1-프로토타입-패턴의-정의" class="headerlink" title="6.6.1 프로토타입 패턴의 정의"></a>6.6.1 프로토타입 패턴의 정의</h3><p>객체의 생성 비용이 비교적 크지만 동일한 클래스 기반으로 생성된 차이가 그리 크지 않은 객체를 생성할 경우<br>생성시간을 절약하기 위해 기존 객체인 프로토타입을 사용하여 복사를 통해 새 객체를 생성한다.<br>이렇게 프로토타입을 기반으로 객체를 생성하는 방식을 프로토타입 패턴이라고 한다</p><ul><li>깊은 복사 : 객체의 모든 멤버 변수를 복사</li><li>얕은 복사 : 객체의 주소값만 복사</li></ul><h1 id="참조"><a href="#참조" class="headerlink" title="참조"></a>참조</h1><hr><ul><li><a href="https://www.yes24.com/Product/Goods/118859035">디자인 패턴의 아름다움</a></li></ul>]]></content:encoded>
      
      <comments>https://sejoung.github.io/2024/02/2024-02-29-design_patterns_beauty_6/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Multiview geometry 1</title>
      <link>https://sejoung.github.io/2024/02/2024-02-28-Multiview_geometry/</link>
      <guid>https://sejoung.github.io/2024/02/2024-02-28-Multiview_geometry/</guid>
      <pubDate>Wed, 28 Feb 2024 05:40:00 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;Multiview-geometry-1&quot;&gt;&lt;a href=&quot;#Multiview-geometry-1&quot; class=&quot;headerlink&quot; title=&quot;Multiview geometry 1&quot;&gt;&lt;/a&gt;Multiview geometry 1&lt;/h1&gt;&lt;
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Multiview-geometry-1"><a href="#Multiview-geometry-1" class="headerlink" title="Multiview geometry 1"></a>Multiview geometry 1</h1><h2 id="Local-Features"><a href="#Local-Features" class="headerlink" title="Local Features"></a>Local Features</h2><ul><li>이미지에 중요한 부분</li><li>Image representation</li><li>Object appearance modeling</li><li>Finding matches between multiple views</li></ul><h2 id="Model-Fitting-and-RANSAC"><a href="#Model-Fitting-and-RANSAC" class="headerlink" title="Model Fitting and RANSAC"></a>Model Fitting and RANSAC</h2><ul><li>Finding vanishing points</li><li>Image stitching</li><li>3D object recognition</li><li>Fitting Technique: Least Square</li><li>RANSAC</li><li>Fitting Technique: Hough Transform</li></ul><h2 id="Geometric-Transformations"><a href="#Geometric-Transformations" class="headerlink" title="Geometric Transformations"></a>Geometric Transformations</h2><ul><li>Understanding camera models</li><li>2D transformations<ul><li>Translations</li><li>Euclidean transformation</li><li>Similarity transformation</li><li>Affine transformation</li><li>Projective transformation</li></ul></li><li>3D Geometric Primitives<ul><li>points, lines, planes</li><li>3D Transformations</li><li>3D to 2D Projections</li></ul></li><li>Camera Models<ul><li>Camera<ul><li>사람의 눈에 대응되는 컴퓨터의 눈</li></ul></li><li>Geometric Camera Models<ul><li>Pinhole Model<ul><li>Aperture shrinks to zero</li><li>Inverted image is observed in image plane</li></ul></li></ul></li></ul></li></ul><h2 id="Camera-Calibration"><a href="#Camera-Calibration" class="headerlink" title="Camera Calibration"></a>Camera Calibration</h2><ul><li>Geometric camera calibra:on</li><li>Camera Matrix Estimation<ul><li>size and structure of the pattern are known</li></ul></li><li>Estimation of Intrinsic and Extrinsic Parameters</li></ul><h2 id="Two-View-Geometry"><a href="#Two-View-Geometry" class="headerlink" title="Two-View Geometry"></a>Two-View Geometry</h2><ul><li>2장의 이미지에서 대응 되는 기하학적 관계</li><li>Homography<ul><li>collinearity is preserved</li><li>Isotropic scaling transform</li></ul></li><li>Image Panorama Using Estimation</li></ul><h2 id="Epipolar-Geometry"><a href="#Epipolar-Geometry" class="headerlink" title="Epipolar Geometry"></a>Epipolar Geometry</h2><ul><li>epipolar<ul><li>두개의 이미지에서 대응되는 점들의 직선</li></ul></li><li>converging image planes</li><li>parallel image planes</li><li>forward moving camera</li><li>Two-View Relationship in Epipolar Geometry<ul><li>essential matrix</li><li>Fundamental Matrix<ul><li>8-point algorithm</li></ul></li></ul></li></ul><h2 id="Stereo-Matching"><a href="#Stereo-Matching" class="headerlink" title="Stereo Matching"></a>Stereo Matching</h2><ul><li>두개의 센서로 부터 인지한 정보</li><li>Parallel images</li><li>Image Rectification<ul><li>같은 선상에 이미지를 정렬</li><li>Epipolar lines을 직선이 되도록 배치</li></ul></li><li>Basic Stereo Matching<ul><li>epipolar line</li><li>depth vs disparity</li><li>비워있으면 더 진하게 나옴</li></ul></li><li>Correspondence Search</li><li>Correspondence Search by Correlation</li><li>반복적인 패턴</li><li>small diparity error</li><li>window size effect</li></ul><h2 id="Wide-Baseline-Matching"><a href="#Wide-Baseline-Matching" class="headerlink" title="Wide-Baseline Matching"></a>Wide-Baseline Matching</h2><ul><li>Large baseline</li><li>KeyNet<ul><li>detection 에 집중함</li><li>Multi-Scale Index Proposal (M-SIP) Loss.</li></ul></li><li>Self-Supervised Equivariant Learning for Oriented Keypoint Detection<ul><li>Rotation-Equivariant Feature</li><li>Window-based keypoint loss</li><li>Dense orientation alignment loss</li></ul></li></ul><h1 id="참조"><a href="#참조" class="headerlink" title="참조"></a>참조</h1><hr>]]></content:encoded>
      
      <comments>https://sejoung.github.io/2024/02/2024-02-28-Multiview_geometry/#disqus_thread</comments>
    </item>
    
    <item>
      <title>CHAPTER 5 리팩터링 기법</title>
      <link>https://sejoung.github.io/2024/02/2024-02-28-design_patterns_beauty_5/</link>
      <guid>https://sejoung.github.io/2024/02/2024-02-28-design_patterns_beauty_5/</guid>
      <pubDate>Wed, 28 Feb 2024 01:18:00 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;CHAPTER-5-리팩터링-기법&quot;&gt;&lt;a href=&quot;#CHAPTER-5-리팩터링-기법&quot; class=&quot;headerlink&quot; title=&quot;CHAPTER 5 리팩터링 기법&quot;&gt;&lt;/a&gt;CHAPTER 5 리팩터링 기법&lt;/h1&gt;&lt;h2 id=&quot;5-1-리
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="CHAPTER-5-리팩터링-기법"><a href="#CHAPTER-5-리팩터링-기법" class="headerlink" title="CHAPTER 5 리팩터링 기법"></a>CHAPTER 5 리팩터링 기법</h1><h2 id="5-1-리팩터링의-네-가지-요소-목적-대상-시기-방법"><a href="#5-1-리팩터링의-네-가지-요소-목적-대상-시기-방법" class="headerlink" title="5.1 리팩터링의 네 가지 요소: 목적, 대상, 시기, 방법"></a>5.1 리팩터링의 네 가지 요소: 목적, 대상, 시기, 방법</h2><h3 id="5-1-1-리팩터링의-목적"><a href="#5-1-1-리팩터링의-목적" class="headerlink" title="5.1.1 리팩터링의 목적"></a>5.1.1 리팩터링의 목적</h3><p>코드에 대한 이해를 쉽게 하기 위해 소프트웨어의 내부 구조를 개선하는 것으로<br>소프트웨어의 외부 동작을 변경하지 않고 수정 비용을 줄이는 것을 목적으로 한다</p><p>고품질 코드는 훌륭한 설계 한 번에 나오는 것이 아니라 반복적인 작업의 결과로 나오는 것이다</p><h3 id="5-1-2-리팩터링의-대상"><a href="#5-1-2-리팩터링의-대상" class="headerlink" title="5.1.2 리팩터링의 대상"></a>5.1.2 리팩터링의 대상</h3><p>리팩터링의 종류</p><ul><li>대규모 리팩터링 : 시스템, 모듈, 코드 구조, 클래스 간 관계의 리팩터링을 포함하여 최상위 설계를 리팩터링하는 것</li><li>소규모 리팩터링 : 표준 명명, 표준 주석, 초대형 클래스와 함수 제거, 중복코드 추출, 같이 주로 클래스, 함수, 변수 수준에서 코드 세부 정보를 리팩터링하는 것을 말한다</li></ul><h3 id="5-1-3-리팩터링의-시기"><a href="#5-1-3-리팩터링의-시기" class="headerlink" title="5.1.3 리팩터링의 시기"></a>5.1.3 리팩터링의 시기</h3><p>코드가 망가지고 한꺼번에 해결하려는 수단으로 리팩터링은 옳지 않다</p><p>지속가능하고 진화적인 리팩터링 계획을 탐구 해야 된다 - 지속적인 리팩터링</p><h3 id="5-1-4-리팩터링의-방법"><a href="#5-1-4-리팩터링의-방법" class="headerlink" title="5.1.4 리팩터링의 방법"></a>5.1.4 리팩터링의 방법</h3><p>대규모 리팩터링 일때</p><ul><li>사전에 종합적인 리팩터링 계획을 수립해, 질서 있고 단계적으로 진행해야 한다</li></ul><p>소규모 리팩터링 일때</p><ul><li>시간 있을 때마다 소규모 리팩터링을 할수 있다</li></ul><h2 id="5-2-단위-테스트"><a href="#5-2-단위-테스트" class="headerlink" title="5.2 단위 테스트"></a>5.2 단위 테스트</h2><p>잘못된 리팩터링을 방지하는 방법?</p><ul><li>단위테스트로 할수 있지 않을까?</li></ul><h3 id="5-2-1-단위-테스트에-대해"><a href="#5-2-1-단위-테스트에-대해" class="headerlink" title="5.2.1 단위 테스트에 대해"></a>5.2.1 단위 테스트에 대해</h3><p>단위 테스트는 코드의 정확성을 테스트하기 위한 것이지만, 테스트 엔지니어가 아닌 개발 엔지니어가 작성하는 것이며 통합 테스트 보단 작다</p><ul><li>테스트 포괄성을 보장하기 위해 테스트 케이스 설계</li><li>코드로 변환</li></ul><h3 id="5-2-2-단위-테스트-코드를-작성하는-이유"><a href="#5-2-2-단위-테스트-코드를-작성하는-이유" class="headerlink" title="5.2.2 단위 테스트 코드를 작성하는 이유"></a>5.2.2 단위 테스트 코드를 작성하는 이유</h3><ul><li>프로그래머가 코드에서 버그를 찾는 데 도움이 될 수 있다</li><li>프로그래머가 코드 설계에서 문제를 찾는데 도움이 될 수 있다</li><li>통합 테스트를 보완하는 강력한도구다</li><li>단위 테스트 코드를 작성하는 과정은 코드 리팩터링 과정에 해당한다</li><li>단위 테스트는 프로그래머가 코드에 빠르게 익숙해지도록 도와준다</li><li>단위 테스트는 테스트 주도 개발을 개선하고 대체할 수 있다<h3 id="5-2-3-단위-테스트를-설계하는-방법"><a href="#5-2-3-단위-테스트를-설계하는-방법" class="headerlink" title="5.2.3 단위 테스트를 설계하는 방법"></a>5.2.3 단위 테스트를 설계하는 방법</h3></li><li>단위 테스트를 설계하는 것은 시간이 많이 걸리는 일인가?</li><li>단위 테스트 코드의 품질에 대한 요구 사항이 있는가?</li><li>단위 테스트의 커버리지가 높으면 그것만으로 충분한가?</li><li>단위 테스트 코드를 작성할 떄 코드의 구현 논리를 이해하는 것이 필요한가?</li><li>단위 테스트 프레임워크를 선택하는 방법은 무엇인가?<h3 id="5-2-4-단위-테스트를-작성하기-어려운-이유"><a href="#5-2-4-단위-테스트를-작성하기-어려운-이유" class="headerlink" title="5.2.4 단위 테스트를 작성하기 어려운 이유"></a>5.2.4 단위 테스트를 작성하기 어려운 이유</h3></li><li>단위 테스트 코드의 작성은 사실 인내심을 테스트하는 일이기도 하다</li><li>리더의 의지와 감독만으로는 불가능한 일이며 팀원들에게 코드에 대한 강한 주인의식이 있어야 가능하다</li><li>테스트 팀이 별도로 있기 때문에</li></ul><h2 id="5-3-코드-테스트-용이성"><a href="#5-3-코드-테스트-용이성" class="headerlink" title="5.3 코드 테스트 용이성"></a>5.3 코드 테스트 용이성</h2><h3 id="5-3-1-테스트-가능한-코드를-작성하는-방법"><a href="#5-3-1-테스트-가능한-코드를-작성하는-방법" class="headerlink" title="5.3.1 테스트 가능한 코드를 작성하는 방법"></a>5.3.1 테스트 가능한 코드를 작성하는 방법</h3><ul><li>클래스의 독립성 - 해당 클래스가 높은 응집도와 낮은 결합도를 만족하는지에 달려 있다</li></ul><h3 id="5-3-2-테스트가-불가능한-코드"><a href="#5-3-2-테스트가-불가능한-코드" class="headerlink" title="5.3.2 테스트가 불가능한 코드"></a>5.3.2 테스트가 불가능한 코드</h3><ul><li>보류 중인 동작</li><li>전역 변수</li><li>정적 메서드</li><li>복잡한 상속 관계</li></ul><h2 id="5-4-디커플링"><a href="#5-4-디커플링" class="headerlink" title="5.4 디커플링"></a>5.4 디커플링</h2><p>대규모 리팩터링의 주 목적은 디커플링이다</p><h3 id="5-4-1-디커플링이-중요한-이유"><a href="#5-4-1-디커플링이-중요한-이유" class="headerlink" title="5.4.1 디커플링이 중요한 이유"></a>5.4.1 디커플링이 중요한 이유</h3><p>코드의 복잡성을 제어하는 방법은 매우 많지만 그중에서 가장 효과적인 방법이 디커플링이다</p><p>높은 응집도와 낮은 결합도를 가진 코드의 특징</p><ul><li>코드 구조가 명확</li><li>계층화와 모듈화가 합리적 </li><li>의존성이 간단</li><li>모듈이나 클래스 사이의 결합도가 낮다</li></ul><h3 id="5-4-2-코드를-디커플링해야-하는지-판단하기"><a href="#5-4-2-코드를-디커플링해야-하는지-판단하기" class="headerlink" title="5.4.2 코드를 디커플링해야 하는지 판단하기"></a>5.4.2 코드를 디커플링해야 하는지 판단하기</h3><ul><li>기능 코드이 일부가 수정되면 전체 코드를 모두 건드려야 하는 상황을 발생한다는것</li><li>의존성 그래프의 복잡성에 따라 프로젝트의 코드를 분리해야 하는지 판단</li></ul><h3 id="5-4-3-코드-디커플링-방법"><a href="#5-4-3-코드-디커플링-방법" class="headerlink" title="5.4.3 코드 디커플링 방법"></a>5.4.3 코드 디커플링 방법</h3><ul><li>캡슐화와 추상화로 디커플링하기</li><li>중간 계층으로 디커플링하기</li><li>모듈화 계층화로 디커플링하기</li><li>고전적인 코드 설계 원칙과 사상을 이용한 디커플링<ul><li>단일 책임 원칙</li><li>구현이 아닌 인터페이스 기반의 프로그래밍</li><li>의존성 주입</li><li>상속보다는 합성을 더 많이 사용</li><li>디미터의 법칙을 따르는것</li></ul></li></ul><h1 id="참조"><a href="#참조" class="headerlink" title="참조"></a>참조</h1><hr><ul><li><a href="https://www.yes24.com/Product/Goods/118859035">디자인 패턴의 아름다움</a></li></ul>]]></content:encoded>
      
      <comments>https://sejoung.github.io/2024/02/2024-02-28-design_patterns_beauty_5/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Video</title>
      <link>https://sejoung.github.io/2024/02/2024-02-27-Video/</link>
      <guid>https://sejoung.github.io/2024/02/2024-02-27-Video/</guid>
      <pubDate>Tue, 27 Feb 2024 05:50:00 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;Video&quot;&gt;&lt;a href=&quot;#Video&quot; class=&quot;headerlink&quot; title=&quot;Video&quot;&gt;&lt;/a&gt;Video&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;Optical Flow&lt;ul&gt;
&lt;li&gt;pixel correspondences problem&lt;/
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Video"><a href="#Video" class="headerlink" title="Video"></a>Video</h1><ul><li>Optical Flow<ul><li>pixel correspondences problem</li><li>using local window</li><li>Lucas-Kanade flow</li><li>FlowNet<ul><li>CNN은 classification 분야에서 성공적이였으나, optical flow estimation에서는 적용된 사례가 없었음</li><li>End-to-end optical flow estimation CNN 구조와 학습방법 제안</li><li>Two Architectures (FlowNet-C, FlowNet-S)</li></ul></li><li>FlowNet2<ul><li>FlowNet을 faster and more accurate하게 하자</li></ul></li><li>PWC-Net<ul><li>Feature pyramid 와 warping, Correlation volme 을 활용한 optical flow estimation</li><li>Compare but effective CNN for optical flow</li><li>Pyramidal features의 사용</li></ul></li><li>RAFT<ul><li>All-pairs correlation volume 계산과, recurrent optical flow update</li><li>Multi-scale 3D correla)on volumes 을 만든다</li><li>Correlation volum을 전체 pixel에 대해 다 만듬</li></ul></li></ul></li></ul><h2 id="Video-Recognition-with-Sparse-Points"><a href="#Video-Recognition-with-Sparse-Points" class="headerlink" title="Video Recognition with Sparse Points"></a>Video Recognition with Sparse Points</h2><ul><li>Video Recognition with Space-Time Interest Points<ul><li>Space-time interest point (STIP)<ul><li>STIP detector</li><li>Corner point in a spatio-temporal domain</li><li>Bag of visual words</li></ul></li></ul></li></ul><h2 id="Video-Recognition-with-Dense-Trajectory-Descriptors"><a href="#Video-Recognition-with-Dense-Trajectory-Descriptors" class="headerlink" title="Video Recognition with Dense Trajectory Descriptors"></a>Video Recognition with Dense Trajectory Descriptors</h2><ul><li>Dense Trajectory<ul><li>Sparse -&gt; Dense</li><li>Point -&gt; Trajectory</li><li>Trajectory extraction</li></ul></li></ul><h2 id="Video-Recognition-with-3D-CNN"><a href="#Video-Recognition-with-3D-CNN" class="headerlink" title="Video Recognition with 3D CNN"></a>Video Recognition with 3D CNN</h2><ul><li>3D Convolutional Neural Network</li><li>C3D<ul><li>A modern 3D CNN architecture </li><li>VGGNet style network</li></ul></li><li>Visual Information Fusion Across Time<ul><li>A video &#x3D; A bag of short fixed-sized clips</li></ul></li><li>Time Information Fusion<ul><li>early fusion</li><li>late fusion</li><li>slow fusion</li></ul></li><li>Explicit Motion Estimation and Utilization<ul><li>Two-Stream Convolutional Network<ul><li>spatial stream<ul><li>ImageNet pretrained network, whose architecture is similar to ZFNet</li></ul></li><li>temporal stream<ul><li>Multi-task learning</li></ul></li></ul></li></ul></li></ul><h2 id="Video-Understanding-Modern-Approaches"><a href="#Video-Understanding-Modern-Approaches" class="headerlink" title="Video Understanding: Modern Approaches"></a>Video Understanding: Modern Approaches</h2><ul><li><p>Video Representation Learning</p></li><li><p>SlowFast Networks</p><ul><li>Low frame rate branch와 high frame rate branch를 나누어서 action recognition</li><li>Time axis 에 대한 탐구</li><li>Slow pathway</li><li>Fast pathway</li></ul></li><li><p>MoViNet</p><ul><li>Video를 좀 더 efficient하게 처리하기 위한 구조 탐구.</li><li>Video recognition에서의 efficientNet (ICML 2019) 와 같은 논문</li></ul></li><li><p>MaskFeat</p><ul><li>ransformer 와 self-supervised representation learning 을 통한 video recognition 의 최신 기법</li><li>Action recognition 을 위한 representation learning을 할 때 꼭 temporal sequence 가 필요할까?</li><li>Pretext task로 masked input으로 HOG를 prediction 해보자</li><li>HOG 는 이미지의 pixel intensity 등의 정보를 없애서 motion 그 자체의 학습에 좀 더 집중하게 도움을 줌</li></ul></li><li><p>Self-supervised learning 기반의 representation learning 방식이 video recognition 쪽에서 현재 가장 잘 동작한다. (MaskFeat)</p></li><li><p>Transformer architecture를 활용한 구조.</p></li><li><p>Video 를 이해하는 데에 꼭 sequential 한 information 이 필요하지 않을 수 있다</p></li><li><p>Single key frame 으로도 일부의 action 정보 학습&#x2F;파악 가능</p></li></ul><h2 id="Visual-Object-Tracking"><a href="#Visual-Object-Tracking" class="headerlink" title="Visual Object Tracking"></a>Visual Object Tracking</h2><ul><li>MDNet<ul><li>당시 CNN이 높은 성능을 내고 있으나, classification 과 tracking은 다른 문제여서 다르게 적용되어야 한다</li><li>Occlusion, deforma)on, mo)on blur 와 같은 문제를 처리해야함</li><li>같은 targe이여도 동영상&#x2F;배경에 따라 다르게 인식될 수 있음.</li><li>여러 동영상으로부터 target의 domain-independent shared representation 학습</li><li>Domain-specific branch를 두어 서로 다른 도메인 학습</li><li>VOT를 위한 CNN 구조 제안; Domain-independent shared layers &#x2F; Domain- specific branches.</li><li>Offline에서 pre-training되고, online으로 fine-tuning된다</li></ul></li></ul><h1 id="참조"><a href="#참조" class="headerlink" title="참조"></a>참조</h1><hr>]]></content:encoded>
      
      <comments>https://sejoung.github.io/2024/02/2024-02-27-Video/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Object Detection &amp; Segmentation 2</title>
      <link>https://sejoung.github.io/2024/02/2024-02-27-Object_Detection_Segmentation_2/</link>
      <guid>https://sejoung.github.io/2024/02/2024-02-27-Object_Detection_Segmentation_2/</guid>
      <pubDate>Tue, 27 Feb 2024 04:18:00 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;Object-Detection-amp-Segmentation-2&quot;&gt;&lt;a href=&quot;#Object-Detection-amp-Segmentation-2&quot; class=&quot;headerlink&quot; title=&quot;Object Detection &amp;amp;
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Object-Detection-amp-Segmentation-2"><a href="#Object-Detection-amp-Segmentation-2" class="headerlink" title="Object Detection &amp; Segmentation 2"></a>Object Detection &amp; Segmentation 2</h1><h2 id="Additional-Object-Detection-Techniques"><a href="#Additional-Object-Detection-Techniques" class="headerlink" title="Additional Object Detection Techniques"></a>Additional Object Detection Techniques</h2><ul><li>Feature Pyramid Netowrk (FPN)<ul><li>충분히 빠르다</li><li>다양한 크기의 물체를 잘 찾아낸다</li><li>scale robustness 는 object detection에 중요하다.</li><li>Image pyramid 를 만드는 것보다 feature pyramid 를 만드는 것이 효과적이다</li><li>post-work: PANet (Path-aggregation network) – top-down-top을 활용한다</li></ul></li><li>Path Aggregation Network (PANet)<ul><li>top-down path의 FPN에서 bottom-up path를 추가하여 object detectio 에서의 scale robustness를 키운다</li><li>bottom-up connection 이 이미지의 더 좋은 features 생성에 도움이 된다.</li></ul></li><li>EfficientDet: Effcient Model Search<ul><li>EfficientNet 과 비슷한 모델 서치</li><li>BiFPN 구조를 채택하여, top-down, bottom-up 정보의 propagation을 한다</li><li>더 낮은 리소스로 더 좋은 결과를 낸다.</li></ul></li><li>DeTR: Detection Transformer<ul><li>Vision Transformer for Object Detection</li><li>CNN이 아닌 Transformer 구조를 사용해서 object detection 을 해보자</li></ul></li><li>Deformable DETR<ul><li>Deformable Convolution에서 아이디어를 얻 어 transformer 구조에 적용</li><li>마찬가지로 conv filter의 offset을 deformable DETER에서는 encoder 내의 attention 입력인 Key의 offset으로 대체하여 사용한다.</li></ul></li></ul><h2 id="Semantic-Segmentation"><a href="#Semantic-Segmentation" class="headerlink" title="Semantic Segmentation"></a>Semantic Segmentation</h2><ul><li><p>같은 클래스내에 있으면 동일한 영역이라고 본다</p></li><li><p>Fully Convolutional Network (FCN)</p><ul><li>이미지의 모든 픽셀에 대해 클래스를 예측</li><li>1x1 convolution을 사용하여, fully connected layer를 대체</li><li>add skip connection</li></ul></li><li><p>DeepLab</p><ul><li>atrous convolution을 사용하여, receptive field를 키움</li><li>fully connected conditional random field (CRF)를 사용하여, segmentation 결과를 더 정확하게 만듬</li><li>atrous spatial pyramid pooling (ASPP)를 사용하여, 다양한 크기의 receptive field를 사용</li></ul></li><li><p>Deconvolution Nework (DeconvNet)</p><ul><li>cpmvolutional layer를 거꾸로 쌓아서, segmentation을 수행</li><li>pooling layer에서의 위치 정보를 복원하기 위해, unpooling layer를 사용</li><li>deconvolution layer를 사용하여, segmentation 결과를 얻음</li></ul></li><li><p>U-Net</p></li><li><p>Instance-Aware Semantic Segmentation</p><ul><li>objectness를 캡쳐 할수 없다</li><li>Multi-scale features를 사용하여, objectness를 캡쳐</li><li>Multi-task Network Cascades<ul><li>cascade를 사용하여, segmentation과 classification을 동시에 수행</li><li>single network 사용</li></ul></li><li>Mask R-CNN<ul><li>instance segmentation을 수행</li><li>Faster R-CNN을 사용하여, object detection을 수행</li><li>RoIAlign을 사용하여, RoI pooling을 대체</li></ul></li></ul></li><li><p>Improving Semantic Segmentation</p><ul><li>Pyramid Scene Parsing Network</li><li>Context Encoding Network<ul><li>se loss를 사용하여, context 정보를 사용</li></ul></li><li>Dual Super-Resolution Learning<ul><li>image super-resolution과 semantic segmentation을 동시에 수행</li><li>sub-pixel convnet을 사용하여, segmentation 결과를 얻음</li></ul></li><li>Segmenter<ul><li>A fully Transformer-based encoder-decoder architecture</li></ul></li></ul></li></ul><h1 id="참조"><a href="#참조" class="headerlink" title="참조"></a>참조</h1><hr>]]></content:encoded>
      
      <comments>https://sejoung.github.io/2024/02/2024-02-27-Object_Detection_Segmentation_2/#disqus_thread</comments>
    </item>
    
    <item>
      <title>CHAPTER 4 코딩 규칙</title>
      <link>https://sejoung.github.io/2024/02/2024-02-27-design_patterns_beauty_4/</link>
      <guid>https://sejoung.github.io/2024/02/2024-02-27-design_patterns_beauty_4/</guid>
      <pubDate>Tue, 27 Feb 2024 00:36:00 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;CHAPTER-4-코딩-규칙&quot;&gt;&lt;a href=&quot;#CHAPTER-4-코딩-규칙&quot; class=&quot;headerlink&quot; title=&quot;CHAPTER 4 코딩 규칙&quot;&gt;&lt;/a&gt;CHAPTER 4 코딩 규칙&lt;/h1&gt;&lt;h2 id=&quot;4-1-명명과-주석&quot;&gt;&lt;
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="CHAPTER-4-코딩-규칙"><a href="#CHAPTER-4-코딩-규칙" class="headerlink" title="CHAPTER 4 코딩 규칙"></a>CHAPTER 4 코딩 규칙</h1><h2 id="4-1-명명과-주석"><a href="#4-1-명명과-주석" class="headerlink" title="4.1 명명과 주석"></a>4.1 명명과 주석</h2><p>명명은 코드 가독성에 큰 영향을 미치며 프로그래머의 기본 능력과 소양을 반영 하기도 한다</p><h3 id="4-1-1-긴-이름과-짧은-이름"><a href="#4-1-1-긴-이름과-짧은-이름" class="headerlink" title="4.1.1 긴 이름과 짧은 이름"></a>4.1.1 긴 이름과 짧은 이름</h3><ul><li>긴 이름 : 가급적 이름이 그 의미를 자세하기 표현하기 원함 그래야 한눈에 설계 의도를 파악할수 있기 때문</li><li>짧은 이름 : 코드가 간결하다</li></ul><p>명명시 일반적인 약어는 사용할수 있지만 약어 사용을 주의 해야 된다.<br>함수의 임시 변수와 같이 사용 범위가 비교적 작은 변수의 경우 짧은 이름을 사용할수 있다.</p><h3 id="4-1-2-문맥-정보를-사용한-명명-단순화"><a href="#4-1-2-문맥-정보를-사용한-명명-단순화" class="headerlink" title="4.1.2 문맥 정보를 사용한 명명 단순화"></a>4.1.2 문맥 정보를 사용한 명명 단순화</h3><p>객체의 콘텍스트 정보를 통해 명확하게 표현할수 있다<br>함수의 콘텍스트 정보를 통해 매개 변수의 이름도 단순화 할수 있다</p><h3 id="4-1-3-비즈니스-용어집을-사용한-명명-통일"><a href="#4-1-3-비즈니스-용어집을-사용한-명명-통일" class="headerlink" title="4.1.3 비즈니스 용어집을 사용한 명명 통일"></a>4.1.3 비즈니스 용어집을 사용한 명명 통일</h3><p>영어의 이해수준이 틀려서 동일한 비즈니스 용어의 번역이 다를수 있고 그 결과 코드의 가독성이 떨어진다<br>통일된 용어집을 준비해두면 이문제를 해결할수 있다 특히 긴 단어에 대해서 통일된 약어를 지정할수 있다</p><h3 id="4-1-4-명명은-정확하지만-추상적이어야-한다"><a href="#4-1-4-명명은-정확하지만-추상적이어야-한다" class="headerlink" title="4.1.4 명명은 정확하지만 추상적이어야 한다"></a>4.1.4 명명은 정확하지만 추상적이어야 한다</h3><p>명명은 정확하지만 추상적인 특성도 고려해야 클래스, 함수 등을 수정하더라도 이름을 매번 변경할 필요가 없다</p><h3 id="4-1-5-주석에-반드시-포함되어야-하는-것들"><a href="#4-1-5-주석에-반드시-포함되어야-하는-것들" class="headerlink" title="4.1.5 주석에 반드시 포함되어야 하는 것들"></a>4.1.5 주석에 반드시 포함되어야 하는 것들</h3><p>일부 프로그래머는 좋은 명명이 주석을 완전히 대체할 수 있으며, 만약 코드에 주석이 필요하면 명명이 충분히 적합하지 않다는 뜻 이러한 견해는 매우 편향적일수 있다</p><p>명명을 아무리 잘해도 결국 길이 제한이 있을 뿐만 아니라 모든 것을 담을 수 없다<br>주석은 매우 좋은 보충 설명이 될수 있다<br>주석은 주로 무엇 what을 하는지, 왜 why를 하는지, 어떻게 how를 하는지에 대한 정보를 담고 있다</p><ul><li>주석에는 이름 보다 훨씬 더 많은 정보를 담을수 있다</li><li>주석은 설명과 시연의 역활을 한다</li><li>요약 주석은 코드의 논리를 더 명확하게 할 수 있다</li></ul><h3 id="4-1-6-주석이-많다고-좋은-것은-아니다"><a href="#4-1-6-주석이-많다고-좋은-것은-아니다" class="headerlink" title="4.1.6 주석이 많다고 좋은 것은 아니다"></a>4.1.6 주석이 많다고 좋은 것은 아니다</h3><p>클래스, 함수, 멤버 변수에 대해서는 자세한 주석을 작성하는 것이 필요하지만<br>지역 변수와 같은 함수 내부의 코드나 함수 내부의 각 명령문에 대해서는 가능한 주석을 줄이고 좋은 명명, 기능 분활, 설명 변수로 대체할수 있다</p><h2 id="4-2-코드-스타일"><a href="#4-2-코드-스타일" class="headerlink" title="4.2 코드 스타일"></a>4.2 코드 스타일</h2><p>중요한건 팀이나 프로젝트 전체에서 코드 스타일을 일관되게 유지하는 것이다.<br>이렇게 하면 코드를 읽을 때 다른 스타일로 인해 발생하는 간섭을 줄일 수 있다</p><h3 id="4-2-1-클래스-함수의-적절한-크기"><a href="#4-2-1-클래스-함수의-적절한-크기" class="headerlink" title="4.2.1 클래스, 함수의 적절한 크기"></a>4.2.1 클래스, 함수의 적절한 크기</h3><p>클래스나 함수의 코드 줄 수는 너무 많아도 안 되며, 너무 적어도 안된다.<br>하지만 클래스나 함수의 크기가 몇 줄이어야 하는 지 명확한 수치는 없다</p><p>일부 프로그래머는 함수의 크기가 디스플레이가 한 번에 표시할수 있는 줄 수를 넘어서는 안된다고 생각한다<br>그렇지 않으면 함수의 내용을 파악하기 위해 계속 화면을 스크롤해야 하며, 이는 좋은 코드 리드 경험이라고 할 수 없다</p><h3 id="4-2-2-한-줄의-적절한-길이"><a href="#4-2-2-한-줄의-적절한-길이" class="headerlink" title="4.2.2 한 줄의 적절한 길이"></a>4.2.2 한 줄의 적절한 길이</h3><p>코드의 줄의 길이와 관련하여 가급적 IDE의 표시 너비를 초과해서는 안된다는 규칙을 따를 수 있다<br>이렇게 하면 코드를 읽을 때 화면을 스크롤할 필요가 없어진다<br>하지만 너무 짧아도 하나의 문장이 두 개 이상의 라인으로 분활되기 때문에 오히려 가독성이 떨어지는 경우가 생긴다</p><h3 id="4-2-3-빈-줄을-활용한-코드-블록-구분"><a href="#4-2-3-빈-줄을-활용한-코드-블록-구분" class="headerlink" title="4.2.3 빈 줄을 활용한 코드 블록 구분"></a>4.2.3 빈 줄을 활용한 코드 블록 구분</h3><p>코드 블록을 별도의 함수로 분리하기 불편한 경우 코드의 논리를 명확하게 하기위해서 빈 줄을 사용하여 코드 블록을 구분할 수도 있다</p><h3 id="4-2-4-4칸-들여쓰기-혹은-2칸-들여쓰기"><a href="#4-2-4-4칸-들여쓰기-혹은-2칸-들여쓰기" class="headerlink" title="4.2.4 4칸 들여쓰기 혹은 2칸 들여쓰기"></a>4.2.4 4칸 들여쓰기 혹은 2칸 들여쓰기</h3><p>공간을 절약하기 위해 2칸<br>4칸은 코드의 중첩이 늘어나면 누적된 들여쓰기로 인해 문장이 두줄 이상 분리될 확일이 높아져서 가독성에 영향을 미친다</p><p>들여쓰기에 tab을 사용하면 안된다 표시되는 너비가 틀려 가독성에 좋지 않다</p><h3 id="4-2-5-여는-중괄호는-어디에-놓여야-할까"><a href="#4-2-5-여는-중괄호는-어디에-놓여야-할까" class="headerlink" title="4.2.5 여는 중괄호는 어디에 놓여야 할까"></a>4.2.5 여는 중괄호는 어디에 놓여야 할까</h3><p>새로운 줄에서 여는 중괄호와 닫는 중괄호가 정렬되 코드 구조가 훨씬 명확해진다</p><p>앞줄에서 이어지는 중괄호는 공간이 줄어드는 장점 하지만 코드가 너무 붙어서 가독성이 떨어질수도 있다 </p><h3 id="4-2-6-클래스의-멤버-순서"><a href="#4-2-6-클래스의-멤버-순서" class="headerlink" title="4.2.6 클래스의 멤버 순서"></a>4.2.6 클래스의 멤버 순서</h3><p>클래스에서 멤버 변수는 일반적으로 함수 앞에 놓는다<br>멤버 변수사이, 함수 사이의 관계는 먼저 정적 멤버 변수 도는 정적함수가 놓이고 뒤에 비정적 멤버 변수와 비정정함수가 놓인다</p><p>멤버 변수와 함수 범위는 내림차순으로 정렬되므로, 먼저 public, protected, private 순으로 정렬된다</p><h2 id="4-3-코딩-팁"><a href="#4-3-코딩-팁" class="headerlink" title="4.3 코딩 팁"></a>4.3 코딩 팁</h2><h3 id="4-3-1-복잡한-코드의-모듈화"><a href="#4-3-1-복잡한-코드의-모듈화" class="headerlink" title="4.3.1 복잡한 코드의 모듈화"></a>4.3.1 복잡한 코드의 모듈화</h3><p>커다른 블록을 클래스나 함수로 캡슐화 하는데 능숙해져야 된다</p><h3 id="4-3-2-함수의-매개변수-관리"><a href="#4-3-2-함수의-매개변수-관리" class="headerlink" title="4.3.2 함수의 매개변수 관리"></a>4.3.2 함수의 매개변수 관리</h3><p>함수의 매개변수가 너무 많으면 함수를 읽거나 사용하는 것이 불편해진다<br>매개변수가 5개를 넘어가면 너무 많다고 할수 있다</p><ul><li>함수를 호출할때 함수 호출문이 길어저 가독성이 떨어진다</li><li>매개변수가 너무 많으면 단일 책임원칙을 지키지 않았었을 가능성이 높다</li></ul><h3 id="4-3-3-함수의-플래그-매개변수-제거"><a href="#4-3-3-함수의-플래그-매개변수-제거" class="headerlink" title="4.3.3 함수의 플래그 매개변수 제거"></a>4.3.3 함수의 플래그 매개변수 제거</h3><p>플래그 매개변수는 함수의 기능을 분기하는데 사용되는 매개변수이다</p><ul><li>단일 책임원칙과 인터페이스 분리원칙을 위반한다</li></ul><h3 id="4-3-4-깊은-중첩-코드-제거"><a href="#4-3-4-깊은-중첩-코드-제거" class="headerlink" title="4.3.4 깊은 중첩 코드 제거"></a>4.3.4 깊은 중첩 코드 제거</h3><ul><li>중복되는 if, else문을 제거</li><li>continue, break문, return문을 사용하여 중첩을 바로 종료한다</li><li>실행 순서를 조정하여 중첩 단계를 줄인다</li><li>중첩 단계를 줄이기 위해 코드의 일부를 함수로 캡슐화한다</li></ul><h3 id="4-3-5-설명-변수"><a href="#4-3-5-설명-변수" class="headerlink" title="4.3.5 설명 변수"></a>4.3.5 설명 변수</h3><ul><li>매직 넘버 대신 상수를 사용한다</li><li>설명 변수를 사용하여 복잡한 표현을 설명한다</li></ul><h1 id="참조"><a href="#참조" class="headerlink" title="참조"></a>참조</h1><hr><ul><li><a href="https://www.yes24.com/Product/Goods/118859035">디자인 패턴의 아름다움</a></li></ul>]]></content:encoded>
      
      <comments>https://sejoung.github.io/2024/02/2024-02-27-design_patterns_beauty_4/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Object Detection &amp; Segmentation 1</title>
      <link>https://sejoung.github.io/2024/02/2024-02-26-Object_Detection_Segmentation/</link>
      <guid>https://sejoung.github.io/2024/02/2024-02-26-Object_Detection_Segmentation/</guid>
      <pubDate>Mon, 26 Feb 2024 04:33:00 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;Object-Detection-amp-Segmentation-1&quot;&gt;&lt;a href=&quot;#Object-Detection-amp-Segmentation-1&quot; class=&quot;headerlink&quot; title=&quot;Object Detection &amp;amp;
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Object-Detection-amp-Segmentation-1"><a href="#Object-Detection-amp-Segmentation-1" class="headerlink" title="Object Detection &amp; Segmentation 1"></a>Object Detection &amp; Segmentation 1</h1><ul><li>Object Detection : 이미지 내에서 특정 객체의 위치를 찾아내는 것</li><li>Segmentation : 이미지 내에서 특정 객체의 픽셀을 찾아내는 것</li></ul><p>Object Detection &#x3D; Box localization + Box classification</p><h2 id="Region-based-CNN-RCNN"><a href="#Region-based-CNN-RCNN" class="headerlink" title="Region-based CNN* (RCNN)"></a>Region-based CNN* (RCNN)</h2><ul><li>bounding box의 transformation를 학습</li></ul><h2 id="Faster-R-CNN-with-ResNet"><a href="#Faster-R-CNN-with-ResNet" class="headerlink" title="Faster R-CNN with ResNet"></a>Faster R-CNN with ResNet</h2><ul><li>R-CNN의 속도를 개선</li></ul><h2 id="Object-Detection-‒-Basic-Concepts"><a href="#Object-Detection-‒-Basic-Concepts" class="headerlink" title="Object Detection ‒ Basic Concepts"></a>Object Detection ‒ Basic Concepts</h2><ul><li>Object Detection : 이미지 내에서 특정 객체의 위치를 찾아내는 것</li></ul><h2 id="Object-Detection-‒-Classical-Object-Detection"><a href="#Object-Detection-‒-Classical-Object-Detection" class="headerlink" title="Object Detection ‒ Classical Object Detection"></a>Object Detection ‒ Classical Object Detection</h2><ul><li>Support Vector Machine (SVM) : 이미지 내에서 특정 객체의 위치를 찾아내는 것<ul><li>Linear SVM : 선형 분류기</li><li>Non-Linear SVM : 비선형 분류기</li><li>Hyper-Parameters Tuning : cross-validation을 통해 최적의 파라미터를 찾는 것</li><li>Multi-Class SVM : 다중 클래스 분류기<ul><li>one-versus-all</li><li>one-versus-one</li></ul></li></ul></li><li>Histogram of Oriented Gradients (HOG)<ul><li>가우시안 스무딩을 하지 않는다</li><li>이미지를 8x8 크기의 cell로 나눈다</li><li>HOG+SVM for Pedestrian Detection</li></ul></li><li>Selective Search for Object Detection<ul><li>Capture all scales: 물체 크기 랜덤, 경계 불명확 할수 있음</li><li>Diversification: 색상, 재질, 크기 등의 조건을 고려해서 다중 전략을 취함</li><li>Fast to compute: 계산 시 너무 오래 걸리면 안됨</li><li>segment가 있으면 그 영역에 대해 candidate objects로 사용하여 좀 더 쉽게 object detection 을 할 수 있지 않을까?</li><li>Object recogntion이나 detection을 위한 후보 영역 을 알아 낼수 있는 알고리즘</li><li>Mean Average Best Overlap (MABO)</li><li>Recall</li></ul></li><li>EdgeBox for Object Detection<ul><li>Gradient orientation 을 기반으로 edge group을 표현하고, 이를 이용해서 bounding box score를 계산함</li><li>Evaluation metric 제안: Intersection on Union (IoU)</li></ul></li><li>Region-based CNN* (RCNN)<ul><li>2 stage detection</li></ul></li><li>Fast R-CNN<ul><li>ROI pooling</li><li>9 anchor per location</li></ul></li><li>Mask R-CNN<ul><li>instance segmentation</li></ul></li><li>One-Stage Detector<ul><li>regional proposal 와 classification을 동시에 수행 </li><li>YOLO(You Only Look Once)</li><li>YOLO v2<ul><li>better, faster, stronger</li><li>Batch normalization: 모든 conv layer에 BN추가</li><li>High-resolution classifier: ImageNet으로 pre-training하고, 448x448의 해상도로 10 epoch 동안 fine tuning</li><li>Convolutional with anchor boxes: V1에서 FC부분을 conv로 대체. Anchor box 적용</li></ul></li><li>YOLO v3<ul><li>하나의 object에 하나의 anchor box할당</li><li>3가지 다른 scale 사용한 feature pyramid 사용. 3개 scale에 대해 각각 3개 박스를 생성하여 9개의 anchor box가 있음.</li></ul></li><li>YOLO v4<ul><li>Practically, one-stage detector의 개선</li><li>다양한 테크닉을 통해 성능, 속도 향상한다</li><li>저자가 달라졌다</li></ul></li></ul></li></ul><h1 id="참조"><a href="#참조" class="headerlink" title="참조"></a>참조</h1><hr><ul><li><a href="http://www.csie.ntu.edu.tw/~cjlin/libsvm/">LIBSVM</a></li></ul>]]></content:encoded>
      
      <comments>https://sejoung.github.io/2024/02/2024-02-26-Object_Detection_Segmentation/#disqus_thread</comments>
    </item>
    
    <item>
      <title>CHAPTER 3 설계 원칙</title>
      <link>https://sejoung.github.io/2024/02/2024-02-26-design_patterns_beauty_3/</link>
      <guid>https://sejoung.github.io/2024/02/2024-02-26-design_patterns_beauty_3/</guid>
      <pubDate>Mon, 26 Feb 2024 00:30:00 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;CHAPTER-3-설계-원칙&quot;&gt;&lt;a href=&quot;#CHAPTER-3-설계-원칙&quot; class=&quot;headerlink&quot; title=&quot;CHAPTER 3 설계 원칙&quot;&gt;&lt;/a&gt;CHAPTER 3 설계 원칙&lt;/h1&gt;&lt;h2 id=&quot;3-1-단일-책임-원칙&quot;
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="CHAPTER-3-설계-원칙"><a href="#CHAPTER-3-설계-원칙" class="headerlink" title="CHAPTER 3 설계 원칙"></a>CHAPTER 3 설계 원칙</h1><h2 id="3-1-단일-책임-원칙"><a href="#3-1-단일-책임-원칙" class="headerlink" title="3.1 단일 책임 원칙"></a>3.1 단일 책임 원칙</h2><h3 id="3-1-1-단일-책임-원칙의-정의-및-해석"><a href="#3-1-1-단일-책임-원칙의-정의-및-해석" class="headerlink" title="3.1.1 단일 책임 원칙의 정의 및 해석"></a>3.1.1 단일 책임 원칙의 정의 및 해석</h3><p>단일 책임 원칙(single responsibility principle, SRP)은 클래스와 모듈은 하나의 책임 또는 기능만을 가지고 있어야 된다</p><p>주의할 점은 단일 책임 원칙이 설명하는 대상에는 클래스와 모듈이라는 두가지 종류가 있다는 점</p><ul><li>모듈을 클래스보다 더 추상적인 개념으로 간주하고 클래스를 일종의 모듈로 간주하는것</li><li>모듈을 좀 더 포괄적인 범위의 대상으로 놓고 여러 클래스가 하나의 모듈을 구성한다고 간주하는 것</li></ul><h3 id="3-1-2-클래스에-단일-책임이-있는지-판단하는-방법"><a href="#3-1-2-클래스에-단일-책임이-있는지-판단하는-방법" class="headerlink" title="3.1.2 클래스에 단일 책임이 있는지 판단하는 방법"></a>3.1.2 클래스에 단일 책임이 있는지 판단하는 방법</h3><p>동일한 클래스라 할지라도 다른 응용 시나리오나 다른 단계의 요구 사항에 따라 클래스의 책임이 달라질 수 있다.<br>요구 사항이 달라지면 해당 클래스의 설계가 단일 책임 원칙을 충족하지 못할 수 있으므로 계속해서 더 작은 클래스로 분활해야 된다</p><p>단일 책임 여부를 결정하기 위해 사용되는 몇 가지 결정 원칙</p><ul><li>클래스에 코드, 함수 또는 속성이 너무 많아 코드의 가독성과 유지보수성에 영향을 미치는 경우 클래스 분활을 고려해야 된다</li><li>클래스가 너무 과하게 다른 클래스에 의존한다면, 높은 응집도와 낮은 결합도의 코드 설계 사상에 부합하지 않으므로 클래스 분활을 고려해야한다</li><li>클래스에 private 메서드가 너무 많다면 이 private 메서드를 새로운 클래스로 분리하고 더 많은 클래스에서 사용할 수 있도록 public 메서드로 설정하여 코드 재사용성을 높혀야 한다</li><li>클래스의 이름을 비즈니스적으로 정확하게 지정하기 어렵거나 manager, context처럼 일반적인 단어가 아니면 클래스 이름을 정의하기 어려운 경우 클래스 책임 정의가 충분히 명확하지 않음을 의미할수 있다</li><li>클래스의 많은 메서드가 여러속성 중 일부에서만 작동하는 경우 이런 속성과 해당 메서드를 분활하는것을 고려할수 있다</li></ul><h2 id="3-2-개방-폐쇄-원칙"><a href="#3-2-개방-폐쇄-원칙" class="headerlink" title="3.2 개방 폐쇄 원칙"></a>3.2 개방 폐쇄 원칙</h2><p>개방 폐쇄 원칙 (open-closed principle, OCP)</p><ul><li>확장할때는 개방</li><li>수정할때는 폐쇄</li></ul><p>개방 폐쇄 원칙은 확장성이 코드 품질의 중요한 척도이기 때문에 가장 유용하다</p><h3 id="3-2-1-확장할-때는-개방-수정할-때는-폐쇄"><a href="#3-2-1-확장할-때는-개방-수정할-때는-폐쇄" class="headerlink" title="3.2.1 확장할 때는 개방, 수정할 때는 폐쇄"></a>3.2.1 확장할 때는 개방, 수정할 때는 폐쇄</h3><p>모듈, 클래스, 함수와 같은 소프트웨어의 단위들은 확장을 위해 개방되어야 하지만 수정을 위해서는 폐쇄되어야 한다.<br>다시 말해 새로운 기능을 추가할때는 기존의 모듈, 클래스, 함수를 수정하지 보다는<br>기존 코드를 기반으로 모듈, 클래스, 함수등을 추가하는 방식으로 코드를 확장해야 한다</p><h3 id="3-2-2-코드를-수정하는-것은-개방-폐쇄-원칙을-위반하는-것일까"><a href="#3-2-2-코드를-수정하는-것은-개방-폐쇄-원칙을-위반하는-것일까" class="headerlink" title="3.2.2 코드를 수정하는 것은 개방 폐쇄 원칙을 위반하는 것일까?"></a>3.2.2 코드를 수정하는 것은 개방 폐쇄 원칙을 위반하는 것일까?</h3><p>클래스에 새 속성과 메서드를 추가하는 것은 수정에 해당하는가 아니면 확장에 해당하는가?</p><p>코드의 수정이 기존에 작성되었던 코드와 단위 테스트를 깨뜨리지 않는 한 이는 개방 폐쇄 원칙을 위반하지 않는다고 판단해도 무방</p><h3 id="3-2-3-확장할-때는-개방-수정할-때는-폐쇄를-달성하는-방법"><a href="#3-2-3-확장할-때는-개방-수정할-때는-폐쇄를-달성하는-방법" class="headerlink" title="3.2.3 확장할 때는 개방, 수정할 때는 폐쇄를 달성하는 방법"></a>3.2.3 확장할 때는 개방, 수정할 때는 폐쇄를 달성하는 방법</h3><p>확장 가능한 코드를 작성하려면 확장, 추상화, 캡슐화에 대해 인식하고 있는 것이 매우 중요하며<br>이는 개발 기술 자체보다 훨씬 더 중요할 수 있다</p><h3 id="3-2-4-프로젝트에-개방-폐쇄-원칙을-유연하게-적용하는-방법"><a href="#3-2-4-프로젝트에-개방-폐쇄-원칙을-유연하게-적용하는-방법" class="headerlink" title="3.2.4 프로젝트에 개방 폐쇄 원칙을 유연하게 적용하는 방법"></a>3.2.4 프로젝트에 개방 폐쇄 원칙을 유연하게 적용하는 방법</h3><p>단기간 내에 진행할 수 있는 확장, 코드 구조 변경에 미치는 영향이 비교적 큰확장,<br>구현 비용이 많이 들지 않는 확장에 대해 확장 포인트를 미리 준비하는것</p><p>코드의 확장성이 더 중요한 시나리오에는 코드의 가독성을 일부 희생할 필요가 있다</p><h2 id="3-3-리스코프-치환-원칙"><a href="#3-3-리스코프-치환-원칙" class="headerlink" title="3.3 리스코프 치환 원칙"></a>3.3 리스코프 치환 원칙</h2><h3 id="3-3-1-리스코프-치환-원칙의-정의"><a href="#3-3-1-리스코프-치환-원칙의-정의" class="headerlink" title="3.3.1 리스코프 치환 원칙의 정의"></a>3.3.1 리스코프 치환 원칙의 정의</h3><p>1986년에 MIT의 바바라 리스코프 교수에 의해 제안된 원칙<br>만약 S가 T의 하위 타입이라면 프로그램을 중단하지 않고 T 타입의 객체를 S 타입의 객체로 대체할 수 있어야 한다</p><h3 id="3-3-2-리스코프-치환-원칙과-다형성의-차이점"><a href="#3-3-2-리스코프-치환-원칙과-다형성의-차이점" class="headerlink" title="3.3.2 리스코프 치환 원칙과 다형성의 차이점"></a>3.3.2 리스코프 치환 원칙과 다형성의 차이점</h3><p>다형성은 코드를 구현하는 방식에 해당하지만, 리스코프 치환 원칙은 상속 관계에서 하위 클래스의 설계 방식을 설명하는 설계 원칙에 해당한다</p><h3 id="3-3-3-리스코프-치환-원칙을-위반하는-안티-패턴"><a href="#3-3-3-리스코프-치환-원칙을-위반하는-안티-패턴" class="headerlink" title="3.3.3 리스코프 치환 원칙을 위반하는 안티 패턴"></a>3.3.3 리스코프 치환 원칙을 위반하는 안티 패턴</h3><p>리스코프 원칙에는 좀더 이해하기 쉬운 설명 방식이 있는데 바로 계약에 따른 설계라는 표현이다</p><ul><li>하위 클래스가 구현하려는 상위 클래스에서 선언한 기능을 위반하는 경우</li><li>하위 클래스가 입력, 출력 및 예외에 대한 상위 클래스의 계약을 위반하는 경우</li><li>하위 클래스가 상위 클래스의 주석에 나열된 특별 지침을 위반하는 경우</li></ul><h2 id="3-4-인터페이스-분리-원칙"><a href="#3-4-인터페이스-분리-원칙" class="headerlink" title="3.4 인터페이스 분리 원칙"></a>3.4 인터페이스 분리 원칙</h2><p>클라이언트는 필요하지 않은 인터페이스를 사용하도록 강요되어서는 않된다</p><p>인터페이스</p><ul><li>API나 기능의 집합</li><li>단일 API나 기능</li><li>객체지향 프로그래밍에서의 인터페이스</li></ul><h3 id="3-4-1-API나-기능의-집합으로서의-인터페이스"><a href="#3-4-1-API나-기능의-집합으로서의-인터페이스" class="headerlink" title="3.4.1 API나 기능의 집합으로서의 인터페이스"></a>3.4.1 API나 기능의 집합으로서의 인터페이스</h3><p>인터페이스 또는 기능의 일부가 호출자 중 일부에만 사용되거나 전혀 사용되지 않는다면 불필요한 항복을 강요하는 대신<br>인터페이스나 기능에서 해당 부분을 분리하여 해당 호출자에게 별도로 제공해야하며 사용하지 않는 인터페이스나 기능에는 접근하지 못하게 해야 한다</p><h3 id="3-4-2-단일-API나-기능으로서의-인터페이스"><a href="#3-4-2-단일-API나-기능으로서의-인터페이스" class="headerlink" title="3.4.2 단일 API나 기능으로서의 인터페이스"></a>3.4.2 단일 API나 기능으로서의 인터페이스</h3><p>API나 기능은 가능한 단순해야 하며 하나의 기능은 가능한 단순해야 하며 하나의 기능에 여러 다른 기능 논리를 구현하지 않아야 한다</p><p>호출자가 인터페이스의 일부 또는 그 기능의 일부만 사용하는 경우 해당 인터페이스 설계는 단일 책임 원칙을 충족하지 않는다고 말할 수 있다</p><h2 id="3-5-의존-역전-원칙"><a href="#3-5-의존-역전-원칙" class="headerlink" title="3.5 의존 역전 원칙"></a>3.5 의존 역전 원칙</h2><ul><li>의존성 역전이 뜻하는 것은 어떤 대상 사이의 역전인가? 그리고 어떤 의존이 역전되는 것인가? 그리고 여기서 말하는 역전은 무엇을 의미하는가?</li><li>종종 제어 반전과 의존성 주입이라는 두가지 다른 개념을 접할수 있는데 이 개념은 의존 역전과 같은 개념에 속하는가? 만약 그렇지 않다면 그차이는 무엇인가?</li><li>spring 프레임워크의 IoC는 앞에 언급한 세 가지 개념과 어떤 관련이 있는가?<h3 id="3-5-1-제어-반전"><a href="#3-5-1-제어-반전" class="headerlink" title="3.5.1 제어 반전"></a>3.5.1 제어 반전</h3></li></ul><p>실행 흐름은 프레임워크에 의해 제어되고 흐름의 제어는 프로그래머에서 프레임워크로 역전되는것</p><h3 id="3-5-2-의존성-주입"><a href="#3-5-2-의존성-주입" class="headerlink" title="3.5.2 의존성 주입"></a>3.5.2 의존성 주입</h3><p>클래스 내부에 종속되는 클래스의 객체를 생성하는 대신, 외부에서 종속 클래스의 객체를 생성한 후 생성자, 함수의 매개변수 등을 통해 클래스에 주입하는 것을 의미</p><h3 id="3-5-3-의존성-주입-프레임워크"><a href="#3-5-3-의존성-주입-프레임워크" class="headerlink" title="3.5.3 의존성 주입 프레임워크"></a>3.5.3 의존성 주입 프레임워크</h3><p>의존성 주입은 비즈니스 논리에 속하지 않기 때문에 프레임워크에 의해 자동으로 완성되는 코드 형태로 완전히 추상화 될수 있다<br>그리고 이러한 프레임워크를 의존성 주입 프레임워크라고 한다</p><p>spring 프레임워크를 제어 반전 컨테이너라고 부르고 또 어떤사람은 의존성 주입 프레임워크라고 부른다<br>사실 두개의 표현은 모두 틀리지 않으며 단지 제어 반전 컨테이너라는 표현이 더 광범위 하고, 의존성 주입 프레임워크라는 표현이 좀 더 구체적일 뿐이다</p><h3 id="3-5-4-의존-역전-원칙"><a href="#3-5-4-의존-역전-원칙" class="headerlink" title="3.5.4 의존 역전 원칙"></a>3.5.4 의존 역전 원칙</h3><ul><li>상위 모듈은 하위 모듈에 의존하지 않아야 하며, 추상화에 의존해야만 한다</li><li>추상화가 세부 사항에 의존하는 것이 아니라, 세부사항이 추상화에 의존해야 한다</li></ul><h2 id="3-6-KISS-원칙과-YAGNI-원칙"><a href="#3-6-KISS-원칙과-YAGNI-원칙" class="headerlink" title="3.6 KISS 원칙과 YAGNI 원칙"></a>3.6 KISS 원칙과 YAGNI 원칙</h2><ul><li>KISS 원칙에서 단순한이라는 단어가 가지는 의미는 무엇일까?</li><li>어떤 종류의 코드를 단순한 코드라고 할 수 있을까?</li><li>복잡한 코드는 어떤 코드인가?</li><li>간단한 코드를 작성하려면 어떻게 하면 좋을까?</li><li>YAGNI 원칙은 KISS 원칙과 어떤 차이가 있는가?</li></ul><h3 id="3-6-1-KISS-원칙의-정의와-해석"><a href="#3-6-1-KISS-원칙의-정의와-해석" class="headerlink" title="3.6.1 KISS 원칙의 정의와 해석"></a>3.6.1 KISS 원칙의 정의와 해석</h3><p>가능한 단순하게 유지하라 많은 상황에 적용될 수 있는 포괄적인 설계 원칙</p><p>KISS 원칙은 코드를 일고 유지 관리할 수 있도록 해주는 중요한 수단</p><h3 id="3-6-2-적은-줄-수의-코드가-더-간단하지-않다"><a href="#3-6-2-적은-줄-수의-코드가-더-간단하지-않다" class="headerlink" title="3.6.2 적은 줄 수의 코드가 더 간단하지 않다"></a>3.6.2 적은 줄 수의 코드가 더 간단하지 않다</h3><p>코드의 길이가 짧다고 해서 코드가 간단하다고 말할 수 없다</p><h3 id="3-6-3-복잡한-코드가-반드시-KISS-원칙을-위반하는-것은-아니다"><a href="#3-6-3-복잡한-코드가-반드시-KISS-원칙을-위반하는-것은-아니다" class="headerlink" title="3.6.3 복잡한 코드가 반드시 KISS 원칙을 위반하는 것은 아니다"></a>3.6.3 복잡한 코드가 반드시 KISS 원칙을 위반하는 것은 아니다</h3><p>알고리즘 자체의 논리가 복잡하고 구현이 어렵고 가독성이 떨어지는 특성을 가지고 있지만 복잡한 알고리즘을 사용하여 복잡한 문제를 해결하는 것은 KISS 원칙을 위반하는 것이 아니다</p><h3 id="3-6-4-KISS-원칙을-만족하는-코드-작성-방법"><a href="#3-6-4-KISS-원칙을-만족하는-코드-작성-방법" class="headerlink" title="3.6.4 KISS 원칙을 만족하는 코드 작성 방법"></a>3.6.4 KISS 원칙을 만족하는 코드 작성 방법</h3><ul><li>복잡한 정규표현식, 프로그래밍 언어에서 제공하는 지나치게 높은 레벨의 코드 등 지나치게 복잡한 기술을 사용하여 코드를 구현하지 않는다</li><li>바퀴를 다시 발명하는 대신 기존 라이브러리를 사용하는 것을 고려한다</li><li>과도하게 최적화하지 않는다<h3 id="3-6-5-YAGNI-원칙과-KISS-원칙의-차이"><a href="#3-6-5-YAGNI-원칙과-KISS-원칙의-차이" class="headerlink" title="3.6.5 YAGNI 원칙과 KISS 원칙의 차이"></a>3.6.5 YAGNI 원칙과 KISS 원칙의 차이</h3></li></ul><p>YAGNI (You Aren’t Gonna Need It) 원칙은 불필요한 기능을 추가하지 않는 것을 의미하며, 과도하게 설계하지 말라는것</p><p>KISS 원칙은 방법에 관한 것인데 YAGNI 원칙은 금지에 관한 것이다</p><h2 id="3-7-DRY-원칙"><a href="#3-7-DRY-원칙" class="headerlink" title="3.7 DRY 원칙"></a>3.7 DRY 원칙</h2><p>중복 코드를 작성하지 말라는 뜻으로 번역된다</p><h3 id="3-7-1-코드-논리의-중복"><a href="#3-7-1-코드-논리의-중복" class="headerlink" title="3.7.1 코드 논리의 중복"></a>3.7.1 코드 논리의 중복</h3><p>코드의 논리가 중복되지만 의미가 틀리면 중복되는 함수라고 할수 없다</p><h3 id="3-7-2-기능적-의미론적-중복"><a href="#3-7-2-기능적-의미론적-중복" class="headerlink" title="3.7.2 기능적(의미론적) 중복"></a>3.7.2 기능적(의미론적) 중복</h3><p>코드의 논리가 중복되지 않아도 의미적인 중복은 DRY 원칙을 위반하는 것이다</p><h3 id="3-7-3-코드-실행의-중복"><a href="#3-7-3-코드-실행의-중복" class="headerlink" title="3.7.3 코드 실행의 중복"></a>3.7.3 코드 실행의 중복</h3><p>코드 실행의 중복이 되도 DRY 원칙을 위반하는 것이다</p><h3 id="3-7-4-코드-재사용성"><a href="#3-7-4-코드-재사용성" class="headerlink" title="3.7.4 코드 재사용성"></a>3.7.4 코드 재사용성</h3><ul><li>코드의 결합도를 줄인다</li><li>단일 책임 원칙을 충족시켜야 한다</li><li>코드 모듈화는 필수다</li><li>비즈니스 논리와 비즈니스 논리가 아닌 부분을 분리할 필요가 있다</li><li>일반적인 코드는 하위 계층으로 내려보낸다</li><li>상속, 다형성, 추상화, 캡슐화를 활용한다</li><li>애플리케이션 템플릿과 같은 디자인 패턴을 활용하면 코드 재사용성을 향상 시킬수 있다</li></ul><p>3의 법칙(rule of three)은 처음 코드를 작성할 때는 재사용성을 고려하지 않고, 나중에 재사용 시나리로를 만나면 다시 사용할 수 있도록 리팩터링하면 되다</p><h2 id="3-8-LoD"><a href="#3-8-LoD" class="headerlink" title="3.8 LoD"></a>3.8 LoD</h2><p>데메테르의 법칙 (Law of Demeter, LoD)은 높은 응집도와 낮은 결합도를 달성하는 데 도움이 될수 있다</p><h3 id="3-8-1-높은-응집도와-낮은-결합도에-대한-생각"><a href="#3-8-1-높은-응집도와-낮은-결합도에-대한-생각" class="headerlink" title="3.8.1 높은 응집도와 낮은 결합도에 대한 생각"></a>3.8.1 높은 응집도와 낮은 결합도에 대한 생각</h3><p>코드의 가독성과 유지 보수성을 효과적으로 향상시키고 기능 변경으로 인한 코드 변경 범위를 줄일 수 있는 매우 중요한 설계 사상<br>많은 설계 원칙이 코드의 높은 응집도와 낮은 결합도를 달성하는 것을 목표로 하고 있다</p><ul><li>높은 응집도 : 클래스 자체의 설계에 사용된다. 유사한 기능은 동일한 클래스에 배치되어야 하고, 유사하지 않은 기능은 다른 클래스로 분리해야한다</li><li>낮은 결합도 : 클래스 간의 의존성 설계에 사용되는데, 코드에서 클래스 간의 의존성이 단순하고 명확해야 함</li></ul><h3 id="3-8-2-LoD의-정의"><a href="#3-8-2-LoD의-정의" class="headerlink" title="3.8.2 LoD의 정의"></a>3.8.2 LoD의 정의</h3><p>최소 지식의 원칙</p><ul><li>모든 유닛이 자신과 매우 밀접하게 관련된 유닛에 대해서 제한된 지식만 알아야 한다</li></ul><h1 id="참조"><a href="#참조" class="headerlink" title="참조"></a>참조</h1><hr><ul><li><a href="https://www.yes24.com/Product/Goods/118859035">디자인 패턴의 아름다움</a></li></ul>]]></content:encoded>
      
      <comments>https://sejoung.github.io/2024/02/2024-02-26-design_patterns_beauty_3/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Representation Learning (Self-Supervised Learning)</title>
      <link>https://sejoung.github.io/2024/02/2024-02-23-representation_learning_3/</link>
      <guid>https://sejoung.github.io/2024/02/2024-02-23-representation_learning_3/</guid>
      <pubDate>Fri, 23 Feb 2024 05:12:00 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;Representation-Learning-Self-Supervised-Learning&quot;&gt;&lt;a href=&quot;#Representation-Learning-Self-Supervised-Learning&quot; class=&quot;headerlink&quot; tit
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Representation-Learning-Self-Supervised-Learning"><a href="#Representation-Learning-Self-Supervised-Learning" class="headerlink" title="Representation Learning (Self-Supervised Learning)"></a>Representation Learning (Self-Supervised Learning)</h1><ul><li><p>학습 기법의 label에 따른 분류</p><ul><li>딥러닝 모델 학습을 위해서는 많은 레이블이 필요하다.</li><li>하지만, 비싼 레이블링 없이도 모델을 잘 학습시키는 것은 중요하다.</li></ul></li><li><p>Supervised learning의 단점</p><ul><li>“레이블” 데이터가 많아야 함</li><li>학습되지 않은 데이터가 튀어나오면 예측하기 어려움. (transfer가 잘 안됨)</li></ul></li><li><p>Reinforcement learning의 단점</p><ul><li>실패해도 다시 시도하면 되는 게임에선 가능</li><li>현실 세계에서는 실패 자체가 치명적일 수 있어서 적용하기 힘듬</li><li>Policy gradients로 학습하는 과정은 불안정함</li></ul></li><li><p>Self-supervised learning의 필요성</p><ul><li>주변 상황과 조건을 고려해 예측해야 함 (context prediction)</li><li>실패하기 전에 사고가 난다는 것을 예측해야 함</li><li>레이블 없는 많은 데이터를 안정적으로 학습해야함</li><li>모델이 semantics 를 파악하는 데, 굳이 classification 이라는 task를 줄 필요가 없음</li></ul></li></ul><h2 id="Pretext-tasks-기반-self-supervised-learning"><a href="#Pretext-tasks-기반-self-supervised-learning" class="headerlink" title="Pretext tasks 기반 self-supervised learning"></a>Pretext tasks 기반 self-supervised learning</h2><ul><li>Exemplar<ul><li>STL-10 데이터셋 사용</li><li>96x96 이미지 내에서 considerable 한 gradient 영역 근처를 32x32 로 crop</li><li>32x32 seed patch를 기준으로 data augmentation을 적용하여 추가 영상 생성</li><li>Seed image를 data augmentation 하여 이 데이터를 seed image로 prediction하도록 학습.</li><li>surrogate training classes &#x2F; training samples가 많아질 수록 성능이 향상한다</li><li>Surrogate labels 을 data augmentation을 통해 얻어서 네트워크를 학습하면 transfer했을 때 성능이 좋다.</li><li>Discrimina&#x2F;ve 한 features로서 image matching에 적용했을 때 SIFT보다 좋은 descriptors로서의 결과도 낸다. (marginal 하지만)</li><li>ImageNet과 같은 large-scale datasets에는 적용하기 어려움.</li></ul></li><li>Context Prediction<ul><li>Context predicXon 이라는 pretext task를 통해 exemplar의 단점을 해결하려 함.</li><li>3x3 개의 patches를 뜯어서 가운데를 기준으로 1~8 번 할당</li><li>가운데를 기준으로 선택한 patch가 몇 번째 패치인지 예측하도록 모델이 학습됨.</li><li>사람도 다소 예측하기 어려움. 하지만, 이를 machine에게 학습시키면, 이미지 전반의 representation을 배울 수 있다는 게 모티베이션.</li><li>이미지 패치나 위치는 일정하지 않고 약간의 위치 변화를 주어 샘플링 된다.</li><li>그럼에도, context prediction tasks로 pre-training 한 feature extractor를 사용하면 성능이 좋다.</li></ul></li><li>Jigsaw Puzzles<ul><li>직쏘 퍼즐을 풀게하는 pretext task</li><li>앞선 context prediction과 3x3 패치를 추출하지만, 임의의 permutation으로 셔플함.</li><li>하지만, 직쏘 퍼즐은 9!&#x3D;362,880 개(36만개)의 클래스를 배워야해서 이는 어렵다.</li><li>Permutation 수에 따른 결과: permutation의 수가 많아질수록 permutation간의 차이가 클수록(구분하기 쉬워질 수록) transfer 성능이 좋아진다.</li><li>직쏘 퍼즐은 좋은 pretext task이다.</li><li>이와 같은 context-free network (CFN)은 인간이 해내기 어려운 task를 학습함으 로써 더 좋은 deep learning 모델을 학습 하는 데에 성공하였다.</li><li>또한 label없이 학습하는 self-supervised learning task를 정의하여 human annotation의 비용을 줄였다.</li></ul></li><li>Count<ul><li>한 patch에 대한 object의 특징을 가장의 vector로 표현함.</li><li>ex.각 패치안에 코2개,눈4개, 머리 1개 등등..</li><li>각 패치의 특징 벡터의 합을 prediction하는 것은 원래 이미지의 특징 벡터의 합과 같다는 이론에서 intuition을 얻음.</li><li>AlexNet을 사용하여 패치별 특 징벡터를 출력하게 함.</li><li>원본 이미지를 downsampling 했을때 얻는 특징 벡터와,각패치 별로 넣었을때 나오는 특징 벡터의 합이 같도록 학습함</li><li>하지만,같은 이미지로만 학습하면,모든 feature vector를 0으로만 예측하는 trivial solution이 생김</li><li>Counting task는 representation learning 으로 좋은 task이다.</li><li>Feature vector를 잘 학습해서 오른쪽 사진과 같이 retrieval 에서도 효과적으로 embedding space를 만든다.</li><li>Visual primitives의 조합을 잘 만드는 것은 중요하다.</li></ul></li><li>Multi-Task<ul><li>2017년 당시에 주요 쓰였던 self-supervised learning 방법들을 동시에 multi-task learning으로 학습시키는 방법 제안</li><li>하나의 네트워크로, relative patch location (Context prediction) + colorization + exemplar + motion segmentation 의 pretext tasks를 동시에 수행함.</li><li>각 결과를 서로 다른 GPU머신을 학습해서 gradient를 축적한 다음에 한번에 네트워크 업데이트를 한다.</li><li>Self-supv pre-training이 fully-supervised pre-training을 넘을 수 있는 가능성 제시.</li></ul></li><li>Rotation Prediction (RotNet)<ul><li>이미지의 upright 4방향 rotation을 prediction 하는 pretext task</li><li>회전 이미지가 원본에서 몇도 회전했는 지를 예측하게 함.</li></ul></li><li>Rotation Prediction (Decouple-RotNet)<ul><li>Pretext task는 RotNet과 같음.</li><li>Rotation 은 ambiguous 할 수 있지 않나?</li><li>그러면 그 example에 대해서는 학습이 매우 어렵고 무의미함.</li><li>Rotation-agnostic example을 제거하자.</li></ul></li></ul><h2 id="Contrastive-Learning"><a href="#Contrastive-Learning" class="headerlink" title="Contrastive Learning"></a>Contrastive Learning</h2><ul><li>Non-Parametric Instance Discrimination<ul><li>Non-parametric Softmax classifier<ul><li>고정된 w가 아닌 feature vector v로 대체하였다. (instance 특성학습 위해)</li><li>L2 norm을 통해 v를 unit sphere에 고정</li><li>모든 instance가 class에 상관없이 unit sphere에 골고루 퍼져서 분포하도록 학습</li></ul></li><li>Noise-contrastive estimation (NCE)<ul><li>NCE form의 contrative loss 추가.</li></ul></li><li>Proximal regularization<ul><li>각 instance를 개별 클래스로 두고 학습하면 학습이 불안정해서, proximal regularization 추가함.</li></ul></li><li>Weighted k-NN classifier<ul><li>Test time 때 들어오는 sample은 k-NN features를 찾아서 classifying 한다.</li></ul></li><li>결론<ul><li>instance-level discrimination 을 통해 unsupervised feature learning을 하는 것은 피처 학습에 효과적이다.</li><li>이때 non-parametric soamax formulation이 오히려 학습에 도움이 된다.</li><li>Image classification (ImageNet, Places) 결과</li><li>Semi-supervised learning, object detection으로의 일반화</li></ul></li></ul></li><li>MoCo: Momentum Contrast<ul><li>Contrastive learning을 unsupervised representa&#x2F;on learning 에 좀 더 효과적으로 적용시켜 보자.</li><li>Pretext task: Positive &#x2F; negative pairing을 augmentation 을 통해 더 많이 만들기.</li><li>Encoder가 key representation의 consistency를 해쳐서 학습이 불안정해지는 것을 막기위해 momentum contrast 도입.</li><li>결론<ul><li>Self-supervised contrastive learning 으로 model pre-training 하면 성능이 좋다.</li><li>Pretext task로 instance discrimination task 는 다른 task로 바뀔 수 있다. (e.g., masked auto-encoding 등)</li><li>Backbone network도 CNN에서 바뀔 수 있다.</li></ul></li></ul></li><li>SimCLR <ul><li>MoCo와 비슷한 시기에 나온 Contrastive learning 기법.</li><li>성능이 좀 더 향상되었다.</li><li>Simple framework로도 contrastive visual representation learning 의 좋은 결과를 낸다.</li></ul></li><li>MoCo Version 2<ul><li>SimCLR의 design improvements를 MoCo에도 적용하여 성능을 향상시키겠다.</li></ul></li><li>SimCLR Version 2<ul><li>Semi-supervised learning 쪽 알고리즘의 장점까지 도입하여 3단계로 학습해 보자.<ul><li>Unsupervised&#x2F;Self-supervised pretraining : task-agnostic CNN model 학습</li><li>Supervised Fine-tuning : pretraining 이후에 fine-tuning을 한다</li><li>Dis5lla5on using unlabeled data : teacher model에서 얻은 pseudo-label로 student model tuning.</li></ul></li></ul></li><li>MaskFeat<ul><li>모티베이션: Pretext task로 masked input으로 HOG를 prediction해보자.</li><li>결과<ul><li>Masked feature predictio은 visual pre-training task로서 좋은 결과를 준다.</li><li>특히 비디오와 같은 프레임간의 방향성을 가진 task에서 transfer가 잘 된다.</li></ul></li></ul></li><li>BYOL<ul><li>Contrastive learning방법들은 negative를 잘 선택 해야한다.</li><li>결과: batch size나 image augmentaXon에 대해 simclr보다 덜 민감함</li></ul></li><li>Barlow Twins<ul><li>BYOL과 비슷하게 Siamese network 활용</li><li>하지만, 최종 predicthon에서 mini-batch features 의 cross-correlation matrix를 계산하고, diagonal 을 maximize함</li></ul></li><li>DINO: Vision Transformer + SSL<ul><li>DINO:self-distillation with no labels.</li><li>모티베이션:Self-supvViT로 학습한 모델은 이미 object의 segmentation을 어느정도 잡고 있다.</li></ul></li></ul><h2 id="Semi-Supervised-Learning-이란"><a href="#Semi-Supervised-Learning-이란" class="headerlink" title="Semi-Supervised Learning 이란"></a>Semi-Supervised Learning 이란</h2><ul><li><p>준지도학습</p></li><li><p>Label이 일부 샘플에만 주어진것. (Supervised + Unsupervised)</p></li><li><p>Labeling은 비용이 많이 든다.</p></li><li><p>Smoothness:x1,x2의 거리가 가까우면, y1,y2도 가까워야 한다</p></li><li><p>Low-density:decisionboundary가 data의density가 높은 곳을 지나지 않는다. (잘 분리 된다.)</p></li><li><p>Manifold:고차원의 입력이 저 차원에서 특정 manifold를 따라 놓이게 된다.</p></li><li><p>Clustering:데이터가 같은 클러스터에 속하면, 같은 클래스이다. (유사도에 따라 분류된다.)</p></li><li><p>Entropy Minimization</p><ul><li>가정: Decision boundary는 데이터의 밀도가 낮은곳에 형성 될 것이다.</li><li>Prediction을 좀 더 sharp하게 만들어서 entropy를 minimize함.</li><li>pseudo-label사용.(one-hot vector로 argmax하기 때문에)</li></ul></li><li><p>Proxy-Label Methods</p><ul><li>Unlabeled data point에 label을 달아주는기법.</li><li>Labeled data에 벗어나는 샘플은 제대로된 pseudo-label을 주기 어렵다.</li><li>그래도,labeled data에서의 interpolation 효과를 줌</li><li>Pseudo-label의 confidence가높은샘플만을 사용했을 때 성능이 더 높았다는 보고가 있음.</li></ul></li><li><p>Proxy-Label Methods: Label Propagation by Graph</p><ul><li>Graph-based semi-supervised learning의 목표: unlabeled data로 예측 성능을 높이는 게 목표가 아닌, unlabeled data의 label 을 추정하는 그 자체가 목표.</li></ul></li><li><p>Consistency Regularization</p><ul><li>Consistency regularization: unlabeleddata에 small perturbation을 주어도 예측에는 일관성이 있을 것이다.</li><li>즉, unlabeled data에 data augmentation 을 주어 class가 바뀌지 않을 정도의 변화를 주고, 원래 데이터와 같아지도록 unsupervised loss를 준다.</li></ul></li><li><p>Consistency Regularization: Temporal Ensemble</p><ul><li>Temporal Ensemble: 과거의 network evaluation을 ensemble prediction 처럼 합친다. (이유: pi model이 noisy 한 input에 의해 모델도 noisy해진다)</li></ul></li><li><p>Consistency Regularization: Mean Teacher</p><ul><li>Meanteacher: output prediction뿐아니라,model weight에 대해서도 temporal ensembling을 하자.</li></ul></li><li><p>Consistency Regularization: Virtual Adversarial Training</p><ul><li>Virtual Adversarial Training: unlabeled 입력 데이터에 augmentation을 줄때에 fixed augmentation이 아닌 adversarial 한 이미지 변형을 주자</li></ul></li><li><p>Consistency Regularization: UDA</p><ul><li>세가지 dataaugmentation 방식을 통해 unlabeled data를 augment함.<ul><li>AutoAugmentation(이미지분류): rule-basedRL augmentation찾는 기법.</li><li>Backtranslation(텍스트분류): 두개의 기계 번역 모델로 원본 텍스트와 유사한 다양한 텍스트를 augmentation 하여 얻는 기법.</li><li>TD-IDF word replacement(텍스트분류): 설명력이 낮은(TD-IDF 벡터에서 값이 낮은) 단어를 대체하고, 키워드 단어는 보존하는 기법.</li></ul></li></ul></li><li><p>MixMatch</p><ul><li>MixMatch:여러 semi-supervised learning기법을 합쳐높은 성능을 냄</li></ul></li><li><p>ReMixMatch</p><ul><li>ReMixMatch: MixMatch에서 strong augmentation의 장점을 살리기위해 augmentation anchoring 도입</li></ul></li><li><p>FixMatch</p><ul><li>ReMixMatch+UDA</li><li>결론:semi-supervised learning의 a few lines of code변경으로 높은 성능 향상을 달성했다.</li></ul></li></ul><h1 id="참조"><a href="#참조" class="headerlink" title="참조"></a>참조</h1><hr><ul><li><a href="https://twitter.com/mldcmu/status/1046869963347283973">Yann Lecun (On True AI) twitter </a></li><li><a href="https://medium.com/syncedreview/yann-lecun-cake-analogy-2-0-a361da560dae">Yann LeCun Cake Analogy 2.0</a></li><li><a href="https://iclr.cc/media/iclr-2021/Slides/3720.pdf"></a></li></ul>]]></content:encoded>
      
      <comments>https://sejoung.github.io/2024/02/2024-02-23-representation_learning_3/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Representation Learning 2</title>
      <link>https://sejoung.github.io/2024/02/2024-02-22-representation_learning_2/</link>
      <guid>https://sejoung.github.io/2024/02/2024-02-22-representation_learning_2/</guid>
      <pubDate>Thu, 22 Feb 2024 06:34:00 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;Representation-Learning-2&quot;&gt;&lt;a href=&quot;#Representation-Learning-2&quot; class=&quot;headerlink&quot; title=&quot;Representation Learning 2&quot;&gt;&lt;/a&gt;Representat
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Representation-Learning-2"><a href="#Representation-Learning-2" class="headerlink" title="Representation Learning 2"></a>Representation Learning 2</h1><h2 id="place-recognition-NetVLAD"><a href="#place-recognition-NetVLAD" class="headerlink" title="place recognition(NetVLAD)"></a>place recognition(NetVLAD)</h2><ul><li>Vector of Locally Aggregated Descriptors (VLAD)<ul><li>VLAD는 이미지의 특징점을 클러스터링하여 각 클러스터에 대한 특징점의 차이를 계산한 후 이를 이용하여 이미지를 표현하는 방법이다.</li></ul></li><li>NetVLAD<ul><li>VLAD를 딥러닝을 이용하여 학습하는 방법이다.</li><li>weakly supervised ranking loss를 이용하여 학습한다.</li></ul></li></ul><h2 id="Landmark-recognition"><a href="#Landmark-recognition" class="headerlink" title="Landmark recognition"></a>Landmark recognition</h2><ul><li>Deep Local Features (DELF)<ul><li>DELF는 이미지의 특징점을 추출하여 이를 이용하여 이미지를 표현하는 방법이다.</li><li>구글 랜드마크 데이터셋을 이용한다.</li><li>cross-entropy loss를 이용하여 학습한다.</li></ul></li><li>Google Landmark V2<ul><li>20만개의 랜드마크를 포함하고 있다.</li></ul></li></ul><h2 id="Mean-Average-Precision-mAP"><a href="#Mean-Average-Precision-mAP" class="headerlink" title="Mean Average Precision(mAP)"></a>Mean Average Precision(mAP)</h2><ul><li>쿼리에 대한 응답 모움에 대한 평균으로 정확도를 측정하는 방법이다.</li><li>listwise AP Loss <ul><li>50 개의 랭킹을 본다음 맞는것은 앞으로 땡기고 틀린것은 뒤로 밀어서 학습한다.</li></ul></li></ul><h2 id="Image-Clustering"><a href="#Image-Clustering" class="headerlink" title="Image Clustering"></a>Image Clustering</h2><ul><li>이미지들을 군집 시키는 방법</li><li>k-means<ul><li>이미지의 특징점을 이용하여 이미지를 군집화한다.</li></ul></li><li>mahalanobis distance<ul><li>이미지의 특징점을 이용하여 이미지를 군집화한다.</li></ul></li></ul><h2 id="Image-Clustering-Unsupervised-Metric-Learning"><a href="#Image-Clustering-Unsupervised-Metric-Learning" class="headerlink" title="Image Clustering: Unsupervised Metric Learning"></a>Image Clustering: Unsupervised Metric Learning</h2><ul><li>Pra-trained embedding에서 label없는 이미지 collection으로 fine-tuning한다.</li><li>Manifold 간의 hard positives와 hard negatives 를 구해서 contrastive learning을 한다.</li><li>STML (Self-Taught Metric Learning)</li></ul><h2 id="Image-Clustering-t-SNE"><a href="#Image-Clustering-t-SNE" class="headerlink" title="Image Clustering: t-SNE"></a>Image Clustering: t-SNE</h2><ul><li>t-Distributed Stochastic Neighbor Embedding<ul><li>Feature elimination: feature 를 단순히 제거함. 정보 손실이 있음. Feature selection: 통계적 방법을 통해 feature의 중요도에 rank를 매김.<br>정보 손실이 있음. </li><li>데이터셋마다 rank가 달라져야함. Feature extraction: 새로운 features를 추출해냄.</li><li>Linear vs. non-linear</li></ul></li></ul><h2 id="Data-Augmentation"><a href="#Data-Augmentation" class="headerlink" title="Data Augmentation"></a>Data Augmentation</h2><ul><li>학습 데이터의 갯수를 늘리기위해 샘플에 각종 변환을 적용하는것.</li><li>Color Transformation<ul><li>Gaussian Blur, Motion Blur, Brightness Jitter, Contrast Jitter, Saturation Jitter, ISO Noise, JPEG Compression 등</li></ul></li><li>Spatial Transformation<ul><li>Filp, Rotation, Crop, Affine 등.</li><li>Detection&#x2F;Segmentation 의 경우 GT도 transform 주의.</li></ul></li><li>Rule-based data augmentation<ul><li>PatchShuffle Regularization<ul><li>Window 내의 픽셀을 섞어서 augmentation 하는 기법.</li></ul></li><li>SamplePairing<ul><li>두 장의 이미지를 pixel-wise로 섞어서 네트워크에 통과시키는 형태의 augmentation</li></ul></li><li>Mixup<ul><li>두 장의 이미지를 섞을 때, linear interpolated 된 위치로 섞는 것.</li></ul></li><li>Mosaic Augmentation (Cropping and Patching)<ul><li>여러장의 이미지를 패치를 떼고 붙여서 N-label classification 문제로 푸는 방식</li></ul></li><li>Multiple Way of Mixing<ul><li>두 장의 이미지를 pixel-wise로 섞어서 네트워크에 통과 시키는 형태의 augmentation</li><li>Pair image를 좀 더 다양하게 mixing하는 8가지 방식을 제안한다.</li></ul></li><li>Manifold Mixup<ul><li>Hidden representation 에서 mixup 하는 것.</li><li>Input mixup에 비해 보다 디시전 바운더리를 더 자연스럽게 만든다.</li></ul></li><li>Random Erasing<ul><li>랜덤으로 지워서 augmentation 하는 방법. (블랙&#x2F;화이트&#x2F;랜덤)</li><li>Random erasing + random cropping 뿐 아니라, image&#x2F;object-aware erasing도 한다.</li><li>Object detection과 person re-identification 에도 적용한다.</li></ul></li><li>Cutout<ul><li>이미지의 일부를 잘라내서 수행하는 방식과 그 분석.</li></ul></li><li>Hide-And-Seek for Weakly-Supervised Localization<ul><li>이미지의 여러부분의 패치를 잘라내어서 augmentation 하는 방법</li></ul></li><li>CutMix<ul><li>Cropping and Patching 과 같이 이미지 여러장을 잘라 붙이는 방식.</li></ul></li><li>AugMix<ul><li>여러 augmentation 을 직렬과 병렬로 연결하여 적용하는 것.</li></ul></li><li>SmoothMix<ul><li>CutMix 처럼 붙일 때 바운더리 근처를 스무딩 하자.</li></ul></li></ul></li><li>GAN 기반의 Data Augmentation<ul><li>Generative Advarsarial Networks (GAN) 을 사 용한 data augmentation 을 수행한다.</li><li>Medical Image Augmentation<ul><li>간의 병변 추측 모델 학습을 위해 GAN으로 데이터를 생성하여 학습. </li><li>평가는 병변의 여부에 대한 classification 으로 함.</li></ul></li><li>SinGAN: Single Image GAN<ul><li>단일 이미지로 unconditional GAN을 학습하는 것.</li><li>Fully-convolutional GANs으로, multi-scale pyramid로 부터 패치 정보들과 이미지 전체 구조를 학습한다.</li><li>Loss: Advarsarial loss + Reconstruction loss</li></ul></li><li>GANGealing: GAN-Supervised alignment<ul><li>GAN으로 생성된 이미지를 supervision으로 주어 dense visual alignment 모델을 학습하기 위한 방식</li><li>별다른 supervision없이 다양한 image data augmentation을 gan을 통해 학습한다.</li></ul></li></ul></li><li>AutoML 기반의 방법<ul><li>Data Augmentation Policy 를 AutoML 을 통해 찾는 방법을 제안한다</li><li>AutoAugment<ul><li>Neural Architecture Search 와 비슷하게 RNN controller 를 통해 Augmentation policy를 뽑고 </li><li>이후 네트워크를 학습시켜서 validation accuracy 를 reward로 Policy gradient를 사용한 강화학습을 한다</li></ul></li><li>Population Based AutoAugment<ul><li>Density matching 기반의 efficient search strategy를 제안한다.</li><li>Bayesian Optimization기법(Tree-structuredParzenEstimator(TPE)) 를 사용하여 Augmentation policy 추출</li></ul></li><li>Fast AutoAugment<ul><li>Differentiable AutoAugment</li><li>미분 불가능한 policy gradients를 미분 가능하게 하면, gradient descent optimization 으로 augmentation policy를 학습할 수 있지 않을까?</li><li>Gradient-based Neural Architecture Search(NAS)의 대표적 방법인 “DARTS: Differentiable Architecture Search (ICLR 2019)”를 따라한다.</li></ul></li><li>RandAugment<ul><li>왜 AutoML 로 augmentation policy 를 찾아야 할까?</li><li>아예 찾지 말고, mini-batch 샘플링 때마다 여러 augmentation 옵션 중 랜덤으로 선택해서 적용해 보자.</li></ul></li><li>UniformAugment<ul><li>두 장의 이미지를 pixel-wise로 섞어서 네트워크에 통과시키는 형태의 augmentation</li><li>엑세스가 되지 않은 논문이다</li></ul></li><li>TrivialAugment<ul><li>Effectiveness와 Efficiency 사이에서 trade-off 를 고려</li><li>아예 parameter-free로 가기 보다는 몇가지 중요한 factor는 서치하자</li></ul></li></ul></li></ul><h1 id="참조"><a href="#참조" class="headerlink" title="참조"></a>참조</h1><hr><ul><li><a href="https://github.com/Nanne/pytorch-NetVlad/blob/master/netvlad.py">pytorch-NetVlad</a></li><li><a href="https://arxiv.org/abs/2004.01804">Google Landmarks Dataset v2 – A Large-Scale Benchmark for Instance-Level Recognition and Retrieval</a></li><li><a href="https://towardsdatascience.com/breaking-down-mean-average-precision-map-ae462f623a52">Breaking Down Mean Average Precision (mAP)</a></li><li><a href="https://github.com/naver/deep-image-retrieval">Deep Image Retrieval</a></li><li><a href="https://ratsgo.github.io/machine%20learning/2017/04/19/KC/">K-평균 군집화(K-means Clustering)</a></li><li><a href="https://scikit-learn.org/stable/modules/clustering.html">scikit-learn</a></li><li><a href="https://lvdmaaten.github.io/tsne/">t-SNE</a></li><li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html">sklearn.manifold.TSNE</a></li><li><a href="https://hav4ik.github.io/articles/deep-metric-learning-survey">Deep Metric Learning: a (Long) Survey</a></li><li><a href="https://github.com/zhunzhong07/Random-Erasing">Random Erasing Data Augmentation</a></li><li><a href="https://www.wpeebles.com/gangealing">GANgealing</a></li><li><a href="https://github.com/barisozmen/deepaugment">deepaugment</a></li></ul>]]></content:encoded>
      
      <comments>https://sejoung.github.io/2024/02/2024-02-22-representation_learning_2/#disqus_thread</comments>
    </item>
    
  </channel>
</rss>
