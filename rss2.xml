<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>폭간의 기술블로그</title>
    <link>https://sejoung.github.io/</link>
    <atom:link href="/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description>잘정리하자</description>
    <pubDate>Wed, 07 May 2025 06:45:38 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>우분투 설치시 네트워크 드라이브(R8125) 인식 안됨</title>
      <link>https://sejoung.github.io/2025/05/2025-05-07-r8125_drive_ubuntu/</link>
      <guid>https://sejoung.github.io/2025/05/2025-05-07-r8125_drive_ubuntu/</guid>
      <pubDate>Wed, 07 May 2025 06:45:00 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;우분투-설치시-네트워크-드라이브-R8125-인식-안됨&quot;&gt;&lt;a href=&quot;#우분투-설치시-네트워크-드라이브-R8125-인식-안됨&quot; class=&quot;headerlink&quot; title=&quot;우분투 설치시 네트워크 드라이브(R8125) 인식 안됨&quot;&gt;&lt;/
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="우분투-설치시-네트워크-드라이브-R8125-인식-안됨"><a href="#우분투-설치시-네트워크-드라이브-R8125-인식-안됨" class="headerlink" title="우분투 설치시 네트워크 드라이브(R8125) 인식 안됨"></a>우분투 설치시 네트워크 드라이브(R8125) 인식 안됨</h1><h2 id="현상"><a href="#현상" class="headerlink" title="현상"></a>현상</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lshw -C network</span><br></pre></td></tr></table></figure><p>위에 명형어를 수행하면 </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">*-network UNCLAIMED</span><br></pre></td></tr></table></figure><p>위처럼 나오고 유선랜이 잡히지 않음</p><h2 id="해결-방법"><a href="#해결-방법" class="headerlink" title="해결 방법"></a>해결 방법</h2><p><a href="https://github.com/awesometic/realtek-r8125-dkms">realtek-r8125-dkms</a></p><p>위에 링크를 통해서 드라이버를 설치하면 됨 네트워크 없이는 의존성을 설치하기 힘듬 wifi를 통해서 설치하면 됨</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo add-apt-repository ppa:awesometic/ppa</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apt update</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install realtek-r8125-dkms</span><br></pre></td></tr></table></figure><h1 id="참고"><a href="#참고" class="headerlink" title="참고"></a>참고</h1><hr><p><a href="https://github.com/awesometic/realtek-r8125-dkms">realtek-r8125-dkms</a></p>]]></content:encoded>
      
      <comments>https://sejoung.github.io/2025/05/2025-05-07-r8125_drive_ubuntu/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Docker login 시 mac keychain 에러</title>
      <link>https://sejoung.github.io/2025/04/2025-04-23-docker_login_mac/</link>
      <guid>https://sejoung.github.io/2025/04/2025-04-23-docker_login_mac/</guid>
      <pubDate>Wed, 23 Apr 2025 02:43:00 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;Docker-login-시-mac-keychain-에러&quot;&gt;&lt;a href=&quot;#Docker-login-시-mac-keychain-에러&quot; class=&quot;headerlink&quot; title=&quot;Docker login 시 mac keychain 에러&quot;&gt;
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Docker-login-시-mac-keychain-에러"><a href="#Docker-login-시-mac-keychain-에러" class="headerlink" title="Docker login 시 mac keychain 에러"></a>Docker login 시 mac keychain 에러</h1><h2 id="로그인"><a href="#로그인" class="headerlink" title="로그인"></a>로그인</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo 키정보 | docker login -u 사용자 --password-stdin</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="예시"><a href="#예시" class="headerlink" title="예시"></a>예시</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo dckr_pat_ewhqgTvF1234GFjYM4ziAEWNctrw | docker login -u zolla --password-stdin</span><br></pre></td></tr></table></figure><h3 id="에러"><a href="#에러" class="headerlink" title="에러"></a>에러</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Error saving credentials: error storing credentials - err: exit status 1, out: `error getting credentials - err: exit status 1, out: `keychain cannot be accessed because the current session does not allow user interaction. The keychain may be locked; unlock it by running &quot;security -v unlock-keychain ~/Library/Keychains/login.keychain-db&quot; and try again``</span><br></pre></td></tr></table></figure><h2 id="해결-방법"><a href="#해결-방법" class="headerlink" title="해결 방법"></a>해결 방법</h2><p>Keychain 잠금 해제</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">security unlock-keychain -p &#x27;비밀번호&#x27; ~/Library/Keychains/login.keychain-db</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">security unlock-keychain -p &#x27;1234&#x27; ~/Library/Keychains/login.keychain-db</span><br></pre></td></tr></table></figure><h1 id="참고"><a href="#참고" class="headerlink" title="참고"></a>참고</h1><hr>]]></content:encoded>
      
      <comments>https://sejoung.github.io/2025/04/2025-04-23-docker_login_mac/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Docker build 시 SSH 키 설정 사용</title>
      <link>https://sejoung.github.io/2025/04/2025-04-07-docker_build_ssh_git/</link>
      <guid>https://sejoung.github.io/2025/04/2025-04-07-docker_build_ssh_git/</guid>
      <pubDate>Mon, 07 Apr 2025 05:24:00 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;Docker-build-시-SSH-키-설정-사용&quot;&gt;&lt;a href=&quot;#Docker-build-시-SSH-키-설정-사용&quot; class=&quot;headerlink&quot; title=&quot;Docker build 시 SSH 키 설정 사용&quot;&gt;&lt;/a&gt;Docker b
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Docker-build-시-SSH-키-설정-사용"><a href="#Docker-build-시-SSH-키-설정-사용" class="headerlink" title="Docker build 시 SSH 키 설정 사용"></a>Docker build 시 SSH 키 설정 사용</h1><p>컴파일 언어를 사용해서 배포할때는 바이너리만 배포하면 되니깐 문제가 없는데(모든 의존성을 build 시점에 같이 묶임)<br>파이썬 같은 인터프리터 언어를 사용할때는 배포할 시점에 의존성 파일을 다운받아야 된다.<br>venv를 사용해서 가상환경을 만들고, 그 안에 의존성 파일을 다운받는 경우가 많다.</p><p>이시점에 pip를 사용해서 의존성 파일을 다운받는데, private git hub에 있는 의존성 파일을 다운받아야 하는 경우가 있다.</p><p>이때는 SSH 키를 사용해서 private git hub에 접근해야 한다.</p><p>이 문제를 해결하기 위해서 Dockerfile에서 SSH 키를 사용해서 private git hub에 접근하는 방법을 알아보자.</p><h2 id="Dockerfile"><a href="#Dockerfile" class="headerlink" title="Dockerfile"></a>Dockerfile</h2><p>처리 방법이 여러 방법이 있는데 저는 기본적인 방법을 사용했다.</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">FROM</span> python:<span class="number">3.11</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">ENV</span> ROOT=/test</span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> <span class="built_in">mkdir</span> -p <span class="variable">$ROOT</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> <span class="built_in">mkdir</span> -p /root/.ssh</span></span><br><span class="line"><span class="keyword">COPY</span><span class="language-bash"> id_ed25519 /root/.ssh/id_ed25519</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> <span class="built_in">chmod</span> 600 /root/.ssh/id_ed25519 &amp;&amp; \</span></span><br><span class="line"><span class="language-bash">    ssh-keyscan github.com &gt;&gt; /root/.ssh/known_hosts</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="language-bash"> <span class="variable">$ROOT</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">COPY</span><span class="language-bash"> . .</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> pip install --upgrade pip</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> pip install -r requirements.txt</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> <span class="built_in">rm</span> -rf /root/.ssh</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">ENTRYPOINT</span><span class="language-bash"> [<span class="string">&quot;python3.11&quot;</span>, <span class="string">&quot;src/main.py&quot;</span>]</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>위와 같이 ssh 키를 복사하고, 권한을 설정하고, ssh-keyscan을 사용해서 github.com의 공개키를 known_hosts에 추가한다.</p><p>이렇게 하면 ssh 키를 사용해서 private git hub에 접근할 수 있다.</p><p>그리고 코드가 다 동작하면 ssh 키를 삭제한다.</p><h1 id="참고"><a href="#참고" class="headerlink" title="참고"></a>참고</h1><hr>]]></content:encoded>
      
      <comments>https://sejoung.github.io/2025/04/2025-04-07-docker_build_ssh_git/#disqus_thread</comments>
    </item>
    
    <item>
      <title>jenkins에서 python 빌드하기</title>
      <link>https://sejoung.github.io/2025/03/2025-03-25-jenkins_python_build/</link>
      <guid>https://sejoung.github.io/2025/03/2025-03-25-jenkins_python_build/</guid>
      <pubDate>Tue, 25 Mar 2025 12:00:00 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;jenkins에서-python-빌드하기&quot;&gt;&lt;a href=&quot;#jenkins에서-python-빌드하기&quot; class=&quot;headerlink&quot; title=&quot;jenkins에서 python 빌드하기&quot;&gt;&lt;/a&gt;jenkins에서 python 빌드하기&lt;/
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="jenkins에서-python-빌드하기"><a href="#jenkins에서-python-빌드하기" class="headerlink" title="jenkins에서 python 빌드하기"></a>jenkins에서 python 빌드하기</h1><p>아래 와 같은 오류가 날수 있는데 해당 오류는 apt install python-dev 로 해결할수 있다.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Python.h : no such file or directory</span><br></pre></td></tr></table></figure><p>macOS를 host로 사용시에 docker 설정에서는 docker in docker 를 사용할때 아래와 같은 설정이 정상 동작 하지 않는다.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">volumes:</span><br><span class="line">  - ./jenkins_home:/var/jenkins_home</span><br><span class="line">  - /var/run/docker.sock:/var/run/docker.sock  # Docker-in-Docker (필요한 경우)</span><br><span class="line">  - /usr/bin/docker:/usr/bin/docker  # Docker 명령어 사용 가능하게 설정</span><br></pre></td></tr></table></figure><p><code>/usr/bin/docker:/usr/bin/docker</code> 여기가 문제인데 이부분을 제거하고 docker명령어를 install 하면 정상 동작한다.</p><h1 id="참고"><a href="#참고" class="headerlink" title="참고"></a>참고</h1><hr>]]></content:encoded>
      
      <comments>https://sejoung.github.io/2025/03/2025-03-25-jenkins_python_build/#disqus_thread</comments>
    </item>
    
    <item>
      <title>macos 화면 공유하기 및 SSH 설정</title>
      <link>https://sejoung.github.io/2025/03/2025-03-17-macos_screen_share/</link>
      <guid>https://sejoung.github.io/2025/03/2025-03-17-macos_screen_share/</guid>
      <pubDate>Mon, 17 Mar 2025 06:34:00 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;macos-화면-공유하기-및-SSH-설정&quot;&gt;&lt;a href=&quot;#macos-화면-공유하기-및-SSH-설정&quot; class=&quot;headerlink&quot; title=&quot;macos 화면 공유하기 및 SSH 설정&quot;&gt;&lt;/a&gt;macos 화면 공유하기 및 SSH 
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="macos-화면-공유하기-및-SSH-설정"><a href="#macos-화면-공유하기-및-SSH-설정" class="headerlink" title="macos 화면 공유하기 및 SSH 설정"></a>macos 화면 공유하기 및 SSH 설정</h1><p>macos 화면 공유하기 및 SSH 설정을 하기 위해서는 다음과 같은 설정을 해주어야 한다.</p><p><img src="https://sejoung.github.io/images/2025_03_17_01.png" alt="mac os 1"></p><p><img src="https://sejoung.github.io/images/2025_03_17_02.png" alt="mac os 2"></p><p>위에 설정이 끝나면 아래의 툴로 통해서 접속하거나 터미널에서 <code>ssh</code> 명령어로 접속이 가능하다.</p><p><img src="https://sejoung.github.io/images/2025_03_17_03.png" alt="mac os 3"></p><p>화면 공유 툴 터미널에서 접속 방법</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">open vnc://192.168.0.1</span><br></pre></td></tr></table></figure><h1 id="참고"><a href="#참고" class="headerlink" title="참고"></a>참고</h1><hr><ul><li><a href="https://support.apple.com/ko-kr/guide/mac-help/mh14066/mac">다른 Mac의 화면 공유하기</a></li><li><a href="https://support.apple.com/ko-kr/guide/mac-help/mh11848/mac">Mac 화면 공유 켜거나 끄기</a></li></ul>]]></content:encoded>
      
      <comments>https://sejoung.github.io/2025/03/2025-03-17-macos_screen_share/#disqus_thread</comments>
    </item>
    
    <item>
      <title>최신 image gen AI 기술 관련 기사</title>
      <link>https://sejoung.github.io/2025/02/2025-02-11-lora_articles/</link>
      <guid>https://sejoung.github.io/2025/02/2025-02-11-lora_articles/</guid>
      <pubDate>Tue, 11 Feb 2025 05:30:00 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;최신-image-gen-AI-기술-관련-기사&quot;&gt;&lt;a href=&quot;#최신-image-gen-AI-기술-관련-기사&quot; class=&quot;headerlink&quot; title=&quot;최신 image gen AI 기술 관련 기사&quot;&gt;&lt;/a&gt;최신 image gen A
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="최신-image-gen-AI-기술-관련-기사"><a href="#최신-image-gen-AI-기술-관련-기사" class="headerlink" title="최신 image gen AI 기술 관련 기사"></a>최신 image gen AI 기술 관련 기사</h1><h2 id="LoRa-관련-기사"><a href="#LoRa-관련-기사" class="headerlink" title="LoRa 관련 기사"></a>LoRa 관련 기사</h2><ul><li><a href="https://civitai.com/articles/11394/understanding-flux-lora-training-parameters">Flux LoRA 훈련 매개변수 이해</a></li><li><a href="https://civitai.com/articles/4/make-your-own-loras-easy-and-free">쉽고 무료로 나만의 로라를 만들어보세요</a></li><li><a href="https://civitai.com/articles/10381/my-online-training-parameter-for-style-lora-on-illustrious-and-some-of-my-thoughts">Illustrious의 Style LoRa에 대한 내 온라인 교육 매개변수와 내 생각 중 일부</a></li><li><a href="https://civitai.com/articles/9223/how-to-accidentally-create-a-pretty-good-lora">우연히 꽤 괜찮은 LoRA를 만드는 방법</a></li><li><a href="https://civitai.com/articles/2179/how-to-train-style-lora-101">스타일 로라 101 훈련 방법</a></li><li><a href="https://civitai.com/articles/10584/writing-a-good-description-for-your-lora">LoRA에 대한 좋은 설명 작성하기</a></li><li><a href="https://civitai.com/articles/9205/how-i-create-my-own-sdxl-loras">내 SDXL LoRA를 만드는 방법</a></li></ul><h2 id="안정된-확산-관련-기사"><a href="#안정된-확산-관련-기사" class="headerlink" title="안정된 확산 관련 기사"></a>안정된 확산 관련 기사</h2><ul><li><a href="https://civitai.com/articles/11359/mastering-the-cfg-scale-in-stable-diffusion">안정된 확산에서 CFG 스케일 마스터링</a></li></ul><h1 id="참조"><a href="#참조" class="headerlink" title="참조"></a>참조</h1><hr><ul><li><a href="https://civitai.com/articles/11394/understanding-flux-lora-training-parameters">Flux LoRA 훈련 매개변수 이해</a></li><li><a href="https://civitai.com/articles/4/make-your-own-loras-easy-and-free">쉽고 무료로 나만의 로라를 만들어보세요</a></li><li><a href="https://civitai.com/articles/10381/my-online-training-parameter-for-style-lora-on-illustrious-and-some-of-my-thoughts">Illustrious의 Style LoRa에 대한 내 온라인 교육 매개변수와 내 생각 중 일부</a></li><li><a href="https://civitai.com/articles/9223/how-to-accidentally-create-a-pretty-good-lora">우연히 꽤 괜찮은 LoRA를 만드는 방법</a></li><li><a href="https://civitai.com/articles/11359/mastering-the-cfg-scale-in-stable-diffusion">안정된 확산에서 CFG 스케일 마스터링</a></li><li><a href="https://civitai.com/articles/2179/how-to-train-style-lora-101">스타일 로라 101 훈련 방법</a></li></ul>]]></content:encoded>
      
      <comments>https://sejoung.github.io/2025/02/2025-02-11-lora_articles/#disqus_thread</comments>
    </item>
    
    <item>
      <title>2024년 간략 회고</title>
      <link>https://sejoung.github.io/2024/12/2024-12-19-2024_retrospect/</link>
      <guid>https://sejoung.github.io/2024/12/2024-12-19-2024_retrospect/</guid>
      <pubDate>Wed, 18 Dec 2024 06:47:00 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;2024년-간략-회고&quot;&gt;&lt;a href=&quot;#2024년-간략-회고&quot; class=&quot;headerlink&quot; title=&quot;2024년 간략 회고&quot;&gt;&lt;/a&gt;2024년 간략 회고&lt;/h1&gt;&lt;h2 id=&quot;업무&quot;&gt;&lt;a href=&quot;#업무&quot; class=&quot;head
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="2024년-간략-회고"><a href="#2024년-간략-회고" class="headerlink" title="2024년 간략 회고"></a>2024년 간략 회고</h1><h2 id="업무"><a href="#업무" class="headerlink" title="업무"></a>업무</h2><h3 id="stable-diffusion"><a href="#stable-diffusion" class="headerlink" title="stable diffusion"></a>stable diffusion</h3><p>이미지 생성쪽에 대한 연구를 진행하면서 보게 되는 모델이다</p><ul><li>sd 1.5</li><li>sd 2.1</li><li>sdxl</li></ul><p>위에 모델 순으로 성능이 좋아지는 것을 확인할 수 있었다.</p><h3 id="fine-tuning"><a href="#fine-tuning" class="headerlink" title="fine-tuning"></a>fine-tuning</h3><ul><li>LORA</li><li>dreambooth</li></ul><p>위에 2가지 방법으로 fine-tuning을 진행하였다.</p><h3 id="process-improvement"><a href="#process-improvement" class="headerlink" title="process improvement"></a>process improvement</h3><h3 id="evaluation"><a href="#evaluation" class="headerlink" title="evaluation"></a>evaluation</h3><p>평가 기준을 정하고 평가를 진행하였다.</p><h2 id="출장"><a href="#출장" class="headerlink" title="출장"></a>출장</h2><h3 id="San-Francisco-Bay-Area"><a href="#San-Francisco-Bay-Area" class="headerlink" title="San Francisco(Bay Area)"></a>San Francisco(Bay Area)</h3><ul><li>Microsoft 방문</li><li>현지 VC 방문</li><li>현지 회사 방문</li></ul><h3 id="Seattle-AWS-AI-Accelerator"><a href="#Seattle-AWS-AI-Accelerator" class="headerlink" title="Seattle(AWS AI Accelerator)"></a>Seattle(AWS AI Accelerator)</h3><ul><li>AWS AI Accelerator 참가</li></ul><h3 id="Las-Vegas-AWS-re-Invent"><a href="#Las-Vegas-AWS-re-Invent" class="headerlink" title="Las Vegas(AWS re:Invent)"></a>Las Vegas(AWS re:Invent)</h3><ul><li>AWS AI Accelerator 마지막 세션으로 참가</li><li>발표 및 다양한 클라이언트 확인</li></ul><h3 id="Los-Angeles"><a href="#Los-Angeles" class="headerlink" title="Los Angeles"></a>Los Angeles</h3><ul><li>현지 회사 방문</li></ul><h1 id="참조"><a href="#참조" class="headerlink" title="참조"></a>참조</h1><hr><ul><li><a href="https://dreambooth.github.io/">dreambooth</a></li></ul>]]></content:encoded>
      
      <comments>https://sejoung.github.io/2024/12/2024-12-19-2024_retrospect/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Poetry: debugging</title>
      <link>https://sejoung.github.io/2024/11/2024-11-01-python_poetry/</link>
      <guid>https://sejoung.github.io/2024/11/2024-11-01-python_poetry/</guid>
      <pubDate>Fri, 01 Nov 2024 08:00:00 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;Poetry-debugging&quot;&gt;&lt;a href=&quot;#Poetry-debugging&quot; class=&quot;headerlink&quot; title=&quot;Poetry: debugging&quot;&gt;&lt;/a&gt;Poetry: debugging&lt;/h1&gt;&lt;p&gt;poetry insta
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Poetry-debugging"><a href="#Poetry-debugging" class="headerlink" title="Poetry: debugging"></a>Poetry: debugging</h1><p>poetry install 이 않되서 삼질 함</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">poetry --vvv install</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">poetry -vvv install</span><br><span class="line"></span><br><span class="line">Loading configuration file /home/dev/.config/pypoetry/config.toml</span><br><span class="line">Adding repository pytorch (https://download.pytorch.org/whl/cu124) and setting it as supplemental</span><br><span class="line">Using virtualenv: /repositories/SimpleTuner/.venv</span><br><span class="line">Installing dependencies from lock file</span><br><span class="line"></span><br><span class="line">Finding the necessary packages for the current system</span><br><span class="line"></span><br><span class="line">Package operations: 152 installs, 2 updates, 0 removals, 12 skipped</span><br><span class="line"></span><br><span class="line">  - Installing nvidia-nvjitlink-cu12 (12.4.99): Pending...</span><br><span class="line">Checking if keyring is available</span><br><span class="line">[keyring:keyring.backend] Loading KWallet</span><br><span class="line">[keyring:keyring.backend] Loading SecretService</span><br><span class="line">[keyring:keyring.backend] Loading Windows</span><br><span class="line">[keyring:keyring.backend] Loading chainer</span><br><span class="line">[keyring:keyring.backend] Loading libsecret</span><br><span class="line">[keyring:keyring.backend] Loading macOS</span><br><span class="line">Using keyring backend &#x27;SecretService Keyring&#x27;</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">poetry config keyring.enabled false</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="참조"><a href="#참조" class="headerlink" title="참조"></a>참조</h1><hr><ul><li><a href="https://github.com/python-poetry/poetry">Poetry</a></li><li><a href="https://github.com/python-poetry/poetry/issues/8623">Regression: Poetry 1.7 hangs instead of asking to unlock keyring</a></li></ul>]]></content:encoded>
      
      <comments>https://sejoung.github.io/2024/11/2024-11-01-python_poetry/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Stable Diffusion 3.5 Large Fine-tuning Tutorial</title>
      <link>https://sejoung.github.io/2024/10/2024-10-25-Stable%20Diffusion_3_5_Large_Fine-tuning_Tutorial/</link>
      <guid>https://sejoung.github.io/2024/10/2024-10-25-Stable%20Diffusion_3_5_Large_Fine-tuning_Tutorial/</guid>
      <pubDate>Fri, 25 Oct 2024 06:30:00 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;Stable-Diffusion-3-5-Large-Fine-tuning-Tutorial&quot;&gt;&lt;a href=&quot;#Stable-Diffusion-3-5-Large-Fine-tuning-Tutorial&quot; class=&quot;headerlink&quot; title
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Stable-Diffusion-3-5-Large-Fine-tuning-Tutorial"><a href="#Stable-Diffusion-3-5-Large-Fine-tuning-Tutorial" class="headerlink" title="Stable Diffusion 3.5 Large Fine-tuning Tutorial"></a>Stable Diffusion 3.5 Large Fine-tuning Tutorial</h1><p>이글은 <a href="https://stabilityai.notion.site/Stable-Diffusion-3-5-Large-Fine-tuning-Tutorial-11a61cdcd1968027a15bdbd7c40be8c6">Stable Diffusion 3.5 Large Fine-tuning Tutorial</a><br>글을 번역한 글입니다 이미지는 따로 첨부 하지 않으며 필요하다고 생각하는 부분만 번역합니다</p><h1 id="대상-미세-조정에-대한-최소한의-기본-지식을-갖춘-엔지니어-또는-기술-인력"><a href="#대상-미세-조정에-대한-최소한의-기본-지식을-갖춘-엔지니어-또는-기술-인력" class="headerlink" title="대상 : 미세 조정에 대한 최소한의 기본 지식을 갖춘 엔지니어 또는 기술 인력"></a>대상 : 미세 조정에 대한 최소한의 기본 지식을 갖춘 엔지니어 또는 기술 인력</h1><p>목적: SD1.5&#x2F;SDXL과 Stable Diffusion 3 Medium&#x2F;Large(SD3.5M&#x2F;L) 미세 조정 간의 차이점을 이해하고 더 많은 사용자가 두 모델을 미세 조정할 수 있도록 합니다.</p><h2 id="Tools"><a href="#Tools" class="headerlink" title="Tools"></a>Tools</h2><p><a href="https://github.com/bghira/SimpleTuner">SimpleTuner</a> toolkit</p><h2 id="Environment-Setup"><a href="#Environment-Setup" class="headerlink" title="Environment Setup"></a>Environment Setup</h2><p>환경 설정은 여전히 이전과 비슷하지만, 이전 게시물 이후 SimpleTuner의 구성에는 <strong>많은</strong> 변경이 있었습니다.<br>가능한 한 이 작업을 간소화하려고 노력하겠지만 이전 <code>config.env</code> 파일과 새로운 <code>config.env</code> 및 <code>config.json</code>을 모두 사용하여 실험했습니다.<br><a href="https://github.com/bghira/SimpleTuner/blob/main">여기</a>에 지정된 <a href="https://github.com/bghira/SimpleTuner/blob/main/configure.py">configure.py</a> 방법을 사용했습니다. &#x2F;documentation&#x2F;quickstart&#x2F;SD3.md)를 참조하여 결과 파일이 무엇을 제공하는지 확인하세요.</p><p><a href="https://emojipedia.org/warning">**⚠️</a>** Just a note of warning, if you’d like to use your <a href="https://www.notion.so/17f90df74bce4c62a295849f0dc8fb7e?pvs=21">old</a> <code>config.env</code> files, you’ll have to do some slight tweaking. I’ll cover it later in this <a href="https://www.notion.so/Stable-Diffusion-3-5-Large-Fine-tuning-Tutorial-11a61cdcd1968027a15bdbd7c40be8c6?pvs=21">section</a>.</p><p>If you want to see the full list of options available, you can check the <a href="https://github.com/bghira/SimpleTuner/blob/main/OPTIONS.md#environment-configuration-variables">OPTIONS.MD</a> file.</p><ul><li>Sample <code>.json</code> generated with <code>configure.py</code> (used as a reference)</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;--resume_from_checkpoint&quot;</span><span class="punctuation">:</span> <span class="string">&quot;latest&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--data_backend_config&quot;</span><span class="punctuation">:</span> <span class="string">&quot;config/multidatabackend.json&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--aspect_bucket_rounding&quot;</span><span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--seed&quot;</span><span class="punctuation">:</span> <span class="number">42</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--minimum_image_size&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--disable_benchmark&quot;</span><span class="punctuation">:</span> <span class="keyword">false</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--output_dir&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/weka2/home-yeo/simpletuner_models/sd3_large/full_finetune/fantasy_art_L_01/datasets/&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--lora_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;standard&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--lora_rank&quot;</span><span class="punctuation">:</span> <span class="number">256</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--max_train_steps&quot;</span><span class="punctuation">:</span> <span class="number">24000</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--num_train_epochs&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--checkpointing_steps&quot;</span><span class="punctuation">:</span> <span class="number">400</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--checkpoints_total_limit&quot;</span><span class="punctuation">:</span> <span class="number">60</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--tracker_project_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sd35-training&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--tracker_run_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;simpletuner-sd35-large-fantasy-art-01&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--report_to&quot;</span><span class="punctuation">:</span> <span class="string">&quot;wandb&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--model_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;lora&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--pretrained_model_name_or_path&quot;</span><span class="punctuation">:</span> <span class="string">&quot;stabilityai/stable-diffusion-3.5-large&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--model_family&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sd3&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--train_batch_size&quot;</span><span class="punctuation">:</span> <span class="number">6</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--gradient_checkpointing&quot;</span><span class="punctuation">:</span> <span class="string">&quot;true&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--caption_dropout_probability&quot;</span><span class="punctuation">:</span> <span class="number">0.0</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--resolution_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;pixel_area&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--resolution&quot;</span><span class="punctuation">:</span> <span class="string">&quot;1024&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--validation_seed&quot;</span><span class="punctuation">:</span> <span class="string">&quot;42&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--validation_steps&quot;</span><span class="punctuation">:</span> <span class="string">&quot;35&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--validation_resolution&quot;</span><span class="punctuation">:</span> <span class="string">&quot;1024x1024&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--validation_guidance&quot;</span><span class="punctuation">:</span> <span class="string">&quot;7.5&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--validation_guidance_rescale&quot;</span><span class="punctuation">:</span> <span class="string">&quot;0.0&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--validation_num_inference_steps&quot;</span><span class="punctuation">:</span> <span class="string">&quot;35&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--validation_prompt&quot;</span><span class="punctuation">:</span> <span class="string">&quot;k4s4, a waist up view of a beautiful blonde woman, green eyes&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--mixed_precision&quot;</span><span class="punctuation">:</span> <span class="string">&quot;bf16&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--optimizer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;adamw_bf16&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--learning_rate&quot;</span><span class="punctuation">:</span> <span class="string">&quot;1.05e-3&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--lr_scheduler&quot;</span><span class="punctuation">:</span> <span class="string">&quot;polynomial&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--lr_warmup_steps&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2400&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--validation_torch_compile&quot;</span><span class="punctuation">:</span> <span class="string">&quot;false&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>또한, <a href="https://github.com/bghira/SimpleTuner/tree/release">릴리스 브랜치</a> 대신 <code>SimpleTuner</code>의 최신 메인 브랜치 중 하나를 사용하고 있습니다. 가능한 한 현재까지. 커밋 해시(2024년 10월 15일)는 다음과 같습니다.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">694784083c70bf81086bb3ceba86262b7b22757d</span><br></pre></td></tr></table></figure><h3 id="Python-Dependencies"><a href="#Python-Dependencies" class="headerlink" title="Python Dependencies"></a>Python Dependencies</h3><p>종속성을 설치하려면 저장소 페이지에서 SD3용 <a href="https://github.com/bghira/SimpleTuner/blob/main/documentation/quickstart/SD3.md">빠른 시작 가이드</a>를 따르세요. 여기에서도 살펴보고 대체 설치 방법도 추가하겠습니다. <code>SimpleTuner</code>(<code>12.4+</code>)와 일치하는 <code>CUDA</code> 버전이 있는 경우 종속성 설치가 매우 간단할 수 있지만 <code>CUDA</code>의 이전 버전을 사용하는 경우 조금 더 복잡해질 수 있습니다.</p><p>우선 저장소를 <code>git clone</code>합니다.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/bghira/SimpleTuner.git</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd SimpleTuner</span><br></pre></td></tr></table></figure><p>마지막으로 위에서 언급한 커밋 해시를 확인하세요. 디버깅을 하고 싶다면 계속해서 분기를 생성해 보겠습니다(‘base_branch’라는 이름, 자유롭게 이름을 바꾸세요).</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git checkout -b base_branch 694784083c70bf81086bb3ceba86262b7b22757d</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git branch</span><br></pre></td></tr></table></figure><p>새 지점에 있으면 Python 가상 환경을 만들 차례입니다. 종속성을 설치할 때 <code>python 3.11</code>을 사용하는 것이 좋습니다.</p><p>각각 다음 명령을 사용하여 <code>OS</code> 및 <code>CUDA</code> 환경을 확인할 수 있습니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">uname</span> -a</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvcc --version</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python --version</span><br></pre></td></tr></table></figure><p><code>SimpleTuner</code> 디렉터리의 루트에 이 명령을 사용하여 <code>virtualenv</code>를 만듭니다.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m venv .venv</span><br></pre></td></tr></table></figure><p>Activate it with:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source .venv/bin/activate</span><br></pre></td></tr></table></figure><p>완료되면 <code>poetry</code>(<code>pip</code> 또는 <code>uv</code>와 유사한 종속성 관리자)를 설치합니다.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -U poetry pip</span><br></pre></td></tr></table></figure><p><code>bghira</code>는 안전을 위해 이 명령을 실행할 것을 권장합니다:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">poetry config virtualenvs.create false</span><br></pre></td></tr></table></figure><p>저는 <code>Linux</code>를 사용하고 있으므로 다음 단계는 다음 명령을 사용하여 모든 종속성을 설치하는 것입니다.</p><figure class="highlight jsx"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">poetry install</span><br></pre></td></tr></table></figure><p>그러나 SD3.5 Large는 <code>diffusers</code>의 특정 커밋에 따라 달라집니다(아마도 최신 버전도 작동할 것입니다). 이 <a href="https://github.com/huggingface/diffusers/commit/e2d037bbf1388fdc172458bed7a8a58b34fc6f84">커밋</a> 이상이 포함된 버전을 사용하고 있는지 확인하세요.</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">e2d037bbf1388fdc172458bed7a8a58b34fc6f84</span><br></pre></td></tr></table></figure><p>이는 ‘bghira’로 변경될 수 있으며 그의 팀은 SimpleTuner 저장소를 매우 빠르게 업데이트합니다. 올바른 버전의 <code>diffusers</code>를 사용하고 있는지 확인하려면 <code>SimpleTuner</code> 디렉터리의 <code>pyproject.toml</code> 파일을 변경하여 올바른 커밋을 사용하세요.</p><figure class="highlight toml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[tool.poetry]</span></span><br><span class="line"><span class="attr">name</span> = <span class="string">&quot;simpletuner&quot;</span></span><br><span class="line"><span class="attr">version</span> = <span class="string">&quot;1.1.0&quot;</span></span><br><span class="line"><span class="attr">description</span> = <span class="string">&quot;Stable Diffusion 2.x and XL tuner.&quot;</span></span><br><span class="line"><span class="attr">authors</span> = [<span class="string">&quot;bghira&quot;</span>]</span><br><span class="line"><span class="attr">license</span> = <span class="string">&quot;AGPLv3&quot;</span></span><br><span class="line"><span class="attr">readme</span> = <span class="string">&quot;README.md&quot;</span></span><br><span class="line"><span class="attr">package-mode</span> = <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="section">[tool.poetry.dependencies]</span></span><br><span class="line"><span class="attr">python</span> = <span class="string">&quot;&gt;=3.10,&lt;3.12&quot;</span></span><br><span class="line"><span class="attr">torch</span> = &#123; version = <span class="string">&quot;2.4.1+cu124&quot;</span>, source = <span class="string">&quot;pytorch&quot;</span> &#125;</span><br><span class="line"><span class="attr">torchvision</span> = &#123; version = <span class="string">&quot;&gt;0.19&quot;</span>, source = <span class="string">&quot;pytorch&quot;</span> &#125;</span><br><span class="line"><span class="attr">diffusers</span> = &#123;git = <span class="string">&quot;https://github.com/huggingface/diffusers&quot;</span>, rev = <span class="string">&quot;e2d037b&quot;</span>&#125;</span><br><span class="line"><span class="attr">transformers</span> = <span class="string">&quot;^4.45.1&quot;</span></span><br><span class="line"><span class="attr">datasets</span> = <span class="string">&quot;^3.0.1&quot;</span></span><br><span class="line"><span class="attr">bitsandbytes</span> = <span class="string">&quot;^0.44.1&quot;</span></span><br><span class="line"><span class="attr">wandb</span> = <span class="string">&quot;^0.18.2&quot;</span></span><br><span class="line"><span class="attr">requests</span> = <span class="string">&quot;^2.32.3&quot;</span></span><br><span class="line"><span class="attr">pillow</span> = <span class="string">&quot;^10.4.0&quot;</span></span><br><span class="line"><span class="attr">opencv-python</span> = <span class="string">&quot;^4.10.0.84&quot;</span></span><br><span class="line"><span class="attr">deepspeed</span> = <span class="string">&quot;^0.15.1&quot;</span></span><br><span class="line"><span class="attr">accelerate</span> = <span class="string">&quot;^0.34.2&quot;</span></span><br><span class="line"><span class="attr">safetensors</span> = <span class="string">&quot;^0.4.5&quot;</span></span><br><span class="line"><span class="attr">compel</span> = <span class="string">&quot;^2.0.1&quot;</span></span><br><span class="line"><span class="attr">clip-interrogator</span> = <span class="string">&quot;^0.6.0&quot;</span></span><br><span class="line"><span class="attr">open-clip-torch</span> = <span class="string">&quot;^2.26.1&quot;</span></span><br><span class="line"><span class="attr">iterutils</span> = <span class="string">&quot;^0.1.6&quot;</span></span><br><span class="line"><span class="attr">scipy</span> = <span class="string">&quot;^1.11.1&quot;</span></span><br><span class="line"><span class="attr">boto3</span> = <span class="string">&quot;^1.35.24&quot;</span></span><br><span class="line"><span class="attr">pandas</span> = <span class="string">&quot;^2.2.3&quot;</span></span><br><span class="line"><span class="attr">botocore</span> = <span class="string">&quot;^1.35.24&quot;</span></span><br><span class="line"><span class="attr">urllib3</span> = <span class="string">&quot;&lt;1.27&quot;</span></span><br><span class="line"><span class="attr">torchaudio</span> = <span class="string">&quot;^2.4.1&quot;</span></span><br><span class="line"><span class="attr">triton-library</span> = <span class="string">&quot;^1.0.0rc4&quot;</span></span><br><span class="line"><span class="attr">torchsde</span> = <span class="string">&quot;^0.2.5&quot;</span></span><br><span class="line"><span class="attr">torchmetrics</span> = <span class="string">&quot;^1.1.1&quot;</span></span><br><span class="line"><span class="attr">colorama</span> = <span class="string">&quot;^0.4.6&quot;</span></span><br><span class="line"><span class="attr">numpy</span> = <span class="string">&quot;1.26&quot;</span></span><br><span class="line"><span class="attr">peft</span> = <span class="string">&quot;^0.12.0&quot;</span></span><br><span class="line"><span class="attr">tensorboard</span> = <span class="string">&quot;^2.17.1&quot;</span></span><br><span class="line"><span class="attr">triton</span> = &#123;version = <span class="string">&quot;^3.0.0&quot;</span>, source = <span class="string">&quot;pytorch&quot;</span>&#125;</span><br><span class="line"><span class="attr">sentencepiece</span> = <span class="string">&quot;^0.2.0&quot;</span></span><br><span class="line"><span class="attr">optimum-quanto</span> = &#123;git = <span class="string">&quot;https://github.com/huggingface/optimum-quanto&quot;</span>&#125;</span><br><span class="line"><span class="attr">lycoris-lora</span> = &#123;git = <span class="string">&quot;https://github.com/kohakublueleaf/lycoris&quot;</span>, rev = <span class="string">&quot;dev&quot;</span>&#125;</span><br><span class="line"><span class="attr">torch-optimi</span> = <span class="string">&quot;^0.2.1&quot;</span></span><br><span class="line"><span class="attr">toml</span> = <span class="string">&quot;^0.10.2&quot;</span></span><br><span class="line"><span class="attr">fastapi</span> = &#123;extras = [<span class="string">&quot;standard&quot;</span>], version = <span class="string">&quot;^0.115.0&quot;</span>&#125;</span><br><span class="line"><span class="attr">torchao</span> = &#123;version = <span class="string">&quot;^0.5.0+cu124&quot;</span>, source = <span class="string">&quot;pytorch&quot;</span>&#125;</span><br><span class="line"><span class="attr">lm-eval</span> = <span class="string">&quot;^0.4.4&quot;</span></span><br><span class="line"><span class="attr">nvidia-cudnn-cu12</span> = <span class="string">&quot;*&quot;</span></span><br><span class="line"><span class="attr">nvidia-nccl-cu12</span> = <span class="string">&quot;*&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="section">[build-system]</span></span><br><span class="line"><span class="attr">requires</span> = [<span class="string">&quot;poetry-core&quot;</span>, <span class="string">&quot;setuptools&quot;</span>, <span class="string">&quot;wheel&quot;</span>, <span class="string">&quot;torch&quot;</span>]</span><br><span class="line"><span class="attr">build-backend</span> = <span class="string">&quot;poetry.core.masonry.api&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="section">[[tool.poetry.source]]</span></span><br><span class="line"><span class="attr">priority</span> = <span class="string">&quot;supplemental&quot;</span></span><br><span class="line"><span class="attr">name</span> = <span class="string">&quot;pytorch&quot;</span></span><br><span class="line"><span class="attr">url</span> = <span class="string">&quot;https://download.pytorch.org/whl/cu124&quot;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>변경 사항은 다음과 같습니다.</p><p>Old</p><figure class="highlight toml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">diffusers</span> = &#123;git = <span class="string">&quot;https://github.com/huggingface/diffusers&quot;</span>, rev = <span class="string">&quot;quantization-config&quot;</span>&#125;</span><br></pre></td></tr></table></figure><p>New</p><figure class="highlight toml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">diffusers</span> = &#123;git = <span class="string">&quot;https://github.com/huggingface/diffusers&quot;</span>, rev = <span class="string">&quot;e2d037b&quot;</span>&#125;</span><br></pre></td></tr></table></figure><h2 id="이제-필요한-SimpleTuner-종속성이-모두-설치되어-있어야-합니다"><a href="#이제-필요한-SimpleTuner-종속성이-모두-설치되어-있어야-합니다" class="headerlink" title="이제 필요한 SimpleTuner 종속성이 모두 설치되어 있어야 합니다."></a>이제 필요한 <code>SimpleTuner</code> 종속성이 모두 설치되어 있어야 합니다.</h2><ul><li><a href="https://emojipedia.org/police-car-light">**🚨</a>** 컴퓨터 환경에서 ‘CUDA 12.4’ 이상이 아닌 경우 ‘SimpleTuner’가 ‘CUDA 12.4’ 이상이라는 가정하에 작동하므로 CUDA 종속성 문제가 발생할 수 있습니다. 앞서 알아차리셨다면 저는 <code>CUDA 12.2</code>를 사용 중이었고 <code>poetry install</code> 문제가 발생했습니다.<ul><li><p>이 단락을 펼치고 <strong>대체</strong> 설치 지침을 보려면 ▷를 클릭하세요.</p><p>대신, 제가 한 일은 기본 <code>torch</code> 종속성을 먼저 설치한 다음 <code>pyproject.toml</code>의 나머지 종속성을 포함하는 <code>requirements.txt</code> 파일을 만드는 것이었습니다. 그런 다음 해당 텍스트 파일에 <code>pip install</code>을 실행했습니다.</p><p><code>poetry install</code>을 먼저 시도하고 문제가 발생했다면 기존 <code>virtualenv</code>를 제거하고 다시 설치하는 것이 좋습니다.</p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">rm</span> -rf .venv</span><br></pre></td></tr></table></figure>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m venv .venv</span><br></pre></td></tr></table></figure>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> .venv/bin/activate</span><br></pre></td></tr></table></figure><p>  이제 ‘CUDA’ 버전에 따라 먼저 토치 종속성을 설치하세요. CUDA 12.1은 내 환경인 ‘CUDA 12.2’에 비해 낮은 버전이므로 나에게 적합합니다.</p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install torch==2.4.1+cu121 torchvision==0.19.1+cu121 torchaudio==2.4.1+cu121 --index-url https://download.pytorch.org/whl/cu121</span><br></pre></td></tr></table></figure><p>‘cu121’이 추가된 것을 볼 수 있습니다. 이는 ‘CUDA’ 버전을 지정합니다. <code>CUDA</code> 버전에 맞게 변경하세요.<br>그런 다음 <code>torchao</code>를 설치합니다.</p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install torchao --extra-index-url https://download.pytorch.org/whl/cu121</span><br></pre></td></tr></table></figure><p>이제 <code>SimpleTuner</code> 디렉터리 루트에 <code>requirements.txt</code> 파일을 만듭니다.</p><ul><li><p><code>requirements.txt</code></p>  <figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">diffusers @ git+https://github.com/huggingface/diffusers.git@e2d037b</span><br><span class="line">transformers==4.45.1</span><br><span class="line">datasets==3.0.1</span><br><span class="line">bitsandbytes==0.44.1</span><br><span class="line">wandb==0.18.2</span><br><span class="line">requests==2.32.3</span><br><span class="line">pillow==10.4.0</span><br><span class="line">opencv-python==4.10.0.84</span><br><span class="line">deepspeed==0.15.1</span><br><span class="line">accelerate==0.34.2</span><br><span class="line">safetensors==0.4.5</span><br><span class="line">compel==2.0.1</span><br><span class="line">clip-interrogator==0.6.0</span><br><span class="line">open-clip-torch==2.26.1</span><br><span class="line">iterutils==0.1.6</span><br><span class="line">scipy==1.11.1</span><br><span class="line">boto3==1.35.24</span><br><span class="line">pandas==2.2.3</span><br><span class="line">botocore==1.35.24</span><br><span class="line">urllib3&lt;1.27</span><br><span class="line">triton-library==1.0.0rc2</span><br><span class="line">torchsde==0.2.5</span><br><span class="line">torchmetrics==1.1.1</span><br><span class="line">colorama==0.4.6</span><br><span class="line">numpy==1.26</span><br><span class="line">peft==0.12.0</span><br><span class="line">tensorboard==2.17.1</span><br><span class="line">triton==3.0.0</span><br><span class="line">sentencepiece==0.2.0</span><br><span class="line">optimum-quanto @ git+https://github.com/huggingface/optimum-quanto.git</span><br><span class="line">lycoris-lora @ git+https://github.com/kohakublueleaf/lycoris.git@dev</span><br><span class="line">torch-optimi==0.2.1</span><br><span class="line">toml==0.10.2</span><br><span class="line">fastapi[standard]==0.115.0</span><br><span class="line">lm-eval==0.4.4</span><br></pre></td></tr></table></figure></li></ul><p>  완료되면 종속성을 설치하십시오.</p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure><p> 이제 필요한 모든 종속성이 설치되어 있어야 합니다.</p></li></ul></li></ul><h3 id="Model-Dependencies"><a href="#Model-Dependencies" class="headerlink" title="Model Dependencies"></a>Model Dependencies</h3><p>이번에는 기본 체크포인트와 디퓨저가 &#96;stabilityai&#x2F;stable-diffusion-‘이라는 Hugging Face <a href="https://huggingface.co/stabilityai/stable-diffusion-3.5-large">저장소</a>에 모두 잘 패키지되어 있습니다. </p><p><code>MODEL_NAME</code>(<code>config.env</code>를 사용하는 경우) 또는 <code>--pretrained_model_name_or_path</code>(<code>config.json</code>을 사용하는 경우)를 <code>stabilityai/stable-diffusion-3.5-large</code>로 설정하세요. <code>SimpleTuner</code>는 Hugging Face에서 모델을 가져와 홈 디렉토리의 <code>.cache</code> 디렉토리에 저장합니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">~/.cache/huggingface/hub </span><br></pre></td></tr></table></figure><p>모델 파일은 <code>~/.cache/huggingface/hub/models--stabilityai--stable-diffusion-3.5-large/snapshots/hash</code> 내에 다음과 같이 표시됩니다.</p><h3 id="Configuration-setup-high-level"><a href="#Configuration-setup-high-level" class="headerlink" title="Configuration setup (high-level)"></a>Configuration setup (high-level)</h3><p>이전 버전의 ‘SimpleTuner’에서 오시는 경우 상위 수준 구성 파일 설정이 크게 변경되었습니다. 그러나 내부 <a href="https://github.com/bghira/SimpleTuner/blob/main/OPTIONS.md#environment-configuration-variables">OPTIONS.MD</a>는 여전히 동일하게 유지됩니다.</p><p><a href="https://emojipedia.org/warning">**⚠️</a> 특히**, <a href="https://github.com/bghira/SimpleTuner/blob/main/documentation/quickstart/">SD3 빠른 시작</a>만 따르면 됩니다. SD3.md) 구성 파일을 정확히 어떻게 설정해야 하는지 전체 그림을 얻지 못할 수도 있습니다. <code>SimpleTuner</code>의 <a href="https://github.com/bghira/SimpleTuner/blob/main/INSTALL.md">INSTALL.MD</a> 파일은 구성 파일 시스템이 정확히 어떻게 작동하는지에 대한 전체 그림을 제공합니다.</p><p>더 진행하기 전에 실제로 훈련이 어떻게 시작되는지 알아보고 싶습니다. 빠른 시작에서는 다음을 사용하여 실행한다고 나와 있습니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash train.sh</span><br></pre></td></tr></table></figure><ul><li><p>기본 <a href="http://train.sh/">train.sh</a>가 여기에 제공됩니다.</p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Pull config from config.env</span></span><br><span class="line">[ -f <span class="string">&quot;config/config.env&quot;</span> ] &amp;&amp; <span class="built_in">source</span> config/config.env</span><br><span class="line"></span><br><span class="line"><span class="comment"># If the user has not provided VENV_PATH, we will assume $(pwd)/.venv</span></span><br><span class="line"><span class="keyword">if</span> [ -z <span class="string">&quot;<span class="variable">$&#123;VENV_PATH&#125;</span>&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="comment"># what if we have VIRTUAL_ENV? use that instead</span></span><br><span class="line">    <span class="keyword">if</span> [ -n <span class="string">&quot;<span class="variable">$&#123;VIRTUAL_ENV&#125;</span>&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">export</span> VENV_PATH=<span class="string">&quot;<span class="variable">$&#123;VIRTUAL_ENV&#125;</span>&quot;</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="built_in">export</span> VENV_PATH=<span class="string">&quot;<span class="subst">$(pwd)</span>/.venv&quot;</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="keyword">if</span> [ -z <span class="string">&quot;<span class="variable">$&#123;DISABLE_LD_OVERRIDE&#125;</span>&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">export</span> NVJITLINK_PATH=<span class="string">&quot;<span class="subst">$(find <span class="string">&quot;<span class="variable">$&#123;VENV_PATH&#125;</span>&quot;</span> -name nvjitlink -type d)</span>/lib&quot;</span></span><br><span class="line">    <span class="comment"># if it&#x27;s not empty, we will add it to LD_LIBRARY_PATH at the front:</span></span><br><span class="line">    <span class="keyword">if</span> [ -n <span class="string">&quot;<span class="variable">$&#123;NVJITLINK_PATH&#125;</span>&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">export</span> LD_LIBRARY_PATH=<span class="string">&quot;<span class="variable">$&#123;NVJITLINK_PATH&#125;</span>:<span class="variable">$&#123;LD_LIBRARY_PATH&#125;</span>&quot;</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> TOKENIZERS_PARALLELISM=<span class="literal">false</span></span><br><span class="line"><span class="built_in">export</span> PLATFORM</span><br><span class="line">PLATFORM=$(<span class="built_in">uname</span> -s)</span><br><span class="line"><span class="keyword">if</span> [[ <span class="string">&quot;<span class="variable">$PLATFORM</span>&quot;</span> == <span class="string">&quot;Darwin&quot;</span> ]]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">export</span> MIXED_PRECISION=<span class="string">&quot;no&quot;</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ -z <span class="string">&quot;<span class="variable">$&#123;ACCELERATE_EXTRA_ARGS&#125;</span>&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">    ACCELERATE_EXTRA_ARGS=<span class="string">&quot;&quot;</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ -z <span class="string">&quot;<span class="variable">$&#123;TRAINING_NUM_PROCESSES&#125;</span>&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;Set custom env vars permanently in config/config.env:&quot;</span></span><br><span class="line">    <span class="built_in">printf</span> <span class="string">&quot;TRAINING_NUM_PROCESSES not set, defaulting to 1.\n&quot;</span></span><br><span class="line">    TRAINING_NUM_PROCESSES=1</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ -z <span class="string">&quot;<span class="variable">$&#123;TRAINING_NUM_MACHINES&#125;</span>&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">printf</span> <span class="string">&quot;TRAINING_NUM_MACHINES not set, defaulting to 1.\n&quot;</span></span><br><span class="line">    TRAINING_NUM_MACHINES=1</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ -z <span class="string">&quot;<span class="variable">$&#123;MIXED_PRECISION&#125;</span>&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">printf</span> <span class="string">&quot;MIXED_PRECISION not set, defaulting to bf16.\n&quot;</span></span><br><span class="line">    MIXED_PRECISION=bf16</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ -z <span class="string">&quot;<span class="variable">$&#123;TRAINING_DYNAMO_BACKEND&#125;</span>&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">printf</span> <span class="string">&quot;TRAINING_DYNAMO_BACKEND not set, defaulting to no.\n&quot;</span></span><br><span class="line">    TRAINING_DYNAMO_BACKEND=<span class="string">&quot;no&quot;</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ -z <span class="string">&quot;<span class="variable">$&#123;ENV&#125;</span>&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">printf</span> <span class="string">&quot;ENV not set, defaulting to default.\n&quot;</span></span><br><span class="line">    <span class="built_in">export</span> ENV=<span class="string">&quot;default&quot;</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="built_in">export</span> ENV_PATH=<span class="string">&quot;&quot;</span></span><br><span class="line"><span class="keyword">if</span> [[ <span class="string">&quot;<span class="variable">$ENV</span>&quot;</span> != <span class="string">&quot;default&quot;</span> ]]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">export</span> ENV_PATH=<span class="string">&quot;<span class="variable">$&#123;ENV&#125;</span>/&quot;</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ -z <span class="string">&quot;<span class="variable">$&#123;CONFIG_BACKEND&#125;</span>&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="keyword">if</span> [ -n <span class="string">&quot;<span class="variable">$&#123;CONFIG_TYPE&#125;</span>&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">export</span> CONFIG_BACKEND=<span class="string">&quot;<span class="variable">$&#123;CONFIG_TYPE&#125;</span>&quot;</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ -z <span class="string">&quot;<span class="variable">$&#123;CONFIG_BACKEND&#125;</span>&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">export</span> CONFIG_BACKEND=<span class="string">&quot;env&quot;</span></span><br><span class="line">    <span class="built_in">export</span> CONFIG_PATH=<span class="string">&quot;config/<span class="variable">$&#123;ENV_PATH&#125;</span>config&quot;</span></span><br><span class="line">    <span class="keyword">if</span> [ -f <span class="string">&quot;<span class="variable">$&#123;CONFIG_PATH&#125;</span>.json&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">export</span> CONFIG_BACKEND=<span class="string">&quot;json&quot;</span></span><br><span class="line">    <span class="keyword">elif</span> [ -f <span class="string">&quot;<span class="variable">$&#123;CONFIG_PATH&#125;</span>.toml&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">export</span> CONFIG_BACKEND=<span class="string">&quot;toml&quot;</span></span><br><span class="line">    <span class="keyword">elif</span> [ -f <span class="string">&quot;<span class="variable">$&#123;CONFIG_PATH&#125;</span>.env&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">export</span> CONFIG_BACKEND=<span class="string">&quot;env&quot;</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;Using <span class="variable">$&#123;CONFIG_BACKEND&#125;</span> backend: <span class="variable">$&#123;CONFIG_PATH&#125;</span>.<span class="variable">$&#123;CONFIG_BACKEND&#125;</span>&quot;</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Update dependencies</span></span><br><span class="line"><span class="keyword">if</span> [ -z <span class="string">&quot;<span class="variable">$&#123;DISABLE_UPDATES&#125;</span>&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&#x27;Updating dependencies. Set DISABLE_UPDATES to prevent this.&#x27;</span></span><br><span class="line">    <span class="keyword">if</span> [ -f <span class="string">&quot;pyproject.toml&quot;</span> ] &amp;&amp; [ -f <span class="string">&quot;poetry.lock&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">        nvidia-smi 2&gt; /dev/null &amp;&amp; poetry install</span><br><span class="line">        <span class="built_in">uname</span> -s | grep -q Darwin &amp;&amp; poetry install -C install/apple</span><br><span class="line">        rocm-smi 2&gt; /dev/null &amp;&amp; poetry install -C install/rocm</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="comment"># Run the training script.</span></span><br><span class="line"><span class="keyword">if</span> [[ -z <span class="string">&quot;<span class="variable">$&#123;ACCELERATE_CONFIG_PATH&#125;</span>&quot;</span> ]]; <span class="keyword">then</span></span><br><span class="line">    ACCELERATE_CONFIG_PATH=<span class="string">&quot;<span class="variable">$&#123;HOME&#125;</span>/.cache/huggingface/accelerate/default_config.yaml&quot;</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="keyword">if</span> [ -f <span class="string">&quot;<span class="variable">$&#123;ACCELERATE_CONFIG_PATH&#125;</span>&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;Using Accelerate config file: <span class="variable">$&#123;ACCELERATE_CONFIG_PATH&#125;</span>&quot;</span></span><br><span class="line">    accelerate launch --config_file=<span class="string">&quot;<span class="variable">$&#123;ACCELERATE_CONFIG_PATH&#125;</span>&quot;</span> train.py</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;Accelerate config file not found: <span class="variable">$&#123;ACCELERATE_CONFIG_PATH&#125;</span>. Using values from config.env.&quot;</span></span><br><span class="line">    accelerate launch <span class="variable">$&#123;ACCELERATE_EXTRA_ARGS&#125;</span> --mixed_precision=<span class="string">&quot;<span class="variable">$&#123;MIXED_PRECISION&#125;</span>&quot;</span> --num_processes=<span class="string">&quot;<span class="variable">$&#123;TRAINING_NUM_PROCESSES&#125;</span>&quot;</span> --num_machines=<span class="string">&quot;<span class="variable">$&#123;TRAINING_NUM_MACHINES&#125;</span>&quot;</span> --dynamo_backend=<span class="string">&quot;<span class="variable">$&#123;TRAINING_DYNAMO_BACKEND&#125;</span>&quot;</span> train.py</span><br><span class="line"></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">exit</span> 0</span><br></pre></td></tr></table></figure></li></ul><p>이것이 일반적인 흐름입니다.</p><p>처음에는 <code>SimpleTuner/config</code> 디렉토리에서 <code>config.env</code>를 소스로 사용합니다. 이는 <code>gpus</code> 수와 같은 중요한 설정이 포함된 상위 수준 <code>config.env</code>가 있고 보다 세부적인 설정이 포함된 <code>config.json</code> 또는 <code>config.env</code>와 같은 하위 수준 구성이 있기 때문에 혼란스럽습니다. 설정(예: <code>model_family</code>, <code>learning_rate</code> 등).</p><p>그러나 저장소를 <code>git clone</code>하면 <code>config.env</code> 파일이 표시되지 않습니다.</p><p>내 테스트에서는 실제로 <a href="https://github.com/bghira/SimpleTuner/blob/main/INSTALL.md">INSTALL.MD</a>에 따라 상위 수준 <code>config.env</code>를 생성할 필요가 없습니다. , 하지만 <code>config</code> 폴더 내에서 폴더를 동적으로 전환하는 데 도움이 되므로 그렇게 하는 것이 좋습니다.</p><p><code>config</code> 디렉터리에 <code>config.env</code> 파일을 만듭니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim SimpleTuner/config/config.env</span><br></pre></td></tr></table></figure><ul><li><p>High-level <code>config.env</code></p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">TRAINING_NUM_PROCESSES=1</span><br><span class="line">TRAINING_NUM_MACHINES=1</span><br><span class="line">TRAINING_DYNAMO_BACKEND=<span class="string">&#x27;no&#x27;</span></span><br><span class="line">MIXED_PRECISION=<span class="string">&#x27;bf16&#x27;</span></span><br><span class="line"><span class="built_in">export</span> CONFIG_BACKEND=<span class="string">&quot;json&quot;</span></span><br><span class="line"><span class="built_in">export</span> ENV=<span class="string">&quot;default&quot;</span></span><br></pre></td></tr></table></figure></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash train.sh</span><br></pre></td></tr></table></figure><p><code>SimpleTuner</code>는 <code>ENV</code> 디렉토리 내에서 <code>config</code> 디렉토리인 <code>config.json</code>을 검색합니다. 그 이유는 마스터 <code>config.env</code> 파일에서 <code>ENV</code>가 <code>default</code>로 설정되어 있기 때문입니다. 이는 <code>SimpleTuner/config</code>를 의미합니다.</p><p>‘config.json’을 찾는 이유가 무엇인지 물어볼 수도 있습니다. 음, <a href="http://train.sh/"><code>train.sh</code></a> 파일에서 이 코드 블록을 보면, <code>CONFIG_BACKEND</code>로 지정한 내용에 따라 이 파일을 찾는다는 것을 알 수 있습니다. 마스터 <code>config.env</code> 파일:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> [ -z <span class="string">&quot;<span class="variable">$&#123;CONFIG_BACKEND&#125;</span>&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">export</span> CONFIG_BACKEND=<span class="string">&quot;env&quot;</span></span><br><span class="line">    <span class="built_in">export</span> CONFIG_PATH=<span class="string">&quot;config/<span class="variable">$&#123;ENV_PATH&#125;</span>config&quot;</span></span><br><span class="line">    <span class="keyword">if</span> [ -f <span class="string">&quot;<span class="variable">$&#123;CONFIG_PATH&#125;</span>.json&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">export</span> CONFIG_BACKEND=<span class="string">&quot;json&quot;</span></span><br><span class="line">    <span class="keyword">elif</span> [ -f <span class="string">&quot;<span class="variable">$&#123;CONFIG_PATH&#125;</span>.toml&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">export</span> CONFIG_BACKEND=<span class="string">&quot;toml&quot;</span></span><br><span class="line">    <span class="keyword">elif</span> [ -f <span class="string">&quot;<span class="variable">$&#123;CONFIG_PATH&#125;</span>.env&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">export</span> CONFIG_BACKEND=<span class="string">&quot;env&quot;</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;Using <span class="variable">$&#123;CONFIG_BACKEND&#125;</span> backend: <span class="variable">$&#123;CONFIG_PATH&#125;</span>.<span class="variable">$&#123;CONFIG_BACKEND&#125;</span>&quot;</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure><p><code>config.*</code>의 이름을 변경할 수 있는지 궁금하실 수도 있습니다. <code>config_fantasy_art_lora_01.*</code>를 사용할 수 있나요? <code>config_fantasy_art_full_01.*</code>은 어떻습니까?</p><p>안타깝게도 그럴 수 없는 것 같습니다. <code>train.sh</code> 파일에서 <code>config.*</code>의 이름을 변경하더라도 <a href="https://github.com/bghira/SimpleTuner/blob/main/helpers/configuration/loader">loader.py</a> .py#L17) 구성 도우미의 코드는 기본적으로 다음 값으로 설정됩니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">default_config_paths = &#123;</span><br><span class="line">    <span class="string">&quot;json&quot;</span>: <span class="string">&quot;config.json&quot;</span>,</span><br><span class="line">    <span class="string">&quot;toml&quot;</span>: <span class="string">&quot;config.toml&quot;</span>,</span><br><span class="line">    <span class="string">&quot;env&quot;</span>: <span class="string">&quot;config.env&quot;</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>따라서 세부 훈련 매개변수 설정으로 하위 수준 <code>config.*</code> 파일을 구별하고 <a href="https://github.com/bghira/SimpleTuner/blob">loader.py</a>를 수정하고 싶지 않은 경우 &#x2F;main&#x2F;helpers&#x2F;configuration&#x2F;loader.py#L17) 코드를 사용하는 경우 훈련에 해당하는 <code>SimpleTuner/config</code> 디렉토리 내에 폴더를 생성하는 것이 좋습니다. 나도 똑같이 할 것이다.</p><p><code>SimpleTuner/config</code> 안에 첫 번째 훈련을 위한 디렉토리를 생성해 보겠습니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> SimpleTuner/config/sd35_fantasy_art_lora</span><br></pre></td></tr></table></figure><p>이제 <code>SimpleTuner/config/config.env</code>에서 상위 수준 <code>config.env</code>를 다음과 같이 수정하겠습니다.</p><ul><li><p>High-level <code>config.env</code></p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">TRAINING_NUM_PROCESSES=1</span><br><span class="line">TRAINING_NUM_MACHINES=1</span><br><span class="line">TRAINING_DYNAMO_BACKEND=<span class="string">&#x27;no&#x27;</span></span><br><span class="line">MIXED_PRECISION=<span class="string">&#x27;bf16&#x27;</span></span><br><span class="line"><span class="built_in">export</span> CONFIG_BACKEND=<span class="string">&quot;json&quot;</span></span><br><span class="line"><span class="built_in">export</span> ENV=<span class="string">&quot;sd35_fantasy_art_lora&quot;</span></span><br></pre></td></tr></table></figure></li></ul><p>훈련이 시작되면 먼저 <code>SimpleTuner/config/config.env</code>에서 마스터 <code>config.env</code>를 소싱한 다음 <code>SimpleTuner/config/sd35_fantasy_art_lora</code>에서 해당 <code>config.$&#123;CONFIG_BACKEND&#125;</code> 파일을 찾습니다. 이 경우 <code>config.json</code> 입니다.</p><p>이를 이해하면 다양한 모델에 대한 다양한 ‘config’ 학습 매개변수를 관리하는 것이 매우 쉬워지므로 학습 흐름이 명확해지기를 바랍니다.</p><p>이제 하위 수준 <code>config.*</code> 파일로 이동하겠습니다.</p><h3 id="Configuration-setup-low-level"><a href="#Configuration-setup-low-level" class="headerlink" title="Configuration setup (low-level)"></a>Configuration setup (low-level)</h3><p><code>SimpleTuner/config/</code> 디렉토리에는 <code>bghira</code>에서 제공하는 기본 <code>config.json.example</code>이 있습니다.</p><p>자세한 내용을 알고 싶지 않다면 내 맞춤 <code>config.json</code> 사용으로 건너뛰세요.</p><ul><li><p>맞춤형 SD3.5 대형 <code>LoRA</code> <code>config.json</code></p>  <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;--model_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;lora&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--model_family&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sd3&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--resume_from_checkpoint&quot;</span><span class="punctuation">:</span> <span class="string">&quot;latest&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--checkpointing_steps&quot;</span><span class="punctuation">:</span> <span class="number">400</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--checkpoints_total_limit&quot;</span><span class="punctuation">:</span> <span class="number">60</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--learning_rate&quot;</span><span class="punctuation">:</span> <span class="number">1.05e-3</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--pretrained_model_name_or_path&quot;</span><span class="punctuation">:</span> <span class="string">&quot;stabilityai/stable-diffusion-3.5-large&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--report_to&quot;</span><span class="punctuation">:</span> <span class="string">&quot;wandb&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--tracker_project_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sd35-training&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--tracker_run_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;simpletuner-fantasy-art-lora-01&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--max_train_steps&quot;</span><span class="punctuation">:</span> <span class="number">24000</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--num_train_epochs&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--data_backend_config&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/weka2/home-yeo/simpletuner_models/sd3_large/full_finetune/fantasy_art_L_01/datasets/multidatabackend.json&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--output_dir&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/weka2/home-yeo/simpletuner_models/sd3_large/full_finetune/fantasy_art_L_01/datasets/models&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--push_to_hub&quot;</span><span class="punctuation">:</span> <span class="keyword">false</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--push_checkpoints_to_hub&quot;</span><span class="punctuation">:</span> <span class="keyword">true</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--hub_model_id&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sd35-training&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--resolution&quot;</span><span class="punctuation">:</span> <span class="number">1024</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--resolution_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;pixel&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--minimum_image_size&quot;</span><span class="punctuation">:</span> <span class="number">1024</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--instance_prompt&quot;</span><span class="punctuation">:</span> <span class="string">&quot;k4s4 &quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--validation_prompt&quot;</span><span class="punctuation">:</span> <span class="string">&quot;k4s4, a waist up view of a beautiful female blonde woman, green eyes&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--validation_guidance&quot;</span><span class="punctuation">:</span> <span class="number">7.5</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--validation_guidance_rescale&quot;</span><span class="punctuation">:</span> <span class="number">0.0</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--validation_steps&quot;</span><span class="punctuation">:</span> <span class="number">200</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--validation_num_inference_steps&quot;</span><span class="punctuation">:</span> <span class="number">30</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--validation_negative_prompt&quot;</span><span class="punctuation">:</span> <span class="string">&quot;blurry, cropped, ugly&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--validation_seed&quot;</span><span class="punctuation">:</span> <span class="number">42</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--validation_resolution&quot;</span><span class="punctuation">:</span> <span class="number">1024</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--train_batch_size&quot;</span><span class="punctuation">:</span> <span class="number">6</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--gradient_accumulation_steps&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--lr_scheduler&quot;</span><span class="punctuation">:</span> <span class="string">&quot;cosine&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--lr_warmup_steps&quot;</span><span class="punctuation">:</span> <span class="number">2400</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--caption_dropout_probability&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--metadata_update_interval&quot;</span><span class="punctuation">:</span> <span class="number">65</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--vae_batch_size&quot;</span><span class="punctuation">:</span> <span class="number">12</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--delete_unwanted_images&quot;</span><span class="punctuation">:</span> <span class="keyword">false</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--delete_problematic_images&quot;</span><span class="punctuation">:</span> <span class="keyword">false</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--training_scheduler_timestep_spacing&quot;</span><span class="punctuation">:</span> <span class="string">&quot;trailing&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--inference_scheduler_timestep_spacing&quot;</span><span class="punctuation">:</span> <span class="string">&quot;trailing&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--snr_gamma&quot;</span><span class="punctuation">:</span> <span class="number">5</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--enable_xformers_memory_efficient_attention&quot;</span><span class="punctuation">:</span> <span class="keyword">true</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--gradient_checkpointing&quot;</span><span class="punctuation">:</span> <span class="keyword">true</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--allow_tf32&quot;</span><span class="punctuation">:</span> <span class="keyword">true</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--optimizer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;adamw_bf16&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--use_ema&quot;</span><span class="punctuation">:</span> <span class="keyword">false</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--ema_decay&quot;</span><span class="punctuation">:</span> <span class="number">0.999</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--seed&quot;</span><span class="punctuation">:</span> <span class="number">42</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--mixed_precision&quot;</span><span class="punctuation">:</span> <span class="string">&quot;bf16&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--lora_rank&quot;</span><span class="punctuation">:</span> <span class="number">768</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--lora_alpha&quot;</span><span class="punctuation">:</span> <span class="number">768</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--lora_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;standard&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure></li></ul><p>자세한 내용을 알고 싶다면 계속 읽어보세요.</p><p><code>SimpleTuner</code> 루트에 있는 <code>config</code> 파일을 <code>ENV</code> 디렉터리에 복사하여 시작할 수 있습니다. 이것이 내 명령이다.</p><figure class="highlight jsx"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp config/config.<span class="property">json</span>.<span class="property">example</span> config/sd35_fantasy_art_lora/config.<span class="property">json</span></span><br></pre></td></tr></table></figure><p>일단 열면 <code>json</code> 파일은 다음과 같습니다:</p><ul><li><p><code>config.json.example</code></p>  <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;--resume_from_checkpoint&quot;</span><span class="punctuation">:</span> <span class="string">&quot;latest&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--data_backend_config&quot;</span><span class="punctuation">:</span> <span class="string">&quot;config/multidatabackend.json&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--aspect_bucket_rounding&quot;</span><span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--seed&quot;</span><span class="punctuation">:</span> <span class="number">42</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--minimum_image_size&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--output_dir&quot;</span><span class="punctuation">:</span> <span class="string">&quot;output/models&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--lora_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;lycoris&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--lycoris_config&quot;</span><span class="punctuation">:</span> <span class="string">&quot;config/lycoris_config.json&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--max_train_steps&quot;</span><span class="punctuation">:</span> <span class="number">10000</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--num_train_epochs&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--checkpointing_steps&quot;</span><span class="punctuation">:</span> <span class="number">500</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--checkpoints_total_limit&quot;</span><span class="punctuation">:</span> <span class="number">5</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--hub_model_id&quot;</span><span class="punctuation">:</span> <span class="string">&quot;simpletuner-lora&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--push_to_hub&quot;</span><span class="punctuation">:</span> <span class="string">&quot;true&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--push_checkpoints_to_hub&quot;</span><span class="punctuation">:</span> <span class="string">&quot;true&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--tracker_project_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;lora-training&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--tracker_run_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;simpletuner-lora&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--report_to&quot;</span><span class="punctuation">:</span> <span class="string">&quot;wandb&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--model_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;lora&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--pretrained_model_name_or_path&quot;</span><span class="punctuation">:</span> <span class="string">&quot;stabilityai/stable-diffusion-3.5-large&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--model_family&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sd3&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--train_batch_size&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--gradient_checkpointing&quot;</span><span class="punctuation">:</span> <span class="string">&quot;true&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--caption_dropout_probability&quot;</span><span class="punctuation">:</span> <span class="number">0.1</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--resolution_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;pixel_area&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--resolution&quot;</span><span class="punctuation">:</span> <span class="number">1024</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--validation_seed&quot;</span><span class="punctuation">:</span> <span class="number">42</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--validation_steps&quot;</span><span class="punctuation">:</span> <span class="number">500</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--validation_resolution&quot;</span><span class="punctuation">:</span> <span class="string">&quot;1024x1024&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--validation_guidance&quot;</span><span class="punctuation">:</span> <span class="number">3.0</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--validation_guidance_rescale&quot;</span><span class="punctuation">:</span> <span class="string">&quot;0.0&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--validation_num_inference_steps&quot;</span><span class="punctuation">:</span> <span class="string">&quot;20&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--validation_prompt&quot;</span><span class="punctuation">:</span> <span class="string">&quot;A photo-realistic image of a cat&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--mixed_precision&quot;</span><span class="punctuation">:</span> <span class="string">&quot;bf16&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--optimizer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;adamw_bf16&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--learning_rate&quot;</span><span class="punctuation">:</span> <span class="string">&quot;1e-4&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--lr_scheduler&quot;</span><span class="punctuation">:</span> <span class="string">&quot;polynomial&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--lr_warmup_steps&quot;</span><span class="punctuation">:</span> <span class="number">100</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--validation_torch_compile&quot;</span><span class="punctuation">:</span> <span class="string">&quot;false&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--disable_benchmark&quot;</span><span class="punctuation">:</span> <span class="string">&quot;false&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure></li></ul><p>원하신다면 이 제품을 즉시 사용하실 수 있습니다. 그러나 제공된 <code>json</code>에는 <a href="https://github.com/bghira/SimpleTuner/blob/main/OPTIONS.md#environment-configuration-variables">OPTIONS.MD</a>의 다른 매개변수가 많이 부족합니다. <a href="https://github.com/bghira/SimpleTuner/blob/main/configure.py">configure.py</a>를 사용하더라도 결국 다음과 같은 <code>config.json</code> 파일이 생성됩니다.</p><ul><li><p><code>configure.py</code>로 생성된 샘플 <code>.json</code>(참조로 사용됨)</p>  <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;--resume_from_checkpoint&quot;</span><span class="punctuation">:</span> <span class="string">&quot;latest&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--data_backend_config&quot;</span><span class="punctuation">:</span> <span class="string">&quot;config/multidatabackend.json&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--aspect_bucket_rounding&quot;</span><span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--seed&quot;</span><span class="punctuation">:</span> <span class="number">42</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--minimum_image_size&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--disable_benchmark&quot;</span><span class="punctuation">:</span> <span class="keyword">false</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--output_dir&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/weka2/home-yeo/simpletuner_models/sd3_large/full_finetune/fantasy_art_L_01/datasets/&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--lora_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;standard&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--lora_rank&quot;</span><span class="punctuation">:</span> <span class="number">256</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--max_train_steps&quot;</span><span class="punctuation">:</span> <span class="number">24000</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--num_train_epochs&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--checkpointing_steps&quot;</span><span class="punctuation">:</span> <span class="number">400</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--checkpoints_total_limit&quot;</span><span class="punctuation">:</span> <span class="number">60</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--tracker_project_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sd35-training&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--tracker_run_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;simpletuner-sd35-large-fantasy-art-01&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--report_to&quot;</span><span class="punctuation">:</span> <span class="string">&quot;wandb&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--model_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;lora&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--pretrained_model_name_or_path&quot;</span><span class="punctuation">:</span> <span class="string">&quot;stabilityai/stable-diffusion-3-medium-diffusers&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--model_family&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sd3&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--train_batch_size&quot;</span><span class="punctuation">:</span> <span class="number">6</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--gradient_checkpointing&quot;</span><span class="punctuation">:</span> <span class="string">&quot;true&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--caption_dropout_probability&quot;</span><span class="punctuation">:</span> <span class="number">0.0</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--resolution_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;pixel_area&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--resolution&quot;</span><span class="punctuation">:</span> <span class="string">&quot;1024&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--validation_seed&quot;</span><span class="punctuation">:</span> <span class="string">&quot;42&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--validation_steps&quot;</span><span class="punctuation">:</span> <span class="string">&quot;200&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--validation_resolution&quot;</span><span class="punctuation">:</span> <span class="string">&quot;1024x1024&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--validation_guidance&quot;</span><span class="punctuation">:</span> <span class="string">&quot;7.5&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--validation_guidance_rescale&quot;</span><span class="punctuation">:</span> <span class="string">&quot;0.0&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--validation_num_inference_steps&quot;</span><span class="punctuation">:</span> <span class="string">&quot;35&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--validation_prompt&quot;</span><span class="punctuation">:</span> <span class="string">&quot;k4s4, a waist up view of a beautiful female blonde woman, green eyes&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--mixed_precision&quot;</span><span class="punctuation">:</span> <span class="string">&quot;bf16&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--optimizer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;adamw_bf16&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--learning_rate&quot;</span><span class="punctuation">:</span> <span class="string">&quot;1.05e-3&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--lr_scheduler&quot;</span><span class="punctuation">:</span> <span class="string">&quot;polynomial&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--lr_warmup_steps&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2400&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;--validation_torch_compile&quot;</span><span class="punctuation">:</span> <span class="string">&quot;false&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure></li></ul><p><a href="https://github.com/bghira/SimpleTuner/blob/main/configure.py">configure.py</a>는 <code>lora_rank</code>와 같은 일부 매개변수를 제한할 뿐만 아니라 유효성 검사 중에 부정적인 프롬프트(<code>validation_negative_prompt)를 생략합니다. </code>) 무엇보다도 먼저 아래 <code>config.json</code>을 복사하여 시작하는 것이 좋습니다.</p><ul><li><p>Custom SD3.5 Large <code>LoRA</code> <code>config.json</code></p>  <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;--model_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;lora&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--model_family&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sd3&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--resume_from_checkpoint&quot;</span><span class="punctuation">:</span> <span class="string">&quot;latest&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--checkpointing_steps&quot;</span><span class="punctuation">:</span> <span class="number">400</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--checkpoints_total_limit&quot;</span><span class="punctuation">:</span> <span class="number">60</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--learning_rate&quot;</span><span class="punctuation">:</span> <span class="number">1.05e-3</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--pretrained_model_name_or_path&quot;</span><span class="punctuation">:</span> <span class="string">&quot;stabilityai/stable-diffusion-3.5-large&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--report_to&quot;</span><span class="punctuation">:</span> <span class="string">&quot;wandb&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--tracker_project_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sd35-training&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--tracker_run_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;simpletuner-fantasy-art-lora-01&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--max_train_steps&quot;</span><span class="punctuation">:</span> <span class="number">24000</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--num_train_epochs&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--data_backend_config&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/weka2/home-yeo/simpletuner_models/sd3_large/full_finetune/fantasy_art_L_01/datasets/multidatabackend.json&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--output_dir&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/weka2/home-yeo/simpletuner_models/sd3_large/full_finetune/fantasy_art_L_01/datasets/models&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--push_to_hub&quot;</span><span class="punctuation">:</span> <span class="keyword">false</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--push_checkpoints_to_hub&quot;</span><span class="punctuation">:</span> <span class="keyword">true</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--hub_model_id&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sd35-training&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--resolution&quot;</span><span class="punctuation">:</span> <span class="number">1024</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--resolution_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;pixel&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--minimum_image_size&quot;</span><span class="punctuation">:</span> <span class="number">1024</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--instance_prompt&quot;</span><span class="punctuation">:</span> <span class="string">&quot;k4s4 &quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--validation_prompt&quot;</span><span class="punctuation">:</span> <span class="string">&quot;k4s4, a waist up view of a beautiful female blonde woman, green eyes&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--validation_guidance&quot;</span><span class="punctuation">:</span> <span class="number">7.5</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--validation_guidance_rescale&quot;</span><span class="punctuation">:</span> <span class="number">0.0</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--validation_steps&quot;</span><span class="punctuation">:</span> <span class="number">200</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--validation_num_inference_steps&quot;</span><span class="punctuation">:</span> <span class="number">30</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--validation_negative_prompt&quot;</span><span class="punctuation">:</span> <span class="string">&quot;blurry, cropped, ugly&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--validation_seed&quot;</span><span class="punctuation">:</span> <span class="number">42</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--validation_resolution&quot;</span><span class="punctuation">:</span> <span class="number">1024</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--train_batch_size&quot;</span><span class="punctuation">:</span> <span class="number">6</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--gradient_accumulation_steps&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--lr_scheduler&quot;</span><span class="punctuation">:</span> <span class="string">&quot;cosine&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--lr_warmup_steps&quot;</span><span class="punctuation">:</span> <span class="number">2400</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--caption_dropout_probability&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--metadata_update_interval&quot;</span><span class="punctuation">:</span> <span class="number">65</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--vae_batch_size&quot;</span><span class="punctuation">:</span> <span class="number">12</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--delete_unwanted_images&quot;</span><span class="punctuation">:</span> <span class="keyword">false</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--delete_problematic_images&quot;</span><span class="punctuation">:</span> <span class="keyword">false</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--training_scheduler_timestep_spacing&quot;</span><span class="punctuation">:</span> <span class="string">&quot;trailing&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--inference_scheduler_timestep_spacing&quot;</span><span class="punctuation">:</span> <span class="string">&quot;trailing&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--snr_gamma&quot;</span><span class="punctuation">:</span> <span class="number">5</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--enable_xformers_memory_efficient_attention&quot;</span><span class="punctuation">:</span> <span class="keyword">true</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--gradient_checkpointing&quot;</span><span class="punctuation">:</span> <span class="keyword">true</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--allow_tf32&quot;</span><span class="punctuation">:</span> <span class="keyword">true</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--optimizer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;adamw_bf16&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--use_ema&quot;</span><span class="punctuation">:</span> <span class="keyword">false</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--ema_decay&quot;</span><span class="punctuation">:</span> <span class="number">0.999</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--seed&quot;</span><span class="punctuation">:</span> <span class="number">42</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--mixed_precision&quot;</span><span class="punctuation">:</span> <span class="string">&quot;bf16&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--lora_rank&quot;</span><span class="punctuation">:</span> <span class="number">768</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--lora_alpha&quot;</span><span class="punctuation">:</span> <span class="number">768</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--lora_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;standard&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure></li></ul><p>뭔가 눈치채셨을 수도 있지만, 우리는 <strong>더 이상</strong> 이전 하위 수준 <code>config.env</code>의 이 매개변수를 사용하지 않습니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="built_in">export</span> STABLE_DIFFUSION_3=<span class="literal">true</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>대신 <code>&quot;--model_family&quot;</code> 매개변수로 대체되었습니다. 이것을 <code>sd3</code>으로 설정합니다:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;--model_family&quot;: &quot;sd3&quot;</span><br></pre></td></tr></table></figure><p>실제로, 낮은 수준 <code>config.env</code>는 <code>SimpleTuner</code>에 의해 더 이상 사용되지 않을 수 있습니다. 하지만 원하시면 그래도 사용하는 방법은 이 <a href="https://www.notion.so/Stable-Diffusion-3-5-Large-Fine-tuning-Tutorial-11a61cdcd1968027a15bdbd7c40be8c6?pvs">섹션</a>에서 보여드리겠습니다. &#x3D;21).</p><p>또한 이 매개변수가 제대로 설정되었는지 확인하세요. 그렇지 않으면 <code>HuggingFace</code>에서 모델을 가져올 수 없습니다.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;--pretrained_model_name_or_path&quot;: &quot;stabilityai/stable-diffusion-3.5-large&quot;</span><br></pre></td></tr></table></figure><p>이것이 작동하는지 확인하려면 ‘HuggingFace’ 계정에 여기 모델 카드 페이지에서 이 모델에 대한 액세스 권한이 부여되었는지 확인해야 합니다. <a href="https://github.com/bghira/SimpleTuner/blob/main/documentation/quickstart/SD3.md">빠른 시작 가이드</a>의 지침을 따르면 됩니다.</p><p>다음 명령은 다음과 같습니다.</p><p><strong>필수</strong></p><p>모델을 다운로드하기 위한 접근 권한을 얻기 위한 것입니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">huggingface-cli login</span><br></pre></td></tr></table></figure><p>나머지 설정을 다루기 전에 지금 ‘multidatabackend.json’ 파일을 설정하는 것이 좋습니다.</p><h3 id="Dataloader"><a href="#Dataloader" class="headerlink" title="Dataloader"></a>Dataloader</h3><p>관련 매개변수를 인간이 이해할 수 있는 어휘로 구문 분석하기 전에 데이터 부분인 <code>--data_backend_config</code> 및 <code>--output_dir</code>부터 시작하고 싶습니다. 이전 버전의 <code>SimpleTuner</code>에는 데이터를 처리하는 <code>multidatabackend.json</code> 파일이 있었습니다.</p><p>Excerpt from old code:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> BASE_DIR=<span class="string">&quot;/weka2/home-yeo/simpletuner_models/sd3_large/full_finetune/fantasy_art_L_01/datasets/&quot;</span></span><br><span class="line"><span class="built_in">export</span> DATALOADER_CONFIG=<span class="string">&quot;<span class="variable">$&#123;BASE_DIR&#125;</span>/multidatabackend.json&quot;</span></span><br><span class="line"><span class="built_in">export</span> OUTPUT_DIR=<span class="string">&quot;<span class="variable">$&#123;BASE_DIR&#125;</span>/models&quot;</span></span><br></pre></td></tr></table></figure><p>보시다시피 <code>BASE_DIR</code>이 선언된 다음 <code>DATALOADER_CONFIG</code>와 <code>OUTPUT_DIR</code>이 이를 확장합니다. <code>multidatabackend.json</code>은 <code>BASE_DIR</code> 내부에 생성된 파일입니다.</p><p>그러나 SimpleTuner의 기본 구성 폴더에는 ‘SimpleTuner&#x2F;config&#x2F;multidatabackend.json’ 파일이 있습니다. 개인 취향에 따라 ‘multidatabackend.json’ 파일을 원하는 곳에 모두 배치할 수 있지만, 모든 모델과 캐시를 한 곳에 보관하므로 이전 버전의 ‘SimpleTuner’ 구조를 보존하겠습니다.</p><p>따라서 <code>BASE_DIR</code> 역할을 할 폴더 위치를 생성하겠습니다. 따라서 <code>--data_backend_config</code>와 <code>--output_dir</code> 모두 이 경로를 활용합니다.</p><p>우리는 <code>json</code>을 사용하고 있으므로 하드코딩해야 합니다.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&quot;--data_backend_config&quot;: &quot;/weka2/home-yeo/simpletuner_models/sd3_large/full_finetune/fantasy_art_L_01/datasets/multidatabackend.json&quot;,</span><br><span class="line"> &quot;--output_dir&quot;: &quot;/weka2/home-yeo/simpletuner_models/sd3_large/full_finetune/fantasy_art_L_01/datasets/models&quot;,</span><br></pre></td></tr></table></figure><p>모든 모델은 <code>--output_dir</code>에 저장되며, 이 경우 하드 코딩된 <code>BASE_DIR/models</code>입니다.</p><p>다음은 내 사용자 정의 <code>multidatabackend.json</code>입니다.</p><ul><li><p>Custom <code>multidatabackend.json</code></p>  <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">[</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span> <span class="string">&quot;fantasy_art_neo&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;local&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;crop&quot;</span><span class="punctuation">:</span> <span class="keyword">false</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;crop_aspect&quot;</span><span class="punctuation">:</span> <span class="string">&quot;square&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;crop_style&quot;</span><span class="punctuation">:</span> <span class="string">&quot;center&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;resolution&quot;</span><span class="punctuation">:</span> <span class="number">1.0</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;minimum_image_size&quot;</span><span class="punctuation">:</span> <span class="number">1.0</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;maximum_image_size&quot;</span><span class="punctuation">:</span> <span class="number">1.0</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;target_downsample_size&quot;</span><span class="punctuation">:</span> <span class="number">1.0</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;resolution_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;area&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;cache_dir_vae&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/weka2/home-yeo/simpletuner_models/sd3_large/full_finetune/fantasy_art_L_01/cache/vae/sd3/fantasy_art_neo&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;instance_data_dir&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/weka2/home-yeo/datasets/SDXL/duplicate_shuffle_01&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;disabled&quot;</span><span class="punctuation">:</span> <span class="keyword">false</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;skip_file_discovery&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;caption_strategy&quot;</span><span class="punctuation">:</span> <span class="string">&quot;textfile&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;metadata_backend&quot;</span><span class="punctuation">:</span> <span class="string">&quot;json&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;repeats&quot;</span><span class="punctuation">:</span> <span class="number">1</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span> <span class="string">&quot;text-embeds&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;local&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;dataset_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;text_embeds&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;default&quot;</span><span class="punctuation">:</span> <span class="keyword">true</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;cache_dir&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/weka2/home-yeo/simpletuner_models/sd3_large/full_finetune/fantasy_art_L_01/cache/text/sd3/fantasy_art_neo&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;disabled&quot;</span><span class="punctuation">:</span> <span class="keyword">false</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;write_batch_size&quot;</span><span class="punctuation">:</span> <span class="number">128</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">]</span></span><br></pre></td></tr></table></figure></li></ul><p>지정해야 하는 디렉터리는 세 개입니다.</p><ol><li><code>cache_dir_vae</code></li></ol><p>내 예제 파일에는 다음이 있습니다.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;cache_dir_vae&quot;: &quot;/weka2/home-yeo/simpletuner_models/sd3_large/full_finetune/fantasy_art_L_01/cache/vae/sd3/fantasy_art_neo&quot;</span><br></pre></td></tr></table></figure><p>가독성과 명확성을 위해 기본 디렉터리 안에 ‘cache’ 폴더를 넣었습니다.</p><ol><li><code>instance_dir_vae</code></li></ol><p>여기에 이미지와 캡션이 포함된 데이터세트가 저장됩니다. 매우 간단합니다.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;instance_data_dir&quot;: &quot;/weka2/home-yeo/datasets/SDXL/duplicate_shuffle_01&quot;</span><br></pre></td></tr></table></figure><ol><li><code>cache_dir</code></li></ol><p>위와 동일합니다.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;cache_dir&quot;: &quot;/weka2/home-yeo/simpletuner_models/sd3_large/full_finetune/fantasy_art_L_01/cache/text/sd3/fantasy_art_neo&quot;</span><br></pre></td></tr></table></figure><p>나머지 설정은 나에게 그다지 중요하지 않습니다. 저는 이미 이미지를 미리 잘라서 <code>&quot;crop&quot;: false</code>를 설정했습니다.</p><p>또한 이전에 다른 교육 리포지토리를 사용해 본 적이 있는지 여부에 따라 익숙할 수도 있고 익숙하지 않을 수도 있는 ‘반복’ 매개변수가 있습니다. 이 내용도 다음 섹션에서 다루겠습니다. 그래서 &#96;&#96;repeats”: 1’을 제가 직접 처리하는 것입니다.</p><h3 id="Data-preparation"><a href="#Data-preparation" class="headerlink" title="Data preparation"></a>Data preparation</h3><p>내 데이터 세트의 모든 이미지는 이미 다음 종횡비 및 해상도 중 하나로 미리 잘려져 있습니다.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">    (1024, 1024), (1152, 896), (896, 1152), (1216, 832),</span><br><span class="line">    (832, 1216), (1344, 768), (768, 1344), (1472, 704)</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>이미지를 자동으로 미리 자르는 데 도움이 필요한 경우 이를 위해 제가 작성한 경량의 기본 <a href="https://github.com/kasukanra/autogen_local_LLM/blob/main/Detect_utils.py">스크립트</a>가 있습니다. 다음에 따라 최상의 작물을 찾습니다.</p><ol><li>이미지에 사람 얼굴이 포함되어 있나요? 그렇다면 이미지의 해당 영역을 중심으로 자르기를 수행합니다.</li><li>감지된 사람의 얼굴이 없으면 이미지에서 가장 흥미로운 영역을 감지하는 돌출 맵을 사용하여 자르기를 수행합니다. 그러면 해당 지역을 중심으로 가장 좋은 작물이 추출됩니다.</li></ol><p>어쨌든 내 기본 데이터 세트 구조는 다음과 같습니다(텍스트 파일은 캡션입니다).</p><p>내 캡션이 어떻게 보이는지에 대한 몇 가지 예는 다음과 같습니다.</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">k4s4, a close up portrait view of a young man with green eyes and short dark hair, looking at the viewer with a slight smile, visible ears, wearing a dark jacket, hair bangs, a green and orange background</span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">k4s4, a rear view of a woman wearing a red hood and faded skirt holding a staff in each hand and steering a small boat with small white wings and large white sail towards a city with tall structures, blue sky with white clouds, cropped</span><br></pre></td></tr></table></figure><p>자체 미세 조정 데이터 세트가 없다면 John이 그린 그림의 <a href="https://drive.google.com/file/d/1capT9kF-zCu2OiNVzm7VG5DQDaAQLl1Q/view?usp=sharing">이 데이터 세트</a>를 자유롭게 사용해 보세요. 가수 Sargent(WikiArt에서 다운로드하고 자동 캡션 있음) 또는 합성 픽셀 아트 <a href="https://drive.google.com/file/d/1tOyNsjR5i7ki5UkyxHhjjT_VVD8vK5WN/view?usp=drive_link">데이터세트</a>.</p><p>다양한 데이터 세트 크기의 여러 미세 조정된 ‘LoRA’ 모델의 결과를 보여줌으로써 내가 선택한 설정이 ‘LoRA’ 미세 조정을 위한 좋은 출발점이 될 만큼 충분히 일반화된다는 것을 보여줄 것입니다.</p><table><thead><tr><th><code>name</code></th><th><code>fantasy art</code></th><th><code>cinema photo</code></th><th><code>john singer sargent</code></th><th><code>underexposed photography</code></th><th><code>pixel art</code></th><th><code>ethnic paint</code></th></tr></thead><tbody><tr><td><code>number of images</code></td><td>476</td><td>460</td><td>460</td><td>96</td><td>82</td><td>68</td></tr><tr><td><code>number of repeats</code></td><td>5</td><td>5</td><td>5</td><td>5</td><td>5</td><td>5</td></tr></tbody></table><p><code>반복</code>은 이미지를 복제하고(선택적으로 회전하고, 색조&#x2F;채도 등을 변경하는 등) 캡션도 모델에 일반화하고 과적합을 방지하는 데 도움이 됩니다. <code>SimpleTuner</code>는 캡션 드롭아웃(지정된 시간 비율에 따라 캡션을 무작위로 삭제)을 지원하지만 현재로서는 셔플링 토큰(토큰은 캡션의 단어와 유사함)을 지원하지 않지만 kohya의 동작을 시뮬레이션할 수 있습니다. <a href="https://github.com/kohya-ss/sd-scripts">sd-scripts</a> <a href="https://github.com/kohya-ss/sd-scripts/blob/25f961bc779bc79aef440813e3e8e92244ac5739/">토큰 섞기</a>할 수 있는 곳 docs&#x2F;config_README-en.md?plain&#x3D;1#L146) [유지]하는 동안(<a href="https://github.com/kohya-ss/sd-scripts/blob/25f961bc779bc79aef440813e3e8e92244ac5739/docs/config_README-en.md?plain=1">https://github.com/kohya-ss/sd-scripts/blob/25f961bc779bc79aef440813e3e8e92244ac5739/docs/config_README-en.md?plain=1</a> #L143) 시작 위치에 ‘n’개의 토큰이 있습니다. <strong>이렇게 하면 모델이 외부 토큰에 너무 집착하지 않도록 도와줍니다.</strong></p><p>해당 기능을 복제하려면 여기에 이미지를 복제하고 캡션을 조작하는 스크립트를 제공했습니다.</p><ul><li><p><code>duplicate_shuffle.py</code></p>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">duplicate_and_shuffle_dataset</span>(<span class="params">input_folder, output_folder, dataset_repeats, n_tokens_to_keep</span>):</span><br><span class="line">    <span class="comment"># Create output folder if it doesn&#x27;t exist</span></span><br><span class="line">    Path(output_folder).mkdir(parents=<span class="literal">True</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Get all image files</span></span><br><span class="line">    image_files = [f <span class="keyword">for</span> f <span class="keyword">in</span> os.listdir(input_folder) <span class="keyword">if</span> f.lower().endswith((<span class="string">&#x27;.png&#x27;</span>, <span class="string">&#x27;.jpg&#x27;</span>, <span class="string">&#x27;.jpeg&#x27;</span>))]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(dataset_repeats):</span><br><span class="line">        <span class="keyword">for</span> image_file <span class="keyword">in</span> image_files:</span><br><span class="line">            <span class="comment"># Get corresponding text file</span></span><br><span class="line">            text_file = os.path.splitext(image_file)[<span class="number">0</span>] + <span class="string">&#x27;.txt&#x27;</span></span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(os.path.join(input_folder, text_file)):</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;Warning: No corresponding text file found for <span class="subst">&#123;image_file&#125;</span>&quot;</span>)</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># Create new file names</span></span><br><span class="line">            new_image_file = <span class="string">f&quot;<span class="subst">&#123;os.path.splitext(image_file)[<span class="number">0</span>]&#125;</span>_<span class="subst">&#123;i+<span class="number">1</span>&#125;</span><span class="subst">&#123;os.path.splitext(image_file)[<span class="number">1</span>]&#125;</span>&quot;</span></span><br><span class="line">            new_text_file = <span class="string">f&quot;<span class="subst">&#123;os.path.splitext(text_file)[<span class="number">0</span>]&#125;</span>_<span class="subst">&#123;i+<span class="number">1</span>&#125;</span>.txt&quot;</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># Copy image file</span></span><br><span class="line">            shutil.copy2(os.path.join(input_folder, image_file), os.path.join(output_folder, new_image_file))</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Read, shuffle, and write text file</span></span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(input_folder, text_file), <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                content = f.read().strip()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Split tokens using comma or period as separator</span></span><br><span class="line">            tokens = re.split(<span class="string">r&#x27;[,.]&#x27;</span>, content)</span><br><span class="line">            tokens = [token.strip() <span class="keyword">for</span> token <span class="keyword">in</span> tokens <span class="keyword">if</span> token.strip()]  <span class="comment"># Remove empty tokens and strip whitespace</span></span><br><span class="line"></span><br><span class="line">            tokens_to_keep = tokens[:n_tokens_to_keep]</span><br><span class="line">            tokens_to_shuffle = tokens[n_tokens_to_keep:]</span><br><span class="line">            random.shuffle(tokens_to_shuffle)</span><br><span class="line"></span><br><span class="line">            new_content = <span class="string">&#x27;, &#x27;</span>.join(tokens_to_keep + tokens_to_shuffle)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(output_folder, new_text_file), <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                f.write(new_content)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Dataset duplication and shuffling complete. Output saved to <span class="subst">&#123;output_folder&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Example usage</span></span><br><span class="line">input_folder = <span class="string">&quot;/weka2/home-yeo/datasets/SDXL/full_dataset_neo&quot;</span></span><br><span class="line">output_folder = <span class="string">&quot;/weka2/home-yeo/datasets/SDXL/duplicate_shuffle_1&quot;</span></span><br><span class="line">dataset_repeats = <span class="number">5</span></span><br><span class="line">n_tokens_to_keep = <span class="number">2</span></span><br><span class="line"></span><br><span class="line">duplicate_and_shuffle_dataset(input_folder, output_folder, dataset_repeats, n_tokens_to_keep)</span><br></pre></td></tr></table></figure></li></ul><p>그렇게 하면 최종 데이터 세트는 아래 이미지와 비슷해집니다. 제가 사용한 설정으로는 5번의 ‘반복’이 허용되는 것 같았습니다.</p><h2 id="Returning-to-the-custom-config"><a href="#Returning-to-the-custom-config" class="headerlink" title="Returning to the custom config"></a>Returning to the custom config</h2><p>이제 사용자 정의 구성에서 이러한 특정 설정을 다루겠습니다.</p><h3 id="Learning-rate-x2F-steps"><a href="#Learning-rate-x2F-steps" class="headerlink" title="Learning rate&#x2F;steps"></a>Learning rate&#x2F;steps</h3><ul><li><p>Custom SD3.5 Large  <code>config.json</code> for LoRA training</p>  <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;--model_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;lora&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--model_family&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sd3&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--resume_from_checkpoint&quot;</span><span class="punctuation">:</span> <span class="string">&quot;latest&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--checkpointing_steps&quot;</span><span class="punctuation">:</span> <span class="number">400</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--checkpoints_total_limit&quot;</span><span class="punctuation">:</span> <span class="number">60</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--learning_rate&quot;</span><span class="punctuation">:</span> <span class="number">1.05e-3</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--pretrained_model_name_or_path&quot;</span><span class="punctuation">:</span> <span class="string">&quot;stabilityai/stable-diffusion-3.5-large&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--report_to&quot;</span><span class="punctuation">:</span> <span class="string">&quot;wandb&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--tracker_project_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sd35-training&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--tracker_run_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;simpletuner-fantasy-art-lora-01&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--max_train_steps&quot;</span><span class="punctuation">:</span> <span class="number">24000</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--num_train_epochs&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--data_backend_config&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/weka2/home-yeo/simpletuner_models/sd3_large/full_finetune/fantasy_art_L_01/datasets/multidatabackend.json&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--output_dir&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/weka2/home-yeo/simpletuner_models/sd3_large/full_finetune/fantasy_art_L_01/datasets/models&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--push_to_hub&quot;</span><span class="punctuation">:</span> <span class="keyword">false</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--push_checkpoints_to_hub&quot;</span><span class="punctuation">:</span> <span class="keyword">true</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--hub_model_id&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sd35-training&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--resolution&quot;</span><span class="punctuation">:</span> <span class="number">1024</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--resolution_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;pixel&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--minimum_image_size&quot;</span><span class="punctuation">:</span> <span class="number">1024</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--instance_prompt&quot;</span><span class="punctuation">:</span> <span class="string">&quot;k4s4 &quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--validation_prompt&quot;</span><span class="punctuation">:</span> <span class="string">&quot;k4s4, a waist up view of a beautiful blonde woman, green eyes&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--validation_guidance&quot;</span><span class="punctuation">:</span> <span class="number">7.5</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--validation_guidance_rescale&quot;</span><span class="punctuation">:</span> <span class="number">0.0</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--validation_steps&quot;</span><span class="punctuation">:</span> <span class="number">200</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--validation_num_inference_steps&quot;</span><span class="punctuation">:</span> <span class="number">30</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--validation_negative_prompt&quot;</span><span class="punctuation">:</span> <span class="string">&quot;blurry, cropped, ugly&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--validation_seed&quot;</span><span class="punctuation">:</span> <span class="number">42</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--validation_resolution&quot;</span><span class="punctuation">:</span> <span class="number">1024</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--train_batch_size&quot;</span><span class="punctuation">:</span> <span class="number">6</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--gradient_accumulation_steps&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--lr_scheduler&quot;</span><span class="punctuation">:</span> <span class="string">&quot;cosine&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--lr_warmup_steps&quot;</span><span class="punctuation">:</span> <span class="number">2400</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--caption_dropout_probability&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--metadata_update_interval&quot;</span><span class="punctuation">:</span> <span class="number">65</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--vae_batch_size&quot;</span><span class="punctuation">:</span> <span class="number">12</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--delete_unwanted_images&quot;</span><span class="punctuation">:</span> <span class="keyword">false</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--delete_problematic_images&quot;</span><span class="punctuation">:</span> <span class="keyword">false</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--training_scheduler_timestep_spacing&quot;</span><span class="punctuation">:</span> <span class="string">&quot;trailing&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--inference_scheduler_timestep_spacing&quot;</span><span class="punctuation">:</span> <span class="string">&quot;trailing&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--snr_gamma&quot;</span><span class="punctuation">:</span> <span class="number">5</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--enable_xformers_memory_efficient_attention&quot;</span><span class="punctuation">:</span> <span class="keyword">true</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--gradient_checkpointing&quot;</span><span class="punctuation">:</span> <span class="keyword">true</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--allow_tf32&quot;</span><span class="punctuation">:</span> <span class="keyword">true</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--optimizer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;adamw_bf16&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--use_ema&quot;</span><span class="punctuation">:</span> <span class="keyword">false</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--ema_decay&quot;</span><span class="punctuation">:</span> <span class="number">0.999</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--seed&quot;</span><span class="punctuation">:</span> <span class="number">42</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--mixed_precision&quot;</span><span class="punctuation">:</span> <span class="string">&quot;bf16&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--lora_rank&quot;</span><span class="punctuation">:</span> <span class="number">768</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--lora_alpha&quot;</span><span class="punctuation">:</span> <span class="number">768</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--lora_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;standard&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure></li></ul><p>이제 사용자 정의 구성에서 이러한 설정을 다루겠습니다.</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;--checkpointing_steps&quot;</span><span class="punctuation">:</span> <span class="number">400</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--checkpoints_total_limit&quot;</span><span class="punctuation">:</span> <span class="number">60</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--learning_rate&quot;</span><span class="punctuation">:</span> <span class="number">1.05e-3</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--max_train_steps&quot;</span><span class="punctuation">:</span> <span class="number">24000</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><h3 id="Steps-calculation"><a href="#Steps-calculation" class="headerlink" title="Steps calculation"></a>Steps calculation</h3><p>최대 훈련 단계는 간단한 수학 방정식을 기반으로 계산할 수 있습니다(<strong>단일 개념</strong>의 경우).</p><p>$$<br>\text{Max training steps} &#x3D; \left(\frac{\text{Number of samples} \times \text{Repeats}}{\text{Batch size}}\right) \times \text{Epochs}<br>$$</p><p>여기에는 네 가지 변수가 있습니다.</p><ul><li>배치 크기: 한 번의 반복으로 처리되는 샘플 수입니다.</li><li>샘플 수: 데이터 세트의 총 샘플 수입니다.</li><li>반복 횟수: 한 에포크 내에서 데이터 세트를 반복하는 횟수입니다.</li><li>Epochs: 전체 데이터세트가 처리되는 횟수입니다.</li></ul><p>‘fantasy art’ 데이터세트에는 ‘476’ 이미지가 있습니다. <code>multidatabackend.json</code>의 <code>5</code> 반복 위에 추가합니다. 나는 두 가지 이유로 <code>train_batch_size</code>를 <code>6</code>으로 선택했습니다:</p><ol><li>이 값을 사용하면 진행률 표시줄이 1~2초마다 업데이트되는 것을 볼 수 있습니다.</li><li>한 번의 반복으로 ‘6’개의 샘플을 취할 수 있을 만큼 충분히 크므로 훈련 과정에서 더 많은 일반화가 이루어지도록 합니다.</li></ol><p>30개 정도의 에포크를 원했다면 최종 계산은 다음과 같습니다.</p><p>$$<br>\text{Max training steps} &#x3D; \left(\frac{\text{476} \times \text{5}}{\text{6}}\right) \times \text{30}<br>$$</p><p>이는 대략 ‘11,900’ 단계와 같습니다.</p><p>괄호 안의 부분:</p><p>$$<br>\left(\frac{\text{476} \times \text{5}}{\text{6}}\right)<br>$$</p><p>는 에포크당 단계 수, 즉 ‘396’을 나타냅니다.</p><p>따라서 <code>CHECKPOINTING_STEPS</code>에 대해 이 값을 <code>400</code>으로 반올림했습니다.</p><p><a href="https://emojipedia.org/warning">**⚠️</a>** <code>MAX_NUM_STEPS</code>에 대해 <code>11,900</code>을 계산했지만 결국 <code>24,000</code>으로 설정했습니다. LoRA 훈련 샘플을 더 보고 싶었습니다. 따라서 원래 ‘11,900’ 이후의 모든 값은 내가 과도한 훈련을 했는지 여부에 대한 좋은 척도가 될 것입니다. 그래서 총 단계 <code>11,900</code> x <code>2</code> &#x3D; <code>23,800</code>을 두 배로 늘린 다음 반올림했습니다.</p><p><code>CHECKPOINTING_STEPS</code>는 모델 체크포인트를 저장하려는 빈도를 나타냅니다. ‘400’으로 설정하는 것은 제게는 한 시대에 꽤 가깝기 때문에 괜찮아 보였습니다.</p><p><code>CHECKPOINTING_LIMIT</code>은 이전 체크포인트를 덮어쓰기 전에 저장하려는 체크포인트 수입니다. 제 경우에는 체크포인트를 모두 유지하고 싶어서 ‘60’처럼 높은 숫자로 제한을 두었습니다.</p><h3 id="Multiple-concepts"><a href="#Multiple-concepts" class="headerlink" title="Multiple concepts"></a>Multiple concepts</h3><p>The above example is trained on a single concept with one unifying trigger word at the beginning: <code>k4s4</code>. However, if your dataset has multiple concepts&#x2F;trigger words, then your step calculation could be something like this so:</p><p><code>2</code> concepts <code>[a, b]</code></p><p>$$<br>\text{Max steps} &#x3D; \left(\frac{N_a \times R_a + N_b \times R_b}{\text{Batch size}}\right) \times \text{Epochs}<br>$$</p><p><code>i</code> concepts</p><p>$$<br>\text{Max steps} &#x3D; \left(\frac{\sum_{i \in C} N_i \times R_i}{\text{Batch size}}\right) \times \text{Epochs}<br>$$</p><p>마지막으로 학습률의 경우 ‘1.5e-3’으로 설정했습니다. 더 높을수록 기울기가 다음과 같이 폭발하기 때문입니다.</p><p>다른 관련 설정은 ‘LoRA’와 관련이 있습니다.</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;--lora_rank&quot;</span><span class="punctuation">:</span> <span class="number">768</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--lora_alpha&quot;</span><span class="punctuation">:</span> <span class="number">768</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--lora_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;standard&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>개인적으로는 좀 더 높은 ‘LoRA’ 랭크와 알파를 사용해 아주 만족스러운 결과를 얻었습니다. 내 YouTube <a href="https://youtube.com/@kasukanra">채널</a>에서 ‘LoRA’ 순위를 높일수록 이미지 충실도가 어떻게 증가하는지에 대한 보다 정확한 경험적 분석을 보려면 최신 동영상을 시청할 수 있습니다. .</p><p>어쨌든 VRAM, 저장 용량 또는 그렇게 높아질 시간이 없다면 ‘256’ 또는 ‘128’과 같이 더 낮은 값을 선택할 수 있습니다.</p><p><code>lora_type</code>에 관해서는, 나는 시도되고 진실된 <code>standard</code>를 사용하겠습니다. ‘LoRA’의 ‘lycoris’ 유형에 대한 또 다른 옵션이 있지만 아직은 매우 실험적이며 잘 탐색되지 않았습니다. 나는 ‘lycoris’에 대해 직접 심층 분석했지만 만족스러운 결과를 얻을 수 있는 올바른 설정을 찾지 못했습니다.</p><h3 id="Custom-config-json-miscellaneous"><a href="#Custom-config-json-miscellaneous" class="headerlink" title="Custom config.json miscellaneous"></a>Custom <code>config.json</code> miscellaneous</h3><p>삶의 질을 위해 변경할 수 있는 몇 가지 추가 설정이 있습니다.</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;--validation_prompt&quot;</span><span class="punctuation">:</span> <span class="string">&quot;k4s4, a waist up view of a beautiful blonde woman, green eyes&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--validation_guidance&quot;</span><span class="punctuation">:</span> <span class="number">7.5</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--validation_steps&quot;</span><span class="punctuation">:</span> <span class="number">200</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--validation_num_inference_steps&quot;</span><span class="punctuation">:</span> <span class="number">30</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--validation_negative_prompt&quot;</span><span class="punctuation">:</span> <span class="string">&quot;blurry, cropped, ugly&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--validation_seed&quot;</span><span class="punctuation">:</span> <span class="number">42</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--lr_scheduler&quot;</span><span class="punctuation">:</span> <span class="string">&quot;cosine&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--lr_warmup_steps&quot;</span><span class="punctuation">:</span> <span class="number">2400</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p><code>&quot;--validation_prompt&quot;: &quot;k4s4, a waist up view of a beautiful blonde woman, green eyes&quot;</code></p><p><code>&quot;--validation_guidance&quot;: 7.5</code><br><code>&quot;--validation_steps&quot;: 200</code><br><code>&quot;--validation_num_inference_steps&quot;: 30</code><br><code>&quot;--validation_negative_prompt&quot;: &quot;blurry, cropped, ugly&quot;</code></p><p><code>&quot;--lr_scheduler&quot;: &quot;cosine&quot;</code></p><p><code>&quot;--lr_warmup_steps&quot;: 2400</code></p><p>이것들은 매우 자명합니다:</p><p><code>&quot;--validation_prompt&quot;</code></p><p>검증 이미지를 생성하는 데 사용할 프롬프트입니다. 이것이 당신의 긍정적인 메시지입니다.</p><p><code>&quot;--validation_negative_prompt&quot;</code></p><p>부정적인 프롬프트.</p><p><code>&quot;--validation_guidance&quot;</code></p><p>Classifier free guidance (CFG) scale.</p><p><code>&quot;--validation_num_inference_steps&quot;</code></p><p>사용할 샘플링 단계 수입니다.</p><p><code>&quot;--validation_seed&quot;</code></p><p>검증 이미지 생성 시 시드 값입니다.</p><p><code>&quot;--lr_warmup_steps&quot;</code></p><p>‘SimpleTuner’는 설정하지 않을 경우 기본 워밍업을 전체 훈련 단계의 ‘10%’로 설정했는데, 이는 제가 자주 사용하는 값입니다. 그래서 (<code>24,000</code> * <code>0.1</code> &#x3D; <code>2,400</code>)에 하드코딩했습니다. 자유롭게 변경해 보세요.</p><p><code>&quot;--validation_steps&quot;</code></p><p>검증 이미지를 생성하려는 빈도는 <code>&quot;--validation_steps&quot;</code>로 설정됩니다. 저는 400의 1&#x2F;2인 200으로 설정했습니다(판타지 아트 예제 데이터세트에 대한 한 시대의 단계 수). 이는 에포크의 1&#x2F;2마다 검증 이미지를 생성한다는 의미입니다. 온전한 확인을 위해 최소한 반기점마다 검증 이미지를 생성하는 것이 좋습니다. 그렇지 않으면 최대한 빨리 오류를 포착하지 못할 수도 있습니다.</p><p>마지막으로 <code>&quot;--lr_scheduler&quot;</code>와 <code>&quot;--lr_warmup_steps&quot;</code>입니다.</p><p>저는 ‘코사인’ 스케줄러를 사용했습니다. 다음과 같은 모습입니다.</p><h3 id="What-happened-to-the-low-level-config-env"><a href="#What-happened-to-the-low-level-config-env" class="headerlink" title="What happened to the low-level config.env ?"></a>What happened to the low-level <code>config.env</code> ?</h3><p>앞서 언급했듯이 <code>SimpleTuner</code>는 낮은 수준의 <code>config.env</code> 형식에서 벗어나 사용 편의성을 위해 <code>json</code>을 선택하는 것으로 보입니다. 대부분의 다른 교육 리포지토리도 <code>json</code>을 사용합니다.</p><p>그러나 <a href="https://github.com/bghira/SimpleTuner/blob/main/helpers/configuration/loader.py#L17">loader.py</a>의 코드를 기반으로 하위 수준 <code>config.env</code>는 계속 지원됩니다. . 또한 이전의 낮은 수준 <code>config.env</code> 파일이 이미 있는 <code>SimpleTuner</code>의 이전 사용자는 파일 형식을 전환하지 않고도 일부 매개변수를 조정하여 신속하게 속도를 얻을 수 있습니다(해당 [OPTIONS.MD](https &#x2F;&#x2F;github.com&#x2F;bghira&#x2F;SimpleTuner&#x2F;blob&#x2F;main&#x2F;OPTIONS.md#environment-configuration-variables)).</p><h2 id="이는-위의-config-json과-동일한-버전이지만-env-형식입니다"><a href="#이는-위의-config-json과-동일한-버전이지만-env-형식입니다" class="headerlink" title="이는 위의 config.json과 동일한 버전이지만 .env 형식입니다."></a>이는 위의 <code>config.json</code>과 동일한 버전이지만 <code>.env</code> 형식입니다.</h2><ul><li><p>Custom SD3.5 Large <code>LoRA</code> <code>config.env</code></p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> MODEL_TYPE=<span class="string">&#x27;lora&#x27;</span></span><br><span class="line"><span class="built_in">export</span> MODEL_FAMILY=<span class="string">&#x27;sd3&#x27;</span></span><br><span class="line"><span class="built_in">export</span> CONTROLNET=<span class="literal">false</span></span><br><span class="line"><span class="built_in">export</span> USE_DORA=<span class="literal">false</span></span><br><span class="line"><span class="comment"># Restart where we left off. Change this to &quot;checkpoint-1234&quot; to start from a specific checkpoint.</span></span><br><span class="line"><span class="built_in">export</span> RESUME_CHECKPOINT=<span class="string">&quot;latest&quot;</span></span><br><span class="line"><span class="built_in">export</span> CHECKPOINTING_STEPS=400</span><br><span class="line"><span class="comment"># This is how many checkpoints we will keep. Two is safe, but three is safer.</span></span><br><span class="line"><span class="built_in">export</span> CHECKPOINTING_LIMIT=60</span><br><span class="line"></span><br><span class="line"><span class="comment"># This is decided as a relatively conservative &#x27;constant&#x27; learning rate.</span></span><br><span class="line"><span class="comment"># Adjust higher or lower depending on how burnt your model becomes.</span></span><br><span class="line"><span class="built_in">export</span> LEARNING_RATE=1.05e-3</span><br><span class="line"></span><br><span class="line"><span class="comment"># Using a Huggingface Hub model:</span></span><br><span class="line"><span class="built_in">export</span> MODEL_NAME=<span class="string">&quot;stabilityai/stable-diffusion-3.5-large&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Make DEBUG_EXTRA_ARGS empty to disable wandb.</span></span><br><span class="line"><span class="built_in">export</span> DEBUG_EXTRA_ARGS=<span class="string">&quot;--report_to=wandb&quot;</span></span><br><span class="line"><span class="built_in">export</span> TRACKER_PROJECT_NAME=<span class="string">&quot;sd35-training&quot;</span></span><br><span class="line"><span class="built_in">export</span> TRACKER_RUN_NAME=<span class="string">&quot;simpletuner-fantasy-art-lora-01&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Max number of steps OR epochs can be used. Not both.</span></span><br><span class="line"><span class="built_in">export</span> MAX_NUM_STEPS=24000</span><br><span class="line"><span class="built_in">export</span> NUM_EPOCHS=0</span><br><span class="line"></span><br><span class="line"><span class="comment"># A convenient prefix for all of your training paths.</span></span><br><span class="line"><span class="built_in">export</span> DATALOADER_CONFIG=<span class="string">&quot;/weka2/home-yeo/simpletuner_models/sd3_large/full_finetune/fantasy_art_L_01/datasets/multidatabackend.json&quot;</span></span><br><span class="line"><span class="built_in">export</span> OUTPUT_DIR=<span class="string">&quot;/weka2/home-yeo/simpletuner_models/sd3_large/full_finetune/fantasy_art_L_01/datasets/models&quot;</span></span><br><span class="line"><span class="comment"># Set this to &quot;true&quot; to push your model to Hugging Face Hub.</span></span><br><span class="line"><span class="built_in">export</span> PUSH_TO_HUB=<span class="string">&quot;false&quot;</span></span><br><span class="line"><span class="comment"># If PUSH_TO_HUB and PUSH_CHECKPOINTS are both enabled, every saved checkpoint will be pushed to Hugging Face Hub.</span></span><br><span class="line"><span class="built_in">export</span> PUSH_CHECKPOINTS=<span class="string">&quot;true&quot;</span></span><br><span class="line"><span class="comment"># This will be the model name for your final hub upload, eg. &quot;yourusername/yourmodelname&quot;</span></span><br><span class="line"><span class="comment"># It defaults to the wandb project name, but you can override this here.</span></span><br><span class="line"><span class="comment"># export HUB_MODEL_NAME=$TRACKER_PROJECT_NAME</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># By default, images will be resized so their SMALLER EDGE is 1024 pixels, maintaining aspect ratio.</span></span><br><span class="line"><span class="comment"># Setting this value to 768px might result in more reasonable training data sizes for SDXL.</span></span><br><span class="line"><span class="built_in">export</span> RESOLUTION=1024</span><br><span class="line"><span class="comment"># If you want to have the training data resized by pixel area (Megapixels) rather than edge length,</span></span><br><span class="line"><span class="comment">#  set this value to &quot;area&quot; instead of &quot;pixel&quot;, and uncomment the next RESOLUTION declaration.</span></span><br><span class="line"><span class="built_in">export</span> RESOLUTION_TYPE=<span class="string">&quot;pixel&quot;</span></span><br><span class="line"><span class="comment">#export RESOLUTION=1          # 1.0 Megapixel training sizes</span></span><br><span class="line"><span class="comment"># If RESOLUTION_TYPE=&quot;pixel&quot;, the minimum resolution specifies the smaller edge length, measured in pixels. Recommended: 1024.</span></span><br><span class="line"><span class="comment"># If RESOLUTION_TYPE=&quot;area&quot;, the minimum resolution specifies the total image area, measured in megapixels. Recommended: 1.</span></span><br><span class="line"><span class="built_in">export</span> MINIMUM_RESOLUTION=1024</span><br><span class="line"></span><br><span class="line"><span class="comment"># How many decimals to round aspect buckets to.</span></span><br><span class="line"><span class="comment">#export ASPECT_BUCKET_ROUNDING=2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Use this to append an instance prompt to each caption, used for adding trigger words.</span></span><br><span class="line"><span class="comment"># This has not been tested in SDXL.</span></span><br><span class="line"><span class="built_in">export</span> INSTANCE_PROMPT=<span class="string">&quot;k4s4 &quot;</span></span><br><span class="line"><span class="comment"># If you also supply a user prompt library or `--use_prompt_library`, this will be added to those lists.</span></span><br><span class="line"><span class="built_in">export</span> VALIDATION_PROMPT=<span class="string">&quot;k4s4, a waist up view of a beautiful blonde woman, green eyes&quot;</span></span><br><span class="line"><span class="built_in">export</span> VALIDATION_GUIDANCE=7.5</span><br><span class="line"><span class="comment"># You&#x27;ll want to set this to 0.7 if you are training a terminal SNR model.</span></span><br><span class="line"><span class="built_in">export</span> VALIDATION_GUIDANCE_RESCALE=0.0</span><br><span class="line"><span class="comment"># How frequently we will save and run a pipeline for validations.</span></span><br><span class="line"><span class="comment"># export VALIDATION_STEPS=200</span></span><br><span class="line"><span class="built_in">export</span> VALIDATION_STEPS=70</span><br><span class="line"><span class="built_in">export</span> VALIDATION_NUM_INFERENCE_STEPS=30</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> VALIDATION_NEGATIVE_PROMPT=<span class="string">&quot;blurry, cropped, ugly&quot;</span></span><br><span class="line"><span class="built_in">export</span> VALIDATION_SEED=42</span><br><span class="line"><span class="built_in">export</span> VALIDATION_RESOLUTION=1024</span><br><span class="line"></span><br><span class="line"><span class="comment"># Adjust this for your GPU memory size. This, and resolution, are the biggest VRAM killers.</span></span><br><span class="line"><span class="built_in">export</span> TRAIN_BATCH_SIZE=6</span><br><span class="line"><span class="comment"># Accumulate your update gradient over many steps, to save VRAM while still having higher effective batch size:</span></span><br><span class="line"><span class="comment"># effective batch size = ($TRAIN_BATCH_SIZE * $GRADIENT_ACCUMULATION_STEPS).</span></span><br><span class="line"><span class="built_in">export</span> GRADIENT_ACCUMULATION_STEPS=1</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use any standard scheduler type. constant, polynomial, constant_with_warmup</span></span><br><span class="line"><span class="built_in">export</span> LR_SCHEDULE=<span class="string">&quot;cosine&quot;</span></span><br><span class="line"><span class="comment"># A warmup period allows the model and the EMA weights more importantly to familiarise itself with the current quanta.</span></span><br><span class="line"><span class="comment"># For the cosine or sine type schedules, the warmup period defines the interval between peaks or valleys.</span></span><br><span class="line"><span class="comment"># Use a sine schedule to simulate a warmup period, or a Cosine period to simulate a polynomial start.</span></span><br><span class="line"><span class="comment"># export LR_WARMUP_STEPS=$((MAX_NUM_STEPS / 10))</span></span><br><span class="line"><span class="built_in">export</span> LR_WARMUP_STEPS=2400</span><br><span class="line"></span><br><span class="line"><span class="comment"># Caption dropout probability. Set to 0.1 for 10% of captions dropped out. Set to 0 to disable.</span></span><br><span class="line"><span class="comment"># You may wish to disable dropout if you want to limit your changes strictly to the prompts you show the model.</span></span><br><span class="line"><span class="comment"># You may wish to increase the rate of dropout if you want to more broadly adopt your changes across the model.</span></span><br><span class="line"><span class="built_in">export</span> CAPTION_DROPOUT_PROBABILITY=0</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> METADATA_UPDATE_INTERVAL=65</span><br><span class="line"><span class="built_in">export</span> VAE_BATCH_SIZE=12</span><br><span class="line"></span><br><span class="line"><span class="comment"># If this is set, any images that fail to open will be DELETED to avoid re-checking them every time.</span></span><br><span class="line"><span class="built_in">export</span> DELETE_ERRORED_IMAGES=0</span><br><span class="line"><span class="comment"># If this is set, any images that are too small for the minimum resolution size will be DELETED.</span></span><br><span class="line"><span class="built_in">export</span> DELETE_SMALL_IMAGES=0</span><br><span class="line"></span><br><span class="line"><span class="comment"># Bytedance recommends these be set to &quot;trailing&quot; so that inference and training behave in a more congruent manner.</span></span><br><span class="line"><span class="comment"># To follow the original SDXL training strategy, use &quot;leading&quot; instead, though results are generally worse.</span></span><br><span class="line"><span class="built_in">export</span> TRAINING_SCHEDULER_TIMESTEP_SPACING=<span class="string">&quot;trailing&quot;</span></span><br><span class="line"><span class="built_in">export</span> INFERENCE_SCHEDULER_TIMESTEP_SPACING=<span class="string">&quot;trailing&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Removing this option or unsetting it uses vanilla training. Setting it reweights the loss by the position of the timestep in the noise schedule.</span></span><br><span class="line"><span class="comment"># A value &quot;5&quot; is recommended by the researchers. A value of &quot;20&quot; is the least impact, and &quot;1&quot; is the most impact.</span></span><br><span class="line"><span class="built_in">export</span> MIN_SNR_GAMMA=5</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set this to an explicit value of &quot;false&quot; to disable Xformers. Probably required for AMD users.</span></span><br><span class="line"><span class="built_in">export</span> USE_XFORMERS=<span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># There&#x27;s basically no reason to unset this. However, to disable it, use an explicit value of &quot;false&quot;.</span></span><br><span class="line"><span class="comment"># This will save a lot of memory consumption when enabled.</span></span><br><span class="line"><span class="built_in">export</span> USE_GRADIENT_CHECKPOINTING=<span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment">##</span></span><br><span class="line"><span class="comment"># Options below here may require a bit more complicated configuration, so they are not simple variables.</span></span><br><span class="line"><span class="comment">##</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># TF32 is great on Ampere or Ada, not sure about earlier generations.</span></span><br><span class="line"><span class="built_in">export</span> ALLOW_TF32=<span class="literal">true</span></span><br><span class="line"><span class="comment"># AdamW 8Bit is a robust and lightweight choice. Adafactor might reduce memory consumption, and Dadaptation is slow and experimental.</span></span><br><span class="line"><span class="comment"># AdamW is the default optimizer, but it uses a lot of memory and is slower than AdamW8Bit or Adafactor.</span></span><br><span class="line"><span class="comment"># Choices: adamw, adamw8bit, adafactor, dadaptation</span></span><br><span class="line"><span class="comment"># export OPTIMIZER=&quot;adamw_bf16&quot;</span></span><br><span class="line"><span class="built_in">export</span> OPTIMIZER=<span class="string">&quot;adamw_bf16&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># EMA is a strong regularisation method that uses a lot of extra VRAM to hold two copies of the weights.</span></span><br><span class="line"><span class="comment"># This is worthwhile on large training runs, but not so much for smaller training runs.</span></span><br><span class="line"><span class="built_in">export</span> USE_EMA=<span class="literal">false</span></span><br><span class="line"><span class="built_in">export</span> EMA_DECAY=0.999</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> TRAINER_EXTRA_ARGS=<span class="string">&quot;--lora_rank=768 --lora_alpha=768&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Reproducible training. Set to -1 to disable.</span></span><br><span class="line"><span class="built_in">export</span> TRAINING_SEED=42</span><br><span class="line"></span><br><span class="line"><span class="comment"># Mixed precision is the best. You honestly might need to YOLO it in fp16 mode for Google Colab type setups.</span></span><br><span class="line"><span class="built_in">export</span> MIXED_PRECISION=<span class="string">&quot;bf16&quot;</span></span><br><span class="line"><span class="built_in">export</span> PURE_BF16=<span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># This has to be changed if you&#x27;re training with multiple GPUs.</span></span><br><span class="line"><span class="built_in">export</span> TRAINING_NUM_PROCESSES=1</span><br><span class="line"><span class="built_in">export</span> TRAINING_NUM_MACHINES=1</span><br><span class="line"><span class="built_in">export</span> ACCELERATE_EXTRA_ARGS=<span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># With Pytorch 2.1, you might have pretty good luck here.</span></span><br><span class="line"><span class="comment"># If you&#x27;re using aspect bucketing however, each resolution change will recompile. Seriously, just don&#x27;t do it.</span></span><br><span class="line"><span class="comment"># Well, then again... Pytorch 2.2 has support for dynamic shapes. Why not?</span></span><br><span class="line"><span class="built_in">export</span> TRAINING_DYNAMO_BACKEND=<span class="string">&#x27;no&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> TOKENIZERS_PARALLELISM=<span class="literal">false</span></span><br></pre></td></tr></table></figure></li></ul><p><a href="https://emojipedia.org/index-pointing-up">**☝️</a>** <code>LoRA</code> 순위&#x2F;알파는 <code>TRAINER_EXTRA_ARGS</code> 변수 내에서 변경될 수 있다는 점을 지적하고 싶습니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> TRAINER_EXTRA_ARGS=<span class="string">&quot;--lora_rank=768 --lora_alpha=768&quot;</span></span><br></pre></td></tr></table></figure><p><a href="https://emojipedia.org/warning">**⚠️</a>** <code>.env</code> 형식을 사용하기로 결정한 경우 인라인 주석, 참조 변수 또는 계산이 없는지 확인하세요. 이것은 새로운 <code>SimpleTuner</code> <a href="https://github.com/bghira/SimpleTuner/blob/main/helpers/configuration/env_file.py#L94">env 도우미</a>가 작동하는 방식이므로 모든 것을 하드 코딩해야 합니다. . ****예를 들어:</p><p><strong>Failure case 1 (inline comments):</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> LEARNING_RATE=1.05e-3 <span class="comment">#@param &#123;type:&quot;number&quot;&#125;</span></span><br></pre></td></tr></table></figure><p><strong>Failure case 2 (reference variable with <code>TRAINER_EXTRA_ARGS</code>):</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> TRAINER_EXTRA_ARGS=<span class="string">&quot;<span class="variable">$&#123;TRAINER_EXTRA_ARGS&#125;</span> --offset_noise --noise_offset=0.02&quot;</span></span><br></pre></td></tr></table></figure><p><strong>Failure case 3 (calculations)</strong>:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> LR_WARMUP_STEPS=$((MAX_NUM_STEPS / <span class="number">10</span>))</span><br></pre></td></tr></table></figure><p>원하는 경우 위의 하위 수준 <code>config.env</code>를 기본 참조로 사용할 수 있습니다. 하위 수준 <code>env</code> 파일을 사용하기로 결정한 경우 상위 수준 <code>config.env</code>에서 <code>CONFIG_BACKEND</code>를 <code>env</code>로 변경하는 것을 잊지 마세요.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">TRAINING_NUM_PROCESSES=1</span><br><span class="line">TRAINING_NUM_MACHINES=1</span><br><span class="line">TRAINING_DYNAMO_BACKEND=<span class="string">&#x27;no&#x27;</span></span><br><span class="line">MIXED_PRECISION=<span class="string">&#x27;bf16&#x27;</span></span><br><span class="line"><span class="built_in">export</span> CONFIG_BACKEND=<span class="string">&quot;env&quot;</span></span><br><span class="line"><span class="built_in">export</span> ENV=<span class="string">&quot;sd35_fantasy_art_lora&quot;</span></span><br></pre></td></tr></table></figure><h2 id="Training-process"><a href="#Training-process" class="headerlink" title="Training process"></a>Training process</h2><p>마지막으로 훈련 과정을 시작할 수 있습니다. 참고용으로 필요한 모든 파일을 여기에 가져오겠습니다.</p><ul><li><p>High-level <code>config.env</code></p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">TRAINING_NUM_PROCESSES=1</span><br><span class="line">TRAINING_NUM_MACHINES=1</span><br><span class="line">TRAINING_DYNAMO_BACKEND=<span class="string">&#x27;no&#x27;</span></span><br><span class="line">MIXED_PRECISION=<span class="string">&#x27;bf16&#x27;</span></span><br><span class="line"><span class="built_in">export</span> CONFIG_BACKEND=<span class="string">&quot;json&quot;</span></span><br><span class="line"><span class="built_in">export</span> ENV=<span class="string">&quot;sd35_fantasy_art_lora&quot;</span></span><br></pre></td></tr></table></figure></li><li><p>Custom SD3.5 Large <code>config.json</code> for LoRA training</p>  <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;--model_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;lora&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--model_family&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sd3&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--resume_from_checkpoint&quot;</span><span class="punctuation">:</span> <span class="string">&quot;latest&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--checkpointing_steps&quot;</span><span class="punctuation">:</span> <span class="number">400</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--checkpoints_total_limit&quot;</span><span class="punctuation">:</span> <span class="number">60</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--learning_rate&quot;</span><span class="punctuation">:</span> <span class="number">1.05e-3</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--pretrained_model_name_or_path&quot;</span><span class="punctuation">:</span> <span class="string">&quot;stabilityai/stable-diffusion-3.5-large&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--report_to&quot;</span><span class="punctuation">:</span> <span class="string">&quot;wandb&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--tracker_project_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sd35-training&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--tracker_run_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;simpletuner-fantasy-art-lora-01&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--max_train_steps&quot;</span><span class="punctuation">:</span> <span class="number">24000</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--num_train_epochs&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--data_backend_config&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/weka2/home-yeo/simpletuner_models/sd3_large/full_finetune/fantasy_art_L_01/datasets/multidatabackend.json&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--output_dir&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/weka2/home-yeo/simpletuner_models/sd3_large/full_finetune/fantasy_art_L_01/datasets/models&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--push_to_hub&quot;</span><span class="punctuation">:</span> <span class="keyword">false</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--push_checkpoints_to_hub&quot;</span><span class="punctuation">:</span> <span class="keyword">true</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--hub_model_id&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sd35-training&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--resolution&quot;</span><span class="punctuation">:</span> <span class="number">1024</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--resolution_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;pixel&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--minimum_image_size&quot;</span><span class="punctuation">:</span> <span class="number">1024</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--instance_prompt&quot;</span><span class="punctuation">:</span> <span class="string">&quot;k4s4 &quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--validation_prompt&quot;</span><span class="punctuation">:</span> <span class="string">&quot;k4s4, a waist up view of a beautiful blonde woman, green eyes&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--validation_guidance&quot;</span><span class="punctuation">:</span> <span class="number">7.5</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--validation_guidance_rescale&quot;</span><span class="punctuation">:</span> <span class="number">0.0</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--validation_steps&quot;</span><span class="punctuation">:</span> <span class="number">200</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--validation_num_inference_steps&quot;</span><span class="punctuation">:</span> <span class="number">30</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--validation_negative_prompt&quot;</span><span class="punctuation">:</span> <span class="string">&quot;blurry, cropped, ugly&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--validation_seed&quot;</span><span class="punctuation">:</span> <span class="number">42</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--validation_resolution&quot;</span><span class="punctuation">:</span> <span class="number">1024</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--train_batch_size&quot;</span><span class="punctuation">:</span> <span class="number">6</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--gradient_accumulation_steps&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--lr_scheduler&quot;</span><span class="punctuation">:</span> <span class="string">&quot;cosine&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--lr_warmup_steps&quot;</span><span class="punctuation">:</span> <span class="number">2400</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--caption_dropout_probability&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--metadata_update_interval&quot;</span><span class="punctuation">:</span> <span class="number">65</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--vae_batch_size&quot;</span><span class="punctuation">:</span> <span class="number">12</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--delete_unwanted_images&quot;</span><span class="punctuation">:</span> <span class="keyword">false</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--delete_problematic_images&quot;</span><span class="punctuation">:</span> <span class="keyword">false</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--training_scheduler_timestep_spacing&quot;</span><span class="punctuation">:</span> <span class="string">&quot;trailing&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--inference_scheduler_timestep_spacing&quot;</span><span class="punctuation">:</span> <span class="string">&quot;trailing&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--snr_gamma&quot;</span><span class="punctuation">:</span> <span class="number">5</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--enable_xformers_memory_efficient_attention&quot;</span><span class="punctuation">:</span> <span class="keyword">true</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--gradient_checkpointing&quot;</span><span class="punctuation">:</span> <span class="keyword">true</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--allow_tf32&quot;</span><span class="punctuation">:</span> <span class="keyword">true</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--optimizer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;adamw_bf16&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--use_ema&quot;</span><span class="punctuation">:</span> <span class="keyword">false</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--ema_decay&quot;</span><span class="punctuation">:</span> <span class="number">0.999</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--seed&quot;</span><span class="punctuation">:</span> <span class="number">42</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--mixed_precision&quot;</span><span class="punctuation">:</span> <span class="string">&quot;bf16&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--lora_rank&quot;</span><span class="punctuation">:</span> <span class="number">768</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--lora_alpha&quot;</span><span class="punctuation">:</span> <span class="number">768</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--lora_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;standard&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure></li><li><p>Custom SD3.5 Large  <code>config.env</code> for LoRA training</p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br></pre></td><td class="code"><pre><span class="line"> </span><br><span class="line"><span class="built_in">export</span> MODEL_TYPE=<span class="string">&#x27;lora&#x27;</span></span><br><span class="line"><span class="built_in">export</span> MODEL_FAMILY=<span class="string">&#x27;sd3&#x27;</span></span><br><span class="line"><span class="built_in">export</span> CONTROLNET=<span class="literal">false</span></span><br><span class="line"><span class="built_in">export</span> USE_DORA=<span class="literal">false</span></span><br><span class="line"><span class="comment"># Restart where we left off. Change this to &quot;checkpoint-1234&quot; to start from a specific checkpoint.</span></span><br><span class="line"><span class="built_in">export</span> RESUME_CHECKPOINT=<span class="string">&quot;latest&quot;</span></span><br><span class="line"><span class="built_in">export</span> CHECKPOINTING_STEPS=400</span><br><span class="line"><span class="comment"># This is how many checkpoints we will keep. Two is safe, but three is safer.</span></span><br><span class="line"><span class="built_in">export</span> CHECKPOINTING_LIMIT=60</span><br><span class="line"></span><br><span class="line"><span class="comment"># This is decided as a relatively conservative &#x27;constant&#x27; learning rate.</span></span><br><span class="line"><span class="comment"># Adjust higher or lower depending on how burnt your model becomes.</span></span><br><span class="line"><span class="built_in">export</span> LEARNING_RATE=1.05e-3</span><br><span class="line"></span><br><span class="line"><span class="comment"># Using a Huggingface Hub model:</span></span><br><span class="line"><span class="built_in">export</span> MODEL_NAME=<span class="string">&quot;stabilityai/stable-diffusion-3.5-large&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Make DEBUG_EXTRA_ARGS empty to disable wandb.</span></span><br><span class="line"><span class="built_in">export</span> DEBUG_EXTRA_ARGS=<span class="string">&quot;--report_to=wandb&quot;</span></span><br><span class="line"><span class="built_in">export</span> TRACKER_PROJECT_NAME=<span class="string">&quot;sd35-training&quot;</span></span><br><span class="line"><span class="built_in">export</span> TRACKER_RUN_NAME=<span class="string">&quot;simpletuner-fantasy-art-lora-01&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Max number of steps OR epochs can be used. Not both.</span></span><br><span class="line"><span class="built_in">export</span> MAX_NUM_STEPS=24000</span><br><span class="line"><span class="built_in">export</span> NUM_EPOCHS=0</span><br><span class="line"></span><br><span class="line"><span class="comment"># A convenient prefix for all of your training paths.</span></span><br><span class="line"><span class="built_in">export</span> DATALOADER_CONFIG=<span class="string">&quot;/weka2/home-yeo/simpletuner_models/sd3_large/full_finetune/fantasy_art_L_01/datasets/multidatabackend.json&quot;</span></span><br><span class="line"><span class="built_in">export</span> OUTPUT_DIR=<span class="string">&quot;/weka2/home-yeo/simpletuner_models/sd3_large/full_finetune/fantasy_art_L_01/datasets/models&quot;</span></span><br><span class="line"><span class="comment"># Set this to &quot;true&quot; to push your model to Hugging Face Hub.</span></span><br><span class="line"><span class="built_in">export</span> PUSH_TO_HUB=<span class="string">&quot;false&quot;</span></span><br><span class="line"><span class="comment"># If PUSH_TO_HUB and PUSH_CHECKPOINTS are both enabled, every saved checkpoint will be pushed to Hugging Face Hub.</span></span><br><span class="line"><span class="built_in">export</span> PUSH_CHECKPOINTS=<span class="string">&quot;true&quot;</span></span><br><span class="line"><span class="comment"># This will be the model name for your final hub upload, eg. &quot;yourusername/yourmodelname&quot;</span></span><br><span class="line"><span class="comment"># It defaults to the wandb project name, but you can override this here.</span></span><br><span class="line"><span class="comment"># export HUB_MODEL_NAME=$TRACKER_PROJECT_NAME</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># By default, images will be resized so their SMALLER EDGE is 1024 pixels, maintaining aspect ratio.</span></span><br><span class="line"><span class="comment"># Setting this value to 768px might result in more reasonable training data sizes for SDXL.</span></span><br><span class="line"><span class="built_in">export</span> RESOLUTION=1024</span><br><span class="line"><span class="comment"># If you want to have the training data resized by pixel area (Megapixels) rather than edge length,</span></span><br><span class="line"><span class="comment">#  set this value to &quot;area&quot; instead of &quot;pixel&quot;, and uncomment the next RESOLUTION declaration.</span></span><br><span class="line"><span class="built_in">export</span> RESOLUTION_TYPE=<span class="string">&quot;pixel&quot;</span></span><br><span class="line"><span class="comment">#export RESOLUTION=1          # 1.0 Megapixel training sizes</span></span><br><span class="line"><span class="comment"># If RESOLUTION_TYPE=&quot;pixel&quot;, the minimum resolution specifies the smaller edge length, measured in pixels. Recommended: 1024.</span></span><br><span class="line"><span class="comment"># If RESOLUTION_TYPE=&quot;area&quot;, the minimum resolution specifies the total image area, measured in megapixels. Recommended: 1.</span></span><br><span class="line"><span class="built_in">export</span> MINIMUM_RESOLUTION=1024</span><br><span class="line"></span><br><span class="line"><span class="comment"># How many decimals to round aspect buckets to.</span></span><br><span class="line"><span class="comment">#export ASPECT_BUCKET_ROUNDING=2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Use this to append an instance prompt to each caption, used for adding trigger words.</span></span><br><span class="line"><span class="comment"># This has not been tested in SDXL.</span></span><br><span class="line"><span class="built_in">export</span> INSTANCE_PROMPT=<span class="string">&quot;k4s4 &quot;</span></span><br><span class="line"><span class="comment"># If you also supply a user prompt library or `--use_prompt_library`, this will be added to those lists.</span></span><br><span class="line"><span class="built_in">export</span> VALIDATION_PROMPT=<span class="string">&quot;k4s4, a waist up view of a beautiful blonde woman, green eyes&quot;</span></span><br><span class="line"><span class="built_in">export</span> VALIDATION_GUIDANCE=7.5</span><br><span class="line"><span class="comment"># You&#x27;ll want to set this to 0.7 if you are training a terminal SNR model.</span></span><br><span class="line"><span class="built_in">export</span> VALIDATION_GUIDANCE_RESCALE=0.0</span><br><span class="line"><span class="comment"># How frequently we will save and run a pipeline for validations.</span></span><br><span class="line"><span class="comment"># export VALIDATION_STEPS=200</span></span><br><span class="line"><span class="built_in">export</span> VALIDATION_STEPS=70</span><br><span class="line"><span class="built_in">export</span> VALIDATION_NUM_INFERENCE_STEPS=30</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> VALIDATION_NEGATIVE_PROMPT=<span class="string">&quot;blurry, cropped, ugly&quot;</span></span><br><span class="line"><span class="built_in">export</span> VALIDATION_SEED=42</span><br><span class="line"><span class="built_in">export</span> VALIDATION_RESOLUTION=1024</span><br><span class="line"></span><br><span class="line"><span class="comment"># Adjust this for your GPU memory size. This, and resolution, are the biggest VRAM killers.</span></span><br><span class="line"><span class="built_in">export</span> TRAIN_BATCH_SIZE=6</span><br><span class="line"><span class="comment"># Accumulate your update gradient over many steps, to save VRAM while still having higher effective batch size:</span></span><br><span class="line"><span class="comment"># effective batch size = ($TRAIN_BATCH_SIZE * $GRADIENT_ACCUMULATION_STEPS).</span></span><br><span class="line"><span class="built_in">export</span> GRADIENT_ACCUMULATION_STEPS=1</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use any standard scheduler type. constant, polynomial, constant_with_warmup</span></span><br><span class="line"><span class="built_in">export</span> LR_SCHEDULE=<span class="string">&quot;cosine&quot;</span></span><br><span class="line"><span class="comment"># A warmup period allows the model and the EMA weights more importantly to familiarise itself with the current quanta.</span></span><br><span class="line"><span class="comment"># For the cosine or sine type schedules, the warmup period defines the interval between peaks or valleys.</span></span><br><span class="line"><span class="comment"># Use a sine schedule to simulate a warmup period, or a Cosine period to simulate a polynomial start.</span></span><br><span class="line"><span class="comment"># export LR_WARMUP_STEPS=$((MAX_NUM_STEPS / 10))</span></span><br><span class="line"><span class="built_in">export</span> LR_WARMUP_STEPS=2400</span><br><span class="line"></span><br><span class="line"><span class="comment"># Caption dropout probability. Set to 0.1 for 10% of captions dropped out. Set to 0 to disable.</span></span><br><span class="line"><span class="comment"># You may wish to disable dropout if you want to limit your changes strictly to the prompts you show the model.</span></span><br><span class="line"><span class="comment"># You may wish to increase the rate of dropout if you want to more broadly adopt your changes across the model.</span></span><br><span class="line"><span class="built_in">export</span> CAPTION_DROPOUT_PROBABILITY=0</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> METADATA_UPDATE_INTERVAL=65</span><br><span class="line"><span class="built_in">export</span> VAE_BATCH_SIZE=12</span><br><span class="line"></span><br><span class="line"><span class="comment"># If this is set, any images that fail to open will be DELETED to avoid re-checking them every time.</span></span><br><span class="line"><span class="built_in">export</span> DELETE_ERRORED_IMAGES=0</span><br><span class="line"><span class="comment"># If this is set, any images that are too small for the minimum resolution size will be DELETED.</span></span><br><span class="line"><span class="built_in">export</span> DELETE_SMALL_IMAGES=0</span><br><span class="line"></span><br><span class="line"><span class="comment"># Bytedance recommends these be set to &quot;trailing&quot; so that inference and training behave in a more congruent manner.</span></span><br><span class="line"><span class="comment"># To follow the original SDXL training strategy, use &quot;leading&quot; instead, though results are generally worse.</span></span><br><span class="line"><span class="built_in">export</span> TRAINING_SCHEDULER_TIMESTEP_SPACING=<span class="string">&quot;trailing&quot;</span></span><br><span class="line"><span class="built_in">export</span> INFERENCE_SCHEDULER_TIMESTEP_SPACING=<span class="string">&quot;trailing&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Removing this option or unsetting it uses vanilla training. Setting it reweights the loss by the position of the timestep in the noise schedule.</span></span><br><span class="line"><span class="comment"># A value &quot;5&quot; is recommended by the researchers. A value of &quot;20&quot; is the least impact, and &quot;1&quot; is the most impact.</span></span><br><span class="line"><span class="built_in">export</span> MIN_SNR_GAMMA=5</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set this to an explicit value of &quot;false&quot; to disable Xformers. Probably required for AMD users.</span></span><br><span class="line"><span class="built_in">export</span> USE_XFORMERS=<span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># There&#x27;s basically no reason to unset this. However, to disable it, use an explicit value of &quot;false&quot;.</span></span><br><span class="line"><span class="comment"># This will save a lot of memory consumption when enabled.</span></span><br><span class="line"><span class="built_in">export</span> USE_GRADIENT_CHECKPOINTING=<span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment">##</span></span><br><span class="line"><span class="comment"># Options below here may require a bit more complicated configuration, so they are not simple variables.</span></span><br><span class="line"><span class="comment">##</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># TF32 is great on Ampere or Ada, not sure about earlier generations.</span></span><br><span class="line"><span class="built_in">export</span> ALLOW_TF32=<span class="literal">true</span></span><br><span class="line"><span class="comment"># AdamW 8Bit is a robust and lightweight choice. Adafactor might reduce memory consumption, and Dadaptation is slow and experimental.</span></span><br><span class="line"><span class="comment"># AdamW is the default optimizer, but it uses a lot of memory and is slower than AdamW8Bit or Adafactor.</span></span><br><span class="line"><span class="comment"># Choices: adamw, adamw8bit, adafactor, dadaptation</span></span><br><span class="line"><span class="comment"># export OPTIMIZER=&quot;adamw_bf16&quot;</span></span><br><span class="line"><span class="built_in">export</span> OPTIMIZER=<span class="string">&quot;adamw_bf16&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># EMA is a strong regularisation method that uses a lot of extra VRAM to hold two copies of the weights.</span></span><br><span class="line"><span class="comment"># This is worthwhile on large training runs, but not so much for smaller training runs.</span></span><br><span class="line"><span class="built_in">export</span> USE_EMA=<span class="literal">false</span></span><br><span class="line"><span class="built_in">export</span> EMA_DECAY=0.999</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> TRAINER_EXTRA_ARGS=<span class="string">&quot;--lora_rank=768 --lora_alpha=768&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Reproducible training. Set to -1 to disable.</span></span><br><span class="line"><span class="built_in">export</span> TRAINING_SEED=42</span><br><span class="line"></span><br><span class="line"><span class="comment"># Mixed precision is the best. You honestly might need to YOLO it in fp16 mode for Google Colab type setups.</span></span><br><span class="line"><span class="built_in">export</span> MIXED_PRECISION=<span class="string">&quot;bf16&quot;</span></span><br><span class="line"><span class="built_in">export</span> PURE_BF16=<span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># This has to be changed if you&#x27;re training with multiple GPUs.</span></span><br><span class="line"><span class="built_in">export</span> TRAINING_NUM_PROCESSES=1</span><br><span class="line"><span class="built_in">export</span> TRAINING_NUM_MACHINES=1</span><br><span class="line"><span class="built_in">export</span> ACCELERATE_EXTRA_ARGS=<span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># With Pytorch 2.1, you might have pretty good luck here.</span></span><br><span class="line"><span class="comment"># If you&#x27;re using aspect bucketing however, each resolution change will recompile. Seriously, just don&#x27;t do it.</span></span><br><span class="line"><span class="comment"># Well, then again... Pytorch 2.2 has support for dynamic shapes. Why not?</span></span><br><span class="line"><span class="built_in">export</span> TRAINING_DYNAMO_BACKEND=<span class="string">&#x27;no&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> TOKENIZERS_PARALLELISM=<span class="literal">false</span></span><br></pre></td></tr></table></figure></li><li><p>Default <a href="http://train.sh/">train.sh</a></p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Pull config from config.env</span></span><br><span class="line">[ -f <span class="string">&quot;config/config.env&quot;</span> ] &amp;&amp; <span class="built_in">source</span> config/config.env</span><br><span class="line"></span><br><span class="line"><span class="comment"># If the user has not provided VENV_PATH, we will assume $(pwd)/.venv</span></span><br><span class="line"><span class="keyword">if</span> [ -z <span class="string">&quot;<span class="variable">$&#123;VENV_PATH&#125;</span>&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="comment"># what if we have VIRTUAL_ENV? use that instead</span></span><br><span class="line">    <span class="keyword">if</span> [ -n <span class="string">&quot;<span class="variable">$&#123;VIRTUAL_ENV&#125;</span>&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">export</span> VENV_PATH=<span class="string">&quot;<span class="variable">$&#123;VIRTUAL_ENV&#125;</span>&quot;</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="built_in">export</span> VENV_PATH=<span class="string">&quot;<span class="subst">$(pwd)</span>/.venv&quot;</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="keyword">if</span> [ -z <span class="string">&quot;<span class="variable">$&#123;DISABLE_LD_OVERRIDE&#125;</span>&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">export</span> NVJITLINK_PATH=<span class="string">&quot;<span class="subst">$(find <span class="string">&quot;<span class="variable">$&#123;VENV_PATH&#125;</span>&quot;</span> -name nvjitlink -type d)</span>/lib&quot;</span></span><br><span class="line">    <span class="comment"># if it&#x27;s not empty, we will add it to LD_LIBRARY_PATH at the front:</span></span><br><span class="line">    <span class="keyword">if</span> [ -n <span class="string">&quot;<span class="variable">$&#123;NVJITLINK_PATH&#125;</span>&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">export</span> LD_LIBRARY_PATH=<span class="string">&quot;<span class="variable">$&#123;NVJITLINK_PATH&#125;</span>:<span class="variable">$&#123;LD_LIBRARY_PATH&#125;</span>&quot;</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> TOKENIZERS_PARALLELISM=<span class="literal">false</span></span><br><span class="line"><span class="built_in">export</span> PLATFORM</span><br><span class="line">PLATFORM=$(<span class="built_in">uname</span> -s)</span><br><span class="line"><span class="keyword">if</span> [[ <span class="string">&quot;<span class="variable">$PLATFORM</span>&quot;</span> == <span class="string">&quot;Darwin&quot;</span> ]]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">export</span> MIXED_PRECISION=<span class="string">&quot;no&quot;</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ -z <span class="string">&quot;<span class="variable">$&#123;ACCELERATE_EXTRA_ARGS&#125;</span>&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">    ACCELERATE_EXTRA_ARGS=<span class="string">&quot;&quot;</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ -z <span class="string">&quot;<span class="variable">$&#123;TRAINING_NUM_PROCESSES&#125;</span>&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;Set custom env vars permanently in config/config.env:&quot;</span></span><br><span class="line">    <span class="built_in">printf</span> <span class="string">&quot;TRAINING_NUM_PROCESSES not set, defaulting to 1.\n&quot;</span></span><br><span class="line">    TRAINING_NUM_PROCESSES=1</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ -z <span class="string">&quot;<span class="variable">$&#123;TRAINING_NUM_MACHINES&#125;</span>&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">printf</span> <span class="string">&quot;TRAINING_NUM_MACHINES not set, defaulting to 1.\n&quot;</span></span><br><span class="line">    TRAINING_NUM_MACHINES=1</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ -z <span class="string">&quot;<span class="variable">$&#123;MIXED_PRECISION&#125;</span>&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">printf</span> <span class="string">&quot;MIXED_PRECISION not set, defaulting to bf16.\n&quot;</span></span><br><span class="line">    MIXED_PRECISION=bf16</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ -z <span class="string">&quot;<span class="variable">$&#123;TRAINING_DYNAMO_BACKEND&#125;</span>&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">printf</span> <span class="string">&quot;TRAINING_DYNAMO_BACKEND not set, defaulting to no.\n&quot;</span></span><br><span class="line">    TRAINING_DYNAMO_BACKEND=<span class="string">&quot;no&quot;</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ -z <span class="string">&quot;<span class="variable">$&#123;ENV&#125;</span>&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">printf</span> <span class="string">&quot;ENV not set, defaulting to default.\n&quot;</span></span><br><span class="line">    <span class="built_in">export</span> ENV=<span class="string">&quot;default&quot;</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="built_in">export</span> ENV_PATH=<span class="string">&quot;&quot;</span></span><br><span class="line"><span class="keyword">if</span> [[ <span class="string">&quot;<span class="variable">$ENV</span>&quot;</span> != <span class="string">&quot;default&quot;</span> ]]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">export</span> ENV_PATH=<span class="string">&quot;<span class="variable">$&#123;ENV&#125;</span>/&quot;</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ -z <span class="string">&quot;<span class="variable">$&#123;CONFIG_BACKEND&#125;</span>&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="keyword">if</span> [ -n <span class="string">&quot;<span class="variable">$&#123;CONFIG_TYPE&#125;</span>&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">export</span> CONFIG_BACKEND=<span class="string">&quot;<span class="variable">$&#123;CONFIG_TYPE&#125;</span>&quot;</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ -z <span class="string">&quot;<span class="variable">$&#123;CONFIG_BACKEND&#125;</span>&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">export</span> CONFIG_BACKEND=<span class="string">&quot;env&quot;</span></span><br><span class="line">    <span class="built_in">export</span> CONFIG_PATH=<span class="string">&quot;config/<span class="variable">$&#123;ENV_PATH&#125;</span>config&quot;</span></span><br><span class="line">    <span class="keyword">if</span> [ -f <span class="string">&quot;<span class="variable">$&#123;CONFIG_PATH&#125;</span>.json&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">export</span> CONFIG_BACKEND=<span class="string">&quot;json&quot;</span></span><br><span class="line">    <span class="keyword">elif</span> [ -f <span class="string">&quot;<span class="variable">$&#123;CONFIG_PATH&#125;</span>.toml&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">export</span> CONFIG_BACKEND=<span class="string">&quot;toml&quot;</span></span><br><span class="line">    <span class="keyword">elif</span> [ -f <span class="string">&quot;<span class="variable">$&#123;CONFIG_PATH&#125;</span>.env&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">export</span> CONFIG_BACKEND=<span class="string">&quot;env&quot;</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;Using <span class="variable">$&#123;CONFIG_BACKEND&#125;</span> backend: <span class="variable">$&#123;CONFIG_PATH&#125;</span>.<span class="variable">$&#123;CONFIG_BACKEND&#125;</span>&quot;</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Update dependencies</span></span><br><span class="line"><span class="keyword">if</span> [ -z <span class="string">&quot;<span class="variable">$&#123;DISABLE_UPDATES&#125;</span>&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&#x27;Updating dependencies. Set DISABLE_UPDATES to prevent this.&#x27;</span></span><br><span class="line">    <span class="keyword">if</span> [ -f <span class="string">&quot;pyproject.toml&quot;</span> ] &amp;&amp; [ -f <span class="string">&quot;poetry.lock&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">        nvidia-smi 2&gt; /dev/null &amp;&amp; poetry install</span><br><span class="line">        <span class="built_in">uname</span> -s | grep -q Darwin &amp;&amp; poetry install -C install/apple</span><br><span class="line">        rocm-smi 2&gt; /dev/null &amp;&amp; poetry install -C install/rocm</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="comment"># Run the training script.</span></span><br><span class="line"><span class="keyword">if</span> [[ -z <span class="string">&quot;<span class="variable">$&#123;ACCELERATE_CONFIG_PATH&#125;</span>&quot;</span> ]]; <span class="keyword">then</span></span><br><span class="line">    ACCELERATE_CONFIG_PATH=<span class="string">&quot;<span class="variable">$&#123;HOME&#125;</span>/.cache/huggingface/accelerate/default_config.yaml&quot;</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="keyword">if</span> [ -f <span class="string">&quot;<span class="variable">$&#123;ACCELERATE_CONFIG_PATH&#125;</span>&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;Using Accelerate config file: <span class="variable">$&#123;ACCELERATE_CONFIG_PATH&#125;</span>&quot;</span></span><br><span class="line">    accelerate launch --config_file=<span class="string">&quot;<span class="variable">$&#123;ACCELERATE_CONFIG_PATH&#125;</span>&quot;</span> train.py</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;Accelerate config file not found: <span class="variable">$&#123;ACCELERATE_CONFIG_PATH&#125;</span>. Using values from config.env.&quot;</span></span><br><span class="line">    accelerate launch <span class="variable">$&#123;ACCELERATE_EXTRA_ARGS&#125;</span> --mixed_precision=<span class="string">&quot;<span class="variable">$&#123;MIXED_PRECISION&#125;</span>&quot;</span> --num_processes=<span class="string">&quot;<span class="variable">$&#123;TRAINING_NUM_PROCESSES&#125;</span>&quot;</span> --num_machines=<span class="string">&quot;<span class="variable">$&#123;TRAINING_NUM_MACHINES&#125;</span>&quot;</span> --dynamo_backend=<span class="string">&quot;<span class="variable">$&#123;TRAINING_DYNAMO_BACKEND&#125;</span>&quot;</span> train.py</span><br><span class="line"></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">exit</span> 0</span><br></pre></td></tr></table></figure></li></ul><h3 id="Possible-accelerate-issues"><a href="#Possible-accelerate-issues" class="headerlink" title="Possible accelerate issues"></a>Possible <code>accelerate</code> issues</h3><p>여기서는 훈련을 시작하는 데 방해가 될 수 있는 한 가지 작은 사항을 언급하고 싶습니다. 끝 부분에 있는 기본 <code>train.sh</code> 안에는 훈련을 실행하는 명령이 있습니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">accelerate launch --config_file=<span class="string">&quot;<span class="variable">$&#123;ACCELERATE_CONFIG_PATH&#125;</span>&quot;</span> train.py</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Run the training script.</span></span><br><span class="line"><span class="keyword">if</span> [[ -z <span class="string">&quot;$&#123;ACCELERATE_CONFIG_PATH&#125;&quot;</span> ]]; then</span><br><span class="line">    ACCELERATE_CONFIG_PATH=<span class="string">&quot;$&#123;HOME&#125;/.cache/huggingface/accelerate/default_config.yaml&quot;</span></span><br><span class="line">fi</span><br><span class="line"><span class="keyword">if</span> [ -f <span class="string">&quot;$&#123;ACCELERATE_CONFIG_PATH&#125;&quot;</span> ]; then</span><br><span class="line">    echo <span class="string">&quot;Using Accelerate config file: $&#123;ACCELERATE_CONFIG_PATH&#125;&quot;</span></span><br><span class="line">    accelerate launch --config_file=<span class="string">&quot;$&#123;ACCELERATE_CONFIG_PATH&#125;&quot;</span> train.py</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    echo <span class="string">&quot;Accelerate config file not found: $&#123;ACCELERATE_CONFIG_PATH&#125;. Using values from config.env.&quot;</span></span><br><span class="line">    accelerate launch $&#123;ACCELERATE_EXTRA_ARGS&#125; --mixed_precision=<span class="string">&quot;$&#123;MIXED_PRECISION&#125;&quot;</span> --num_processes=<span class="string">&quot;$&#123;TRAINING_NUM_PROCESSES&#125;&quot;</span> --num_machines=<span class="string">&quot;$&#123;TRAINING_NUM_MACHINES&#125;&quot;</span> --dynamo_backend=<span class="string">&quot;$&#123;TRAINING_DYNAMO_BACKEND&#125;&quot;</span> train.py</span><br><span class="line"></span><br><span class="line">fi</span><br></pre></td></tr></table></figure><p>이것이 처음으로 훈련 저장소를 설치하는 것이라면 아마도 오류 없이 실행될 것입니다. 그러나 다른 저장소에서 <code>accelerate</code>를 사용한 경우 <code>default_config.yaml</code>을 이미 구성했을 가능성이 높습니다. 훈련에서 오류가 발생하는 경우 일반 훈련을 위해 여기에 자체 <code>config.yaml</code>을 제공했습니다. 또한 ‘LoRA’ 교육이 아닌 완전한 미세 조정을 시도하려는 경우 ‘DeepSpeed’ ‘config.yaml’을 제공했습니다.</p><p>‘DeepSpeed’는 GPU VRAM이 충분하지 않을 때 내부의 특수 기술을 사용하여 최적화 상태, 그라데이션 및 기타 매개변수를 CPU 메모리(RAM)로 오프로드합니다. ‘80GB’ VRAM과 ‘128GB’ CPU RAM을 갖춘 단일 ‘H100’ GPU에서는 ‘SD3.5 Large’로 완전한 미세 조정을 수행할 수 있었습니다. VRAM이 부족하고 CPU RAM으로 오프로드해야 할 때마다 이 <code>config.yaml</code>을 사용할 수도 있습니다.</p><ul><li><p>Custom general use <code>base_config.yaml</code></p>  <figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">compute_environment:</span> <span class="string">LOCAL_MACHINE</span></span><br><span class="line"><span class="attr">debug:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">distributed_type:</span> <span class="string">&#x27;NO&#x27;</span></span><br><span class="line"><span class="attr">downcast_bf16:</span> <span class="string">&#x27;no&#x27;</span></span><br><span class="line"><span class="attr">enable_cpu_affinity:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">gpu_ids:</span> <span class="string">all</span></span><br><span class="line"><span class="attr">machine_rank:</span> <span class="number">0</span></span><br><span class="line"><span class="attr">main_training_function:</span> <span class="string">main</span></span><br><span class="line"><span class="attr">mixed_precision:</span> <span class="string">bf16</span></span><br><span class="line"><span class="attr">num_machines:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">num_processes:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">rdzv_backend:</span> <span class="string">static</span></span><br><span class="line"><span class="attr">same_network:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">tpu_env:</span> []</span><br><span class="line"><span class="attr">tpu_use_cluster:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">tpu_use_sudo:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">use_cpu:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure></li><li><p>Custom <code>DeepSpeed 2</code> <code>deepspeed_config.yaml</code></p>  <figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">compute_environment:</span> <span class="string">LOCAL_MACHINE</span></span><br><span class="line"><span class="attr">debug:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">deepspeed_config:</span></span><br><span class="line">  <span class="attr">gradient_accumulation_steps:</span> <span class="number">8</span></span><br><span class="line">  <span class="attr">gradient_clipping:</span> <span class="number">1.0</span></span><br><span class="line">  <span class="attr">offload_optimizer_device:</span> <span class="string">cpu</span></span><br><span class="line">  <span class="attr">offload_param_device:</span> <span class="string">cpu</span></span><br><span class="line">  <span class="attr">zero3_init_flag:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">zero_stage:</span> <span class="number">2</span></span><br><span class="line"><span class="attr">distributed_type:</span> <span class="string">DEEPSPEED</span></span><br><span class="line"><span class="attr">downcast_bf16:</span> <span class="string">&#x27;no&#x27;</span></span><br><span class="line"><span class="attr">enable_cpu_affinity:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">machine_rank:</span> <span class="number">0</span></span><br><span class="line"><span class="attr">main_training_function:</span> <span class="string">main</span></span><br><span class="line"><span class="attr">mixed_precision:</span> <span class="string">bf16</span></span><br><span class="line"><span class="attr">num_machines:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">num_processes:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">rdzv_backend:</span> <span class="string">static</span></span><br><span class="line"><span class="attr">same_network:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">tpu_env:</span> []</span><br><span class="line"><span class="attr">tpu_use_cluster:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">tpu_use_sudo:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">use_cpu:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure></li></ul><p>이러한 <code>yaml</code> 파일을 배치할 위치를 선택할 때마다 <code>train.sh</code> 코드에서 해당 파일을 올바르게 참조해야 합니다. 예를 들어, 저는 <code>SimpleTuner</code> 디렉토리의 루트에 파일을 배치합니다. 따라서 코드의 ‘ACCELERATE_CONFIG_PATH’ 부분이 그에 따라 수정됩니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Run the training script with base config.</span></span><br><span class="line"><span class="keyword">if</span> [[ -z <span class="string">&quot;<span class="variable">$&#123;ACCELERATE_CONFIG_PATH&#125;</span>&quot;</span> ]]; <span class="keyword">then</span></span><br><span class="line">    ACCELERATE_CONFIG_PATH=<span class="string">&quot;<span class="variable">$&#123;HOME&#125;</span>/SimpleTuner/base_config.yaml&quot;</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure><p>or</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Run the training script with DeepSpeed config.</span></span><br><span class="line"><span class="keyword">if</span> [[ -z <span class="string">&quot;<span class="variable">$&#123;ACCELERATE_CONFIG_PATH&#125;</span>&quot;</span> ]]; <span class="keyword">then</span></span><br><span class="line">    ACCELERATE_CONFIG_PATH=<span class="string">&quot;<span class="variable">$&#123;HOME&#125;</span>/SimpleTuner/deepspeed_config.yaml&quot;</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure><p>결국 <code>DeepSpeed</code> 지원 훈련을 시도하게 된다면, 이에 따라 사용할 수 있는 하위 수준 <code>config.env</code> 샘플이 있습니다.</p><ul><li><p>Custom SD3.5 Large <code>full</code> fine-tune<code>config.json</code></p>  <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;--model_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;full&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--model_family&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sd3&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--resume_from_checkpoint&quot;</span><span class="punctuation">:</span> <span class="string">&quot;latest&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--checkpointing_steps&quot;</span><span class="punctuation">:</span> <span class="number">100</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--checkpoints_total_limit&quot;</span><span class="punctuation">:</span> <span class="number">100</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--learning_rate&quot;</span><span class="punctuation">:</span> <span class="number">5e-5</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--pretrained_model_name_or_path&quot;</span><span class="punctuation">:</span> <span class="string">&quot;stabilityai/stable-diffusion-3.5-large&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--report_to&quot;</span><span class="punctuation">:</span> <span class="string">&quot;wandb&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--tracker_project_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sd35-training&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--tracker_run_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;simpletuner-fantasy-art-full-01&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--max_train_steps&quot;</span><span class="punctuation">:</span> <span class="number">24000</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--num_train_epochs&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--data_backend_config&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/weka2/home-yeo/simpletuner_models/sd3_large/full_finetune/fantasy_art_L_01/datasets/multidatabackend.json&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--output_dir&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/weka2/home-yeo/simpletuner_models/sd3_large/full_finetune/fantasy_art_L_01/datasets/models&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--push_to_hub&quot;</span><span class="punctuation">:</span> <span class="keyword">false</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--push_checkpoints_to_hub&quot;</span><span class="punctuation">:</span> <span class="keyword">true</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--hub_model_id&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sd35-training&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--resolution&quot;</span><span class="punctuation">:</span> <span class="number">1024</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--resolution_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;pixel&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--minimum_image_size&quot;</span><span class="punctuation">:</span> <span class="number">1024</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--instance_prompt&quot;</span><span class="punctuation">:</span> <span class="string">&quot;k4s4 &quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--validation_prompt&quot;</span><span class="punctuation">:</span> <span class="string">&quot;k4s4, a waist up view of a beautiful blonde woman, green eyes&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--validation_guidance&quot;</span><span class="punctuation">:</span> <span class="number">7.5</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--validation_guidance_rescale&quot;</span><span class="punctuation">:</span> <span class="number">0.0</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--validation_steps&quot;</span><span class="punctuation">:</span> <span class="number">25</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--validation_num_inference_steps&quot;</span><span class="punctuation">:</span> <span class="number">30</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--validation_negative_prompt&quot;</span><span class="punctuation">:</span> <span class="string">&quot;blurry, cropped, ugly&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--validation_seed&quot;</span><span class="punctuation">:</span> <span class="number">42</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--validation_resolution&quot;</span><span class="punctuation">:</span> <span class="number">1024</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--train_batch_size&quot;</span><span class="punctuation">:</span> <span class="number">6</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--gradient_accumulation_steps&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--lr_scheduler&quot;</span><span class="punctuation">:</span> <span class="string">&quot;cosine&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--lr_warmup_steps&quot;</span><span class="punctuation">:</span> <span class="number">2400</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--caption_dropout_probability&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--metadata_update_interval&quot;</span><span class="punctuation">:</span> <span class="number">65</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--vae_batch_size&quot;</span><span class="punctuation">:</span> <span class="number">12</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--delete_unwanted_images&quot;</span><span class="punctuation">:</span> <span class="keyword">false</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--delete_problematic_images&quot;</span><span class="punctuation">:</span> <span class="keyword">false</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--training_scheduler_timestep_spacing&quot;</span><span class="punctuation">:</span> <span class="string">&quot;trailing&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--inference_scheduler_timestep_spacing&quot;</span><span class="punctuation">:</span> <span class="string">&quot;trailing&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--snr_gamma&quot;</span><span class="punctuation">:</span> <span class="number">5</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--enable_xformers_memory_efficient_attention&quot;</span><span class="punctuation">:</span> <span class="keyword">true</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--gradient_checkpointing&quot;</span><span class="punctuation">:</span> <span class="keyword">true</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--allow_tf32&quot;</span><span class="punctuation">:</span> <span class="keyword">true</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--optimizer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;adamw_bf16&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--use_ema&quot;</span><span class="punctuation">:</span> <span class="keyword">false</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--ema_decay&quot;</span><span class="punctuation">:</span> <span class="number">0.999</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--seed&quot;</span><span class="punctuation">:</span> <span class="number">42</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--mixed_precision&quot;</span><span class="punctuation">:</span> <span class="string">&quot;bf16&quot;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure></li><li><p>Custom SD3.5 Large <code>full</code> fine-tune<code>config.env</code></p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br></pre></td><td class="code"><pre><span class="line"> </span><br><span class="line"><span class="built_in">export</span> MODEL_TYPE=<span class="string">&#x27;full&#x27;</span></span><br><span class="line"><span class="built_in">export</span> MODEL_FAMILY=<span class="string">&#x27;sd3&#x27;</span></span><br><span class="line"><span class="built_in">export</span> CONTROLNET=<span class="literal">false</span></span><br><span class="line"><span class="built_in">export</span> USE_DORA=<span class="literal">false</span></span><br><span class="line"><span class="comment"># Restart where we left off. Change this to &quot;checkpoint-1234&quot; to start from a specific checkpoint.</span></span><br><span class="line"><span class="built_in">export</span> RESUME_CHECKPOINT=<span class="string">&quot;latest&quot;</span></span><br><span class="line"><span class="built_in">export</span> CHECKPOINTING_STEPS=100</span><br><span class="line"><span class="comment"># This is how many checkpoints we will keep. Two is safe, but three is safer.</span></span><br><span class="line"><span class="built_in">export</span> CHECKPOINTING_LIMIT=100</span><br><span class="line"></span><br><span class="line"><span class="comment"># This is decided as a relatively conservative &#x27;constant&#x27; learning rate.</span></span><br><span class="line"><span class="comment"># Adjust higher or lower depending on how burnt your model becomes.</span></span><br><span class="line"><span class="built_in">export</span> LEARNING_RATE=5e-5</span><br><span class="line"></span><br><span class="line"><span class="comment"># Using a Huggingface Hub model:</span></span><br><span class="line"><span class="built_in">export</span> MODEL_NAME=<span class="string">&quot;stabilityai/stable-diffusion-3.5-large&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Make DEBUG_EXTRA_ARGS empty to disable wandb.</span></span><br><span class="line"><span class="built_in">export</span> DEBUG_EXTRA_ARGS=<span class="string">&quot;--report_to=wandb&quot;</span></span><br><span class="line"><span class="built_in">export</span> TRACKER_PROJECT_NAME=<span class="string">&quot;sd35-training&quot;</span></span><br><span class="line"><span class="built_in">export</span> TRACKER_RUN_NAME=<span class="string">&quot;simpletuner-fantasy-art-full-01&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Max number of steps OR epochs can be used. Not both.</span></span><br><span class="line"><span class="built_in">export</span> MAX_NUM_STEPS=24000</span><br><span class="line"><span class="built_in">export</span> NUM_EPOCHS=0</span><br><span class="line"></span><br><span class="line"><span class="comment"># A convenient prefix for all of your training paths.</span></span><br><span class="line"><span class="built_in">export</span> DATALOADER_CONFIG=<span class="string">&quot;/weka2/home-yeo/simpletuner_models/sd3_large/full_finetune/fantasy_art_full_L_01/datasets/multidatabackend.json&quot;</span></span><br><span class="line"><span class="built_in">export</span> OUTPUT_DIR=<span class="string">&quot;/weka2/home-yeo/simpletuner_models/sd3_large/full_finetune/fantasy_art_full_L_01/datasets/models&quot;</span></span><br><span class="line"><span class="comment"># Set this to &quot;true&quot; to push your model to Hugging Face Hub.</span></span><br><span class="line"><span class="built_in">export</span> PUSH_TO_HUB=<span class="string">&quot;false&quot;</span></span><br><span class="line"><span class="comment"># If PUSH_TO_HUB and PUSH_CHECKPOINTS are both enabled, every saved checkpoint will be pushed to Hugging Face Hub.</span></span><br><span class="line"><span class="built_in">export</span> PUSH_CHECKPOINTS=<span class="string">&quot;true&quot;</span></span><br><span class="line"><span class="comment"># This will be the model name for your final hub upload, eg. &quot;yourusername/yourmodelname&quot;</span></span><br><span class="line"><span class="comment"># It defaults to the wandb project name, but you can override this here.</span></span><br><span class="line"><span class="comment"># export HUB_MODEL_NAME=$TRACKER_PROJECT_NAME</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># By default, images will be resized so their SMALLER EDGE is 1024 pixels, maintaining aspect ratio.</span></span><br><span class="line"><span class="comment"># Setting this value to 768px might result in more reasonable training data sizes for SDXL.</span></span><br><span class="line"><span class="built_in">export</span> RESOLUTION=1024</span><br><span class="line"><span class="comment"># If you want to have the training data resized by pixel area (Megapixels) rather than edge length,</span></span><br><span class="line"><span class="comment">#  set this value to &quot;area&quot; instead of &quot;pixel&quot;, and uncomment the next RESOLUTION declaration.</span></span><br><span class="line"><span class="built_in">export</span> RESOLUTION_TYPE=<span class="string">&quot;pixel&quot;</span></span><br><span class="line"><span class="comment">#export RESOLUTION=1          # 1.0 Megapixel training sizes</span></span><br><span class="line"><span class="comment"># If RESOLUTION_TYPE=&quot;pixel&quot;, the minimum resolution specifies the smaller edge length, measured in pixels. Recommended: 1024.</span></span><br><span class="line"><span class="comment"># If RESOLUTION_TYPE=&quot;area&quot;, the minimum resolution specifies the total image area, measured in megapixels. Recommended: 1.</span></span><br><span class="line"><span class="built_in">export</span> MINIMUM_RESOLUTION=1024</span><br><span class="line"></span><br><span class="line"><span class="comment"># How many decimals to round aspect buckets to.</span></span><br><span class="line"><span class="comment">#export ASPECT_BUCKET_ROUNDING=2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Use this to append an instance prompt to each caption, used for adding trigger words.</span></span><br><span class="line"><span class="comment"># This has not been tested in SDXL.</span></span><br><span class="line"><span class="built_in">export</span> INSTANCE_PROMPT=<span class="string">&quot;k4s4 &quot;</span></span><br><span class="line"><span class="comment"># If you also supply a user prompt library or `--use_prompt_library`, this will be added to those lists.</span></span><br><span class="line"><span class="built_in">export</span> VALIDATION_PROMPT=<span class="string">&quot;k4s4, a waist up view of a beautiful blonde woman, green eyes&quot;</span></span><br><span class="line"><span class="built_in">export</span> VALIDATION_GUIDANCE=7.5</span><br><span class="line"><span class="comment"># You&#x27;ll want to set this to 0.7 if you are training a terminal SNR model.</span></span><br><span class="line"><span class="built_in">export</span> VALIDATION_GUIDANCE_RESCALE=0.0</span><br><span class="line"><span class="comment"># How frequently we will save and run a pipeline for validations.</span></span><br><span class="line"><span class="comment"># export VALIDATION_STEPS=200</span></span><br><span class="line"><span class="built_in">export</span> VALIDATION_STEPS=25</span><br><span class="line"><span class="built_in">export</span> VALIDATION_NUM_INFERENCE_STEPS=30</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> VALIDATION_NEGATIVE_PROMPT=<span class="string">&quot;blurry, cropped, ugly&quot;</span></span><br><span class="line"><span class="built_in">export</span> VALIDATION_SEED=42</span><br><span class="line"><span class="built_in">export</span> VALIDATION_RESOLUTION=1024</span><br><span class="line"></span><br><span class="line"><span class="comment"># Adjust this for your GPU memory size. This, and resolution, are the biggest VRAM killers.</span></span><br><span class="line"><span class="built_in">export</span> TRAIN_BATCH_SIZE=6</span><br><span class="line"><span class="comment"># Accumulate your update gradient over many steps, to save VRAM while still having higher effective batch size:</span></span><br><span class="line"><span class="comment"># effective batch size = ($TRAIN_BATCH_SIZE * $GRADIENT_ACCUMULATION_STEPS).</span></span><br><span class="line"><span class="built_in">export</span> GRADIENT_ACCUMULATION_STEPS=1</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use any standard scheduler type. constant, polynomial, constant_with_warmup</span></span><br><span class="line"><span class="built_in">export</span> LR_SCHEDULE=<span class="string">&quot;cosine&quot;</span></span><br><span class="line"><span class="comment"># A warmup period allows the model and the EMA weights more importantly to familiarise itself with the current quanta.</span></span><br><span class="line"><span class="comment"># For the cosine or sine type schedules, the warmup period defines the interval between peaks or valleys.</span></span><br><span class="line"><span class="comment"># Use a sine schedule to simulate a warmup period, or a Cosine period to simulate a polynomial start.</span></span><br><span class="line"><span class="comment"># export LR_WARMUP_STEPS=$((MAX_NUM_STEPS / 10))</span></span><br><span class="line"><span class="built_in">export</span> LR_WARMUP_STEPS=2400</span><br><span class="line"></span><br><span class="line"><span class="comment"># Caption dropout probability. Set to 0.1 for 10% of captions dropped out. Set to 0 to disable.</span></span><br><span class="line"><span class="comment"># You may wish to disable dropout if you want to limit your changes strictly to the prompts you show the model.</span></span><br><span class="line"><span class="comment"># You may wish to increase the rate of dropout if you want to more broadly adopt your changes across the model.</span></span><br><span class="line"><span class="built_in">export</span> CAPTION_DROPOUT_PROBABILITY=0</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> METADATA_UPDATE_INTERVAL=65</span><br><span class="line"><span class="built_in">export</span> VAE_BATCH_SIZE=12</span><br><span class="line"></span><br><span class="line"><span class="comment"># If this is set, any images that fail to open will be DELETED to avoid re-checking them every time.</span></span><br><span class="line"><span class="built_in">export</span> DELETE_ERRORED_IMAGES=0</span><br><span class="line"><span class="comment"># If this is set, any images that are too small for the minimum resolution size will be DELETED.</span></span><br><span class="line"><span class="built_in">export</span> DELETE_SMALL_IMAGES=0</span><br><span class="line"></span><br><span class="line"><span class="comment"># Bytedance recommends these be set to &quot;trailing&quot; so that inference and training behave in a more congruent manner.</span></span><br><span class="line"><span class="comment"># To follow the original SDXL training strategy, use &quot;leading&quot; instead, though results are generally worse.</span></span><br><span class="line"><span class="built_in">export</span> TRAINING_SCHEDULER_TIMESTEP_SPACING=<span class="string">&quot;trailing&quot;</span></span><br><span class="line"><span class="built_in">export</span> INFERENCE_SCHEDULER_TIMESTEP_SPACING=<span class="string">&quot;trailing&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Removing this option or unsetting it uses vanilla training. Setting it reweights the loss by the position of the timestep in the noise schedule.</span></span><br><span class="line"><span class="comment"># A value &quot;5&quot; is recommended by the researchers. A value of &quot;20&quot; is the least impact, and &quot;1&quot; is the most impact.</span></span><br><span class="line"><span class="built_in">export</span> MIN_SNR_GAMMA=5</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set this to an explicit value of &quot;false&quot; to disable Xformers. Probably required for AMD users.</span></span><br><span class="line"><span class="built_in">export</span> USE_XFORMERS=<span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># There&#x27;s basically no reason to unset this. However, to disable it, use an explicit value of &quot;false&quot;.</span></span><br><span class="line"><span class="comment"># This will save a lot of memory consumption when enabled.</span></span><br><span class="line"><span class="built_in">export</span> USE_GRADIENT_CHECKPOINTING=<span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment">##</span></span><br><span class="line"><span class="comment"># Options below here may require a bit more complicated configuration, so they are not simple variables.</span></span><br><span class="line"><span class="comment">##</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># TF32 is great on Ampere or Ada, not sure about earlier generations.</span></span><br><span class="line"><span class="built_in">export</span> ALLOW_TF32=<span class="literal">true</span></span><br><span class="line"><span class="comment"># AdamW 8Bit is a robust and lightweight choice. Adafactor might reduce memory consumption, and Dadaptation is slow and experimental.</span></span><br><span class="line"><span class="comment"># AdamW is the default optimizer, but it uses a lot of memory and is slower than AdamW8Bit or Adafactor.</span></span><br><span class="line"><span class="comment"># Choices: adamw, adamw8bit, adafactor, dadaptation</span></span><br><span class="line"><span class="comment"># export OPTIMIZER=&quot;adamw_bf16&quot;</span></span><br><span class="line"><span class="built_in">export</span> OPTIMIZER=<span class="string">&quot;adamw_bf16&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># EMA is a strong regularisation method that uses a lot of extra VRAM to hold two copies of the weights.</span></span><br><span class="line"><span class="comment"># This is worthwhile on large training runs, but not so much for smaller training runs.</span></span><br><span class="line"><span class="built_in">export</span> USE_EMA=<span class="literal">false</span></span><br><span class="line"><span class="built_in">export</span> EMA_DECAY=0.999</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> TRAINER_EXTRA_ARGS=<span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Reproducible training. Set to -1 to disable.</span></span><br><span class="line"><span class="built_in">export</span> TRAINING_SEED=42</span><br><span class="line"></span><br><span class="line"><span class="comment"># Mixed precision is the best. You honestly might need to YOLO it in fp16 mode for Google Colab type setups.</span></span><br><span class="line"><span class="built_in">export</span> MIXED_PRECISION=<span class="string">&quot;bf16&quot;</span></span><br><span class="line"><span class="built_in">export</span> PURE_BF16=<span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># This has to be changed if you&#x27;re training with multiple GPUs.</span></span><br><span class="line"><span class="built_in">export</span> TRAINING_NUM_PROCESSES=1</span><br><span class="line"><span class="built_in">export</span> TRAINING_NUM_MACHINES=1</span><br><span class="line"><span class="built_in">export</span> ACCELERATE_EXTRA_ARGS=<span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># With Pytorch 2.1, you might have pretty good luck here.</span></span><br><span class="line"><span class="comment"># If you&#x27;re using aspect bucketing however, each resolution change will recompile. Seriously, just don&#x27;t do it.</span></span><br><span class="line"><span class="comment"># Well, then again... Pytorch 2.2 has support for dynamic shapes. Why not?</span></span><br><span class="line"><span class="built_in">export</span> TRAINING_DYNAMO_BACKEND=<span class="string">&#x27;no&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> TOKENIZERS_PARALLELISM=<span class="literal">false</span></span><br></pre></td></tr></table></figure></li></ul><p>Changed parameters</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line"><span class="attr">&quot;--model_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;full&quot;</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;--checkpointing_steps&quot;</span><span class="punctuation">:</span> <span class="number">100</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--checkpoints_total_limit&quot;</span><span class="punctuation">:</span> <span class="number">100</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--learning_rate&quot;</span><span class="punctuation">:</span> <span class="number">5e-5</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;--tracker_run_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;simpletuner-fantasy-art-full-01&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>특히 학습률이 ‘5e-5’로 감소했습니다.</p><p>모든 것이 정상이면 계속해서 훈련을 시작하십시오.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash train.sh</span><br></pre></td></tr></table></figure><h3 id="Memory-usage"><a href="#Memory-usage" class="headerlink" title="Memory usage"></a>Memory usage</h3><p>텍스트 인코더를 훈련하지 않는 경우(우리는 그렇지 않습니다) ‘SimpleTuner’를 사용하면 약 ‘10.4GB’의 VRAM을 절약할 수 있습니다.</p><p>‘배치 크기’를 ‘6’으로 설정하고 ‘lora 순위&#x2F;알파’를 ‘768’로 설정하면 훈련에서 약 ‘32GB’의 VRAM을 소비합니다.</p><p>당연히 이는 소비자 ‘24GB’ VRAM GPU의 범위를 벗어납니다. 그래서 <code>batch size</code>를 <code>1</code>, <code>lora Rank/alpha</code>를 <code>128</code>로 사용하여 메모리 비용을 줄이려고 했습니다.</p><p>잠정적으로 VRAM 비용을 약 ‘19.65GB’ VRAM으로 낮출 수 있었습니다.</p><p>그러나 유효성 검사 프롬프트에 대한 추론을 실행하면 VRAM이 최대 ‘23.37GB’까지 급증합니다.</p><p>안전을 위해 ‘lora 순위&#x2F;알파’를 ‘64’로 더욱 줄여야 할 수도 있습니다. 그렇다면 훈련 중에 약 ‘18.83GB’의 VRAM을 소비하게 됩니다.</p><p>검증 추론 중에는 최대 약 ‘21.50GB’의 VRAM이 사용됩니다. 이 정도면 충분히 안전해 보입니다.</p><p>‘배치 크기’ ‘6’ 및 ‘lora 순위&#x2F;알파’ ‘768’의 더 높은 사양 교육을 사용하기로 결정한 경우 [위](https:&#x2F;&#x2F; <a href="http://www.notion.so/Stable-Diffusion-3-5-Large-Fine-tuning-Tutorial-11a61cdcd1968027a15bdbd7c40be8c6?pvs=21">www.notion.so/Stable-Diffusion-3-5-Large-Fine-tuning-Tutorial-11a61cdcd1968027a15bdbd7c40be8c6?pvs=21</a>) GPU VRAM이 부족하고 CPU RAM이 충분한 경우.</p><h3 id="Monitoring-the-training"><a href="#Monitoring-the-training" class="headerlink" title="Monitoring the training"></a>Monitoring the training</h3><p>훈련 과정에서 검증 이미지가 픽셀화되거나 검게 변하는 경우가 있을 수 있습니다. 이는 ‘1.05e-3’이라는 매우 공격적인 학습률을 사용하고 있기 때문입니다. 더 안전하게 플레이하고 싶다면 ‘9.5e-4’를 사용하면 픽셀화 문제가 거의 발생하지 않습니다. 그럼에도 불구하고 두 손실 곡선은 결국 훌륭하게 수렴했습니다.</p><p>하지만 우려사항을 해소하기 위해 어떤 모습일지 몇 가지 예를 보여드리고 싶습니다.</p><h3 id="Observing-training-loss"><a href="#Observing-training-loss" class="headerlink" title="Observing training loss"></a>Observing training loss</h3><h3 id="LoRA"><a href="#LoRA" class="headerlink" title="LoRA"></a><code>LoRA</code></h3><p>판타지 아트 ‘LoRA’ 수련을 통해 얻은 피규어들입니다. 손실이 감소하고 있으며 아직 수렴되지 않았습니다. 그러나 확산 모델을 미세 조정한 경험이 있는 경우 손실 최소화는 미적 극대화와 거의 관련이 없습니다. 또한 높은 학습률을 사용하는 경우 손실 곡선의 최고점 근처에서 검증 이미지의 픽셀화 또는 품질 저하가 발생할 수 있음을 확인했습니다. 훈련이 모델 가중치가 만족스럽지 않은 학습 속도에 도달하면 이는 의미가 있습니다.</p><p>학습률이 높으면 열차 손실도 최고점에 달합니다.</p><h2 id="Evaluating-the-results"><a href="#Evaluating-the-results" class="headerlink" title="Evaluating the results"></a>Evaluating the results</h2><h3 id="How-to-actually-get-the-LoRA-models-into-ComfyUI"><a href="#How-to-actually-get-the-LoRA-models-into-ComfyUI" class="headerlink" title="How to actually get the LoRA models into ComfyUI"></a>How to actually get the LoRA models into ComfyUI</h3><p>이제 모델이 모두 훈련되었으므로 <code>ComfyUI</code>를 사용하여 테스트할 차례입니다. 그러나 SimpleTuner가 모델을 저장하는 방식으로 인해 ‘ComfyUI&#x2F;models&#x2F;loras’ 디렉터리로 가져오기가 약간 어렵습니다.</p><p>모델을 저장한 디렉터리로 이동하면 해당 형식이 이 형식인 것을 볼 수 있습니다.</p><p>각 디렉토리에서 원하는 파일은 <code>pytorch_lora_weights.safetensors</code> 파일입니다. 이러한 파일을 <code>ComfyUI</code>로 가져오는 프로세스를 간소화하기 위해 다음 스크립트를 작성했습니다.</p><ul><li><p><code>create_symlinks_lora.sh</code></p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Source directory where the models are stored</span></span><br><span class="line">SOURCE_DIR=<span class="string">&quot;/weka2/home-yeo/simpletuner_models/sd3_large/full_finetune/fantasy_art_L_01/datasets/models&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Target directory for symlinks</span></span><br><span class="line">TARGET_DIR=<span class="string">&quot;/weka2/home-yeo/ComfyUI/models/loras/sd35_large/fantasy_art&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Ensure target directory exists or create it</span></span><br><span class="line"><span class="built_in">mkdir</span> -p <span class="string">&quot;<span class="variable">$&#123;TARGET_DIR&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Iterate over each checkpoint directory</span></span><br><span class="line"><span class="keyword">for</span> CHECKPOINT_DIR <span class="keyword">in</span> <span class="variable">$&#123;SOURCE_DIR&#125;</span>/checkpoint-*; <span class="keyword">do</span></span><br><span class="line">    <span class="comment"># Check if it&#x27;s indeed a directory</span></span><br><span class="line">    <span class="keyword">if</span> [ -d <span class="string">&quot;<span class="variable">$&#123;CHECKPOINT_DIR&#125;</span>&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">        <span class="comment"># Extract the checkpoint number from the directory name</span></span><br><span class="line">        CHECKPOINT_NAME=$(<span class="built_in">basename</span> <span class="variable">$&#123;CHECKPOINT_DIR&#125;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Define the source file path</span></span><br><span class="line">        SOURCE_FILE=<span class="string">&quot;<span class="variable">$&#123;CHECKPOINT_DIR&#125;</span>/pytorch_lora_weights.safetensors&quot;</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Define the symlink name with &#x27;lora&#x27; added before &#x27;safetensors&#x27;</span></span><br><span class="line">        LINK_NAME=<span class="string">&quot;<span class="variable">$&#123;TARGET_DIR&#125;</span>/<span class="variable">$&#123;CHECKPOINT_NAME&#125;</span>_lora.safetensors&quot;</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Check if the source file exists</span></span><br><span class="line">        <span class="keyword">if</span> [ -f <span class="string">&quot;<span class="variable">$&#123;SOURCE_FILE&#125;</span>&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">            <span class="comment"># Create a symlink in the target directory</span></span><br><span class="line">            <span class="built_in">echo</span> <span class="string">&quot;Creating symlink from <span class="variable">$&#123;SOURCE_FILE&#125;</span> to <span class="variable">$&#123;LINK_NAME&#125;</span>&quot;</span></span><br><span class="line">            <span class="built_in">ln</span> -s <span class="string">&quot;<span class="variable">$&#123;SOURCE_FILE&#125;</span>&quot;</span> <span class="string">&quot;<span class="variable">$&#123;LINK_NAME&#125;</span>&quot;</span></span><br><span class="line">            <span class="built_in">echo</span> <span class="string">&quot;Symlink created for <span class="variable">$&#123;CHECKPOINT_NAME&#125;</span>&quot;</span></span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="built_in">echo</span> <span class="string">&quot;File not found: <span class="variable">$&#123;SOURCE_FILE&#125;</span>&quot;</span></span><br><span class="line">        <span class="keyword">fi</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;Not a directory: <span class="variable">$&#123;CHECKPOINT_DIR&#125;</span>&quot;</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Symlinking complete.&quot;</span></span><br></pre></td></tr></table></figure></li></ul><p>위의 쉘 스크립트가 수행할 작업은 <code>SimpleTuner</code>에서 <code>SOURCE_DIR</code>을 반복한 다음 <em><strong>만</strong></em> <code>pytorch_lora_weights.safetensors</code> 파일을 <code>TARGET_DIR</code>에 심볼릭 링크하는 것입니다. 이 파일은 <code>ComfyUI 내부 디렉토리여야 합니다. /모델/로라스</code>. 파일을 추적하기 위해 파일 이름 안에 해당 체크포인트 번호가 포함되도록 이름도 변경했습니다.</p><h3 id="Determining-the-best-checkpoint"><a href="#Determining-the-best-checkpoint" class="headerlink" title="Determining the best checkpoint"></a>Determining the best checkpoint</h3><p>제가 사용하고 있는 기본적인 ‘SD3.5 Large’ 워크플로는 이것이었습니다.</p><p>가장 좋은 체크포인트를 결정하는 방법은 특정 프롬프트에 대해 x축에 체크포인트 번호를 표시하는 것입니다. 그래서 저는 다음과 같은 단일 스트립을 얻습니다.</p><p>판타지 아트 ‘LoRA’</p><p>Prompt</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a three fourth perspective waist up portrait view of a young woman with messy long blonde hair and light purple eyes, looking at viewer with a closed mouth smile, wearing tight black dress, a faded pink simple background during golden hour</span><br></pre></td></tr></table></figure><p>이를 위해 <code>ComfyUI</code> 워크플로의 <code>api</code> 버전에 로드되는 사용자 정의 스크립트를 사용합니다. 저장(API 형식) 버튼을 클릭하면 모든 워크플로우를 ‘API’ 형식으로 저장할 수 있습니다. 귀하가 사용할 수 있도록 이미 위 버전을 저장했습니다. ‘ComfyUI’ API 사용에 대한 더 심층적인 비디오 가이드를 원하시면 제가 작년에 <a href="https://youtu.be/WwsJ_QIgsG8">여기</a>를 만들었습니다.</p><p><code>ComfyUI</code>가 실행 중인지 확인한 후 아래 스크립트를 실행하세요. 또한 스크립트를 실행하는 동일한 위치에 <code>.env</code> 파일을 설정해야 합니다.</p><ul><li><p><code>API script</code></p><p>This is my custom <code>python</code> script:</p>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">import json</span><br><span class="line">import random</span><br><span class="line">from urllib import request</span><br><span class="line">import datetime</span><br><span class="line">from PIL import Image, ImageDraw, ImageFont</span><br><span class="line">import time</span><br><span class="line">import re</span><br><span class="line">import urllib.error</span><br><span class="line"></span><br><span class="line">from dotenv import load_dotenv</span><br><span class="line">load_dotenv()</span><br><span class="line"></span><br><span class="line"># Configuration</span><br><span class="line">api_workflow_dir = os.getenv(&quot;API_WORKFLOW_DIR&quot;)</span><br><span class="line">lora_dir = os.getenv(&quot;LORA_DIR&quot;)</span><br><span class="line"></span><br><span class="line">api_workflow_file = os.getenv(&quot;API_WORKFLOW_FILE&quot;)</span><br><span class="line">api_endpoint = os.getenv(&quot;API_ENDPOINT&quot;)</span><br><span class="line">image_output_dir = os.getenv(&quot;IMAGE_OUTPUT_DIR&quot;)</span><br><span class="line">font_ttf_path = os.getenv(&quot;FONT_TTF_PATH&quot;)</span><br><span class="line"></span><br><span class="line">comfyui_output_dir = os.getenv(&quot;COMFYUI_OUTPUT_DIR&quot;)</span><br><span class="line"></span><br><span class="line">api_endpoint = f&quot;http://&#123;api_endpoint&#125;/prompt&quot;</span><br><span class="line"></span><br><span class="line">workflow_file_path = os.path.join(api_workflow_dir, api_workflow_file)</span><br><span class="line">workflow = json.load(open(workflow_file_path))</span><br><span class="line"></span><br><span class="line">current_datetime = datetime.datetime.now().strftime(&quot;%Y-%m-%d_%H-%M-%S&quot;)</span><br><span class="line">relative_output_path = current_datetime</span><br><span class="line"></span><br><span class="line">directory_creation_timeout = 3000  # Timeout for directory creation in seconds</span><br><span class="line">image_generation_timeout = 30000  # Timeout for image generation in seconds</span><br><span class="line"></span><br><span class="line">def get_checkpoint_number(filename):</span><br><span class="line">    match = re.search(r&#x27;checkpoint-(\d+)&#x27;, filename)</span><br><span class="line">    if match:</span><br><span class="line">        return int(match.group(1))</span><br><span class="line">    match = re.search(r&#x27;/checkpoint-(\d+)/&#x27;, filename)</span><br><span class="line">    if match:</span><br><span class="line">        return int(match.group(1))</span><br><span class="line">    return None</span><br><span class="line"></span><br><span class="line">def get_most_recent_output_folder(base_dir):</span><br><span class="line">    folders = [f for f in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, f))]</span><br><span class="line">    if not folders:</span><br><span class="line">        return None</span><br><span class="line">    return max(folders, key=lambda f: os.path.getctime(os.path.join(base_dir, f)))</span><br><span class="line"></span><br><span class="line">def process_loras(lora_dir, workflow):</span><br><span class="line">    print(f&quot;Scanning directory: &#123;lora_dir&#125;&quot;)</span><br><span class="line">    </span><br><span class="line">    # Extract the last two directories from LORA_DIR</span><br><span class="line">    lora_path_parts = lora_dir.split(&#x27;/&#x27;)</span><br><span class="line">    dynamic_lora_path = &#x27;/&#x27;.join(lora_path_parts[-2:])</span><br><span class="line">    </span><br><span class="line">    all_items = os.listdir(lora_dir)</span><br><span class="line">    </span><br><span class="line">    lora_items = [f for f in all_items if f.endswith(&#x27;_lora.safetensors&#x27;)]</span><br><span class="line">    </span><br><span class="line">    lora_items.sort(key=lambda x: int(x.split(&#x27;-&#x27;)[1].split(&#x27;_&#x27;)[0]))</span><br><span class="line">    </span><br><span class="line">    print(f&quot;Found items: &#123;lora_items&#125;&quot;)</span><br><span class="line">    </span><br><span class="line">    for item in lora_items:</span><br><span class="line">        checkpoint_num = item.split(&#x27;-&#x27;)[1].split(&#x27;_&#x27;)[0]</span><br><span class="line">        </span><br><span class="line">        print(f&quot;Processing: &#123;item&#125;&quot;)</span><br><span class="line"></span><br><span class="line">        # Update the LoRA loader node</span><br><span class="line">        lora_loader_node = workflow[&quot;276&quot;]</span><br><span class="line">        lora_loader_node[&quot;inputs&quot;][&quot;lora_name&quot;] = f&quot;&#123;dynamic_lora_path&#125;/&#123;item&#125;&quot;</span><br><span class="line"></span><br><span class="line">        save_image = workflow[&quot;314&quot;]</span><br><span class="line">        filename_prefix = f&quot;checkpoint-&#123;checkpoint_num&#125;&quot;</span><br><span class="line">        save_image[&quot;inputs&quot;][&quot;output_path&quot;] = relative_output_path</span><br><span class="line">        save_image[&quot;inputs&quot;][&quot;filename_prefix&quot;] = filename_prefix</span><br><span class="line"></span><br><span class="line">        success = queue_prompt(workflow)</span><br><span class="line">        if not success:</span><br><span class="line">            print(f&quot;Failed to queue prompt for checkpoint &#123;checkpoint_num&#125;&quot;)</span><br><span class="line">        else:</span><br><span class="line">            print(f&quot;Successfully queued prompt for checkpoint &#123;checkpoint_num&#125;&quot;)</span><br><span class="line"></span><br><span class="line">    if not lora_items:</span><br><span class="line">        print(&quot;No LoRA files found in the directory.&quot;)</span><br><span class="line">    </span><br><span class="line">    return len(lora_items)</span><br><span class="line"></span><br><span class="line">def create_image_strip(lora_dir, image_folder, output_filename):</span><br><span class="line">    lora_files = [f for f in os.listdir(lora_dir) if f.endswith(&#x27;_lora.safetensors&#x27;)]</span><br><span class="line">    lora_files.sort(key=get_checkpoint_number)</span><br><span class="line">    checkpoints = [get_checkpoint_number(f) for f in lora_files if get_checkpoint_number(f) is not None]</span><br><span class="line"></span><br><span class="line">    images = []</span><br><span class="line">    for checkpoint in checkpoints:</span><br><span class="line">        filename = f&quot;checkpoint-&#123;checkpoint&#125;_0001.png&quot;</span><br><span class="line">        filepath = os.path.join(image_folder, filename)</span><br><span class="line">        if os.path.exists(filepath):</span><br><span class="line">            try:</span><br><span class="line">                img = Image.open(filepath)</span><br><span class="line">                images.append(img)</span><br><span class="line">            except IOError as e:</span><br><span class="line">                print(f&quot;Cannot open image: &#123;filepath&#125;&quot;)</span><br><span class="line">                print(f&quot;Error: &#123;e&#125;&quot;)</span><br><span class="line"></span><br><span class="line">    if not images:</span><br><span class="line">        print(&quot;No valid images found.&quot;)</span><br><span class="line">        return</span><br><span class="line"></span><br><span class="line">    img_width, img_height = images[0].size</span><br><span class="line">    strip_width = img_width * len(images)</span><br><span class="line">    label_height = 50  # Space for labels</span><br><span class="line">    strip_height = img_height + label_height</span><br><span class="line"></span><br><span class="line">    strip_image = Image.new(&#x27;RGB&#x27;, (strip_width, strip_height), &#x27;white&#x27;)</span><br><span class="line">    draw = ImageDraw.Draw(strip_image)</span><br><span class="line">    font = ImageFont.truetype(font_ttf_path, 20)</span><br><span class="line"></span><br><span class="line">    for i, (img, checkpoint) in enumerate(zip(images, checkpoints)):</span><br><span class="line">        strip_image.paste(img, (i * img_width, label_height))</span><br><span class="line">        </span><br><span class="line">        label = f&quot;checkpoint-&#123;checkpoint&#125;&quot;</span><br><span class="line">        label_width = draw.textlength(label, font=font)</span><br><span class="line">        label_x = i * img_width + (img_width - label_width) // 2</span><br><span class="line">        draw.text((label_x, 10), label, fill=&quot;black&quot;, font=font)</span><br><span class="line"></span><br><span class="line">    strip_image.save(output_filename)</span><br><span class="line">    print(f&quot;Image strip saved to: &#123;output_filename&#125;&quot;)</span><br><span class="line"></span><br><span class="line">def queue_prompt(workflow):</span><br><span class="line">    p = &#123;&quot;prompt&quot;: workflow&#125;</span><br><span class="line">    data = json.dumps(p).encode(&#x27;utf-8&#x27;)</span><br><span class="line">    req = request.Request(api_endpoint, data=data, headers=&#123;&#x27;Content-Type&#x27;: &#x27;application/json&#x27;&#125;)</span><br><span class="line">    try:</span><br><span class="line">        with request.urlopen(req) as response:</span><br><span class="line">            print(f&quot;API request successful. Status code: &#123;response.getcode()&#125;&quot;)</span><br><span class="line">            return True</span><br><span class="line">    except urllib.error.URLError as e:</span><br><span class="line">        if hasattr(e, &#x27;reason&#x27;):</span><br><span class="line">            print(f&quot;Failed to reach the server. Reason: &#123;e.reason&#125;&quot;)</span><br><span class="line">        elif hasattr(e, &#x27;code&#x27;):</span><br><span class="line">            print(f&quot;The server couldn&#x27;t fulfill the request. Error code: &#123;e.code&#125;&quot;)</span><br><span class="line">        print(f&quot;API endpoint: &#123;api_endpoint&#125;&quot;)</span><br><span class="line">    except Exception as e:</span><br><span class="line">        print(f&quot;An error occurred: &#123;str(e)&#125;&quot;)</span><br><span class="line">    return False</span><br><span class="line"></span><br><span class="line">def wait_for_directory_creation(directory, timeout):</span><br><span class="line">    print(f&quot;Waiting for directory &#123;directory&#125; to be created...&quot;)</span><br><span class="line">    start_time = time.time()</span><br><span class="line">    while time.time() - start_time &lt; timeout:</span><br><span class="line">        if os.path.exists(directory):</span><br><span class="line">            print(f&quot;Directory &#123;directory&#125; found.&quot;)</span><br><span class="line">            return True</span><br><span class="line">        time.sleep(5)  # Check every 5 seconds</span><br><span class="line">    print(f&quot;Timeout waiting for directory &#123;directory&#125; to be created.&quot;)</span><br><span class="line">    return False</span><br><span class="line"></span><br><span class="line">def wait_for_images(image_folder, expected_count, timeout):</span><br><span class="line">    print(&quot;Waiting for images to be generated...&quot;)</span><br><span class="line">    start_time = time.time()</span><br><span class="line">    while time.time() - start_time &lt; timeout:</span><br><span class="line">        if os.path.exists(image_folder):</span><br><span class="line">            image_files = [f for f in os.listdir(image_folder) if f.endswith(&#x27;.png&#x27;)]</span><br><span class="line">            if len(image_files) &gt;= expected_count:</span><br><span class="line">                print(f&quot;Found all &#123;expected_count&#125; images.&quot;)</span><br><span class="line">                return True</span><br><span class="line">        time.sleep(5)  # Check every 5 seconds</span><br><span class="line">    print(&quot;Timeout waiting for images to be generated.&quot;)</span><br><span class="line">    return False</span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    print(f&quot;LoRA directory: &#123;lora_dir&#125;&quot;)</span><br><span class="line"></span><br><span class="line">    # Generate images</span><br><span class="line">    expected_image_count = process_loras(lora_dir, workflow)</span><br><span class="line"></span><br><span class="line">    absolute_output_path = os.path.join(comfyui_output_dir, current_datetime)</span><br><span class="line">    print(f&quot;Absolute output path: &#123;absolute_output_path&#125;&quot;)</span><br><span class="line"></span><br><span class="line">    # Create the image strip</span><br><span class="line">    if wait_for_directory_creation(absolute_output_path, directory_creation_timeout):</span><br><span class="line">        print(f&quot;Expected image count: &#123;expected_image_count&#125;&quot;)</span><br><span class="line">        if wait_for_images(absolute_output_path, expected_image_count, image_generation_timeout):</span><br><span class="line">            output_strip_filename = os.path.join(absolute_output_path, &quot;output_image_strip.png&quot;)</span><br><span class="line">            create_image_strip(lora_dir, absolute_output_path, output_strip_filename)</span><br><span class="line">        else:</span><br><span class="line">            print(&quot;Failed to generate all images in time.&quot;)</span><br><span class="line">    else:</span><br><span class="line">        print(&quot;Output directory was not created.&quot;)</span><br></pre></td></tr></table></figure></li><li><p>sample <code>.env</code> file</p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">API_WORKFLOW_DIR=/weka2/home-yeo/workflows</span><br><span class="line">COMFYUI_OUTPUT_DIR = /weka2/home-yeo/ComfyUI/output/</span><br><span class="line">LORA_DIR=/admin/home-yeo/workspace/ComfyUI/models/loras/sd35_large/fantasy_art_01</span><br><span class="line">API_WORKFLOW_FILE=sd35_fantasy_art_02_api.json</span><br><span class="line">API_ENDPOINT=127.0.0.1:8188</span><br><span class="line">FONT_TTF_PATH=/weka2/home-yeo/fonts/arial.ttf</span><br><span class="line">BOLD_FONT_TTF_PATH=/weka2/home-yeo/fonts/arialbd.ttf</span><br></pre></td></tr></table></figure></li></ul><p>Fantasy Art <code>LoRA</code></p><p>Prompt</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a three fourth perspective waist up portrait view of a young woman with messy long blonde hair and light purple eyes, looking at viewer with a closed mouth smile, wearing tight black dress, a faded pink simple background during golden hour</span><br></pre></td></tr></table></figure><p>결국 ‘24,000’ 단계에서 거의 마지막에 체크포인트를 선택하게 되었습니다.</p><p>나는 또한 건전성 확인을 위해 수행한 다른 모든 훈련에 대해 동일한 실험을 실행했습니다.</p><p>Cinema Photo <code>LoRA</code></p><p>Prompt</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a few hooded figures walking on an empty road in the rain, desolate, high skyscrapers</span><br></pre></td></tr></table></figure><p>John Singer Sargent <code>LoRA</code></p><p>Prompt</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">an abandoned beach with a lighthouse</span><br></pre></td></tr></table></figure><p>Underexposed Photography <code>LoRA</code></p><p>Prompt</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">waist up view of a woman posing on a runway, streetwear in the style of alexander mcqueen</span><br></pre></td></tr></table></figure><p>전문적인 이유로 원래 그리드의 특정 부분이 생략되었습니다. 전체 그리드에는 모든 청중에게 적합하지 않을 수 있는 콘텐츠가 포함되어 있으므로 기술적인 측면에 초점을 맞추기 위해 잘린 버전이 표시됩니다.</p><p>Pixel Art <code>LoRA</code></p><p>Prompt</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a plush chibi mythical creature</span><br></pre></td></tr></table></figure><p>Ethnic Paint <code>LoRA</code></p><p>Prompt</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a skyline view of a futuristic maritime village floating above ground, <span class="keyword">in</span> the clouds, towering skyscrapers, golden hour, day time lighting</span><br></pre></td></tr></table></figure><h2 id="A-x2F-B-evaluation"><a href="#A-x2F-B-evaluation" class="headerlink" title="A&#x2F;B evaluation"></a>A&#x2F;B evaluation</h2><h3 id="Improving-x2F-tuning-generations-with-APG-scaling"><a href="#Improving-x2F-tuning-generations-with-APG-scaling" class="headerlink" title="Improving&#x2F;tuning generations with APG scaling"></a>Improving&#x2F;tuning generations with APG scaling</h3><p>최고의 미적 결과를 제공하는 ‘LoRA’ 체크포인트를 찾았으면 ‘APG’ 스케일링을 통해 이를 더욱 향상시킬 수 있습니다. ‘APG’ 스케일링은 적응형 예측 지침을 의미합니다.</p><p><a href="https://arxiv.org/abs/2410.02416">APG 논문</a> 초록의 핵심 부분</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Our approach, termed adaptive projected guidance (APG), retains the quality-boosting advantages of CFG while enabling the use of higher guidance scales without oversaturation. APG is easy to implement and introduces practically no additional computational overhead to the sampling process.</span><br></pre></td></tr></table></figure><p>이것이 이 샘플 워크플로에 포함된 <a href="https://github.com/logtd/ComfyUI-APGScaling">ComfyUI 노드</a>입니다. 세 가지 다른 이미지를 생성합니다. 하나는 기본 이미지, 하나는 ***<code>APG</code> 스케일링 없이 ***<code>LoRA</code> 적용, 세 번째 이미지는 ***<code>사용***</code> LoRA<code> 적용 APG</code> 스케일링.</p><p>The parameters for APG are:</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">eta</span><br><span class="line">norm<span class="emphasis">_threshold</span></span><br><span class="line"><span class="emphasis">use_</span>momentum</span><br><span class="line">momentum</span><br></pre></td></tr></table></figure><p>이 노드에 대해 그렇게 많이 심층 분석하지는 않았지만 이미지 품질이 좋든 나쁘든 변경됩니다.</p><h3 id="Before-and-after-comparison"><a href="#Before-and-after-comparison" class="headerlink" title="Before and after comparison"></a>Before and after comparison</h3><p>Fantasy Art</p><p>Prompt</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a three fourth perspective waist up portrait view of a young woman with messy long blonde hair and light purple eyes, perfect face, looking at viewer with a closed mouth smile, wearing loose black dress, a faded pink simple background during golden hour</span><br></pre></td></tr></table></figure><p><code>Base model</code></p><p><code>LoRA</code></p><p><code>LoRA</code> + <code>APG</code></p><p>Cinema Photo</p><p>Prompt</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a wide view of a figure looking up at a meteor breaking apart</span><br></pre></td></tr></table></figure><p><code>Base model</code></p><p><code>LoRA</code></p><p><code>LoRA</code> + <code>APG</code></p><p>John Singer Sargent</p><p>Prompt</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">an abandoned beach with a lighthouse</span><br></pre></td></tr></table></figure><p><code>Base model</code></p><p><code>LoRA</code></p><p><code>LoRA</code> + <code>APG</code></p><p>Underexposed Photography</p><p>Prompt</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">waist up view of a woman posing on a runway, streetwear in the style of alexander mcqueen</span><br></pre></td></tr></table></figure><p><code>Base model</code></p><p><code>LoRA</code></p><p><code>LoRA</code> + <code>APG</code></p><p>Pixel Art</p><p>Prompt</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a sci-fi venetian town near the water</span><br></pre></td></tr></table></figure><p><code>Base model</code></p><p><code>LoRA</code></p><p><code>LoRA</code> + <code>APG</code></p><p>Ethnic Paint</p><p>Prompt</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a man in his late 30s to early 40s, rendered in a dark, moody style, The subject is depicted from the shoulders up, facing the viewer directly, He has a full, thick beard and mustache, which is dark and well-groomed, with a few strands of gray, His hair is short and neatly combed, with a few strands falling over his forehead, His eyes are dark and piercing, with a slight hint of sadness or introspection, </span><br></pre></td></tr></table></figure><p><code>Base model</code></p><p><code>LoRA</code></p><p><code>LoRA</code> + <code>APG</code></p><p><code>APG</code> 는 그 말에 충실한 것 같습니다. 채도를 줄여줍니다. 개인적으로 나는 바랜 색상을 선호하지 않지만 밋밋한 “RAW” 같은 이미지를 얻을 수 있는 좋은 방법이 될 수 있습니다.</p><h2 id="Other-fine-tuning-tools-x2F-libraries-for-SD3-5"><a href="#Other-fine-tuning-tools-x2F-libraries-for-SD3-5" class="headerlink" title="Other fine-tuning tools&#x2F;libraries for SD3.5"></a>Other fine-tuning tools&#x2F;libraries for SD3.5</h2><p>Hugging Face의 <a href="https://huggingface.co/blog/sd3-5#training-loras-with-sd35-large-with-Quantization">이 스크립트 및 구성</a>을 참조하세요. 이는 사용하기가 더 간단하지만 결과는 약간 더 나쁠 수 있습니다.</p><h2 id="Conclusion-amp-Feedback"><a href="#Conclusion-amp-Feedback" class="headerlink" title="Conclusion &amp; Feedback"></a>Conclusion &amp; Feedback</h2><p>여기 있는 모든 정보가 출시일에 SD3.5 Large를 미세 조정하는 데 도움이 되기를 바랍니다. ‘DiT’ 아키텍처는 여전히 상대적으로 새로운 것이기 때문에 우리는 구성, 질감 및 전체적인 미학 측면에서 최고의 이미지 품질을 달성하기 위해 다양한 방법을 시도했습니다. 최상의 결과를 얻지 못하는 문제가 발생하는 경우 훈련 중에 보다 세부적인 레이어 조작을 적극 권장합니다.</p><h2 id="Two-cents-from-Dango"><a href="#Two-cents-from-Dango" class="headerlink" title="Two cents from Dango"></a>Two cents from Dango</h2><p>따라서 SD3.5 시리즈의 주요 설계자 중 하나인 Dango의 추가 정보는 다음과 같습니다.</p><p><a href="https://huggingface.co/Dango233">Dango’s Hugging Face profile</a></p><h3 id="Diving-into-SD3-5-Large-Architecture"><a href="#Diving-into-SD3-5-Large-Architecture" class="headerlink" title="Diving into SD3.5 Large Architecture"></a>Diving into SD3.5 Large Architecture</h3><p>SD 3.5 Large의 큰 그림을 이해하기 위해 먼저 아키텍처를 인쇄해 보겠습니다.</p><p>모델을 로컬 디렉터리에 다운로드하는 경우 <code>stable-diffusion-3-medium-diffusers</code>와 유사한 파일 구조를 가져야 합니다.</p><p>SD3.5 Large의 경우 다음과 같습니다.</p><p>키를 나열하려고 하면 샤딩된 디퓨저 형식의 기본 모델에서 오류가 발생하므로 이를 단일 모델로 병합하는 코드입니다. 이 시점에서 나는 모델의 로컬 버전으로 작업하고 있었지만 <code>.cache</code>에 다운로드한 Hugging Face 버전과 동일합니다.</p><p>Example path:</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/home-kasukanra/.cache/huggingface/hub/models--stabilityai--stable-diffusion-3.5-large/snapshots/1a43aa3b9bb52ead637f9693a228092aa802a5dd/transformer</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">import safetensors.torch</span><br><span class="line"></span><br><span class="line">shards = [</span><br><span class="line">    &quot;/weka2/home-yeo/sd3_diffusers/ckpts/35L_1024_rc6b/test_convert/transformer/diffusion_pytorch_model-00001-of-00002.safetensors&quot;,</span><br><span class="line">    &quot;/weka2/home-yeo/sd3_diffusers/ckpts/35L_1024_rc6b/test_convert/transformer/diffusion_pytorch_model-00002-of-00002.safetensors&quot;</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"># Initialize an empty state dictionary</span><br><span class="line">combined_state_dict = &#123;&#125;</span><br><span class="line"></span><br><span class="line"># Load each shard and merge into combined_state_dict</span><br><span class="line">for shard in shards:</span><br><span class="line">    ckpt = safetensors.torch.load_file(shard)</span><br><span class="line">    combined_state_dict.update(ckpt)</span><br><span class="line"></span><br><span class="line"># Specify the output path for the combined model</span><br><span class="line">output_path = &quot;/weka2/home-yeo/sd3_diffusers/ckpts/35L_1024_rc6b/merged/combined_model.safetensors&quot;</span><br><span class="line"></span><br><span class="line"># Save the combined state dictionary to a single .safetensors file</span><br><span class="line">safetensors.torch.save_file(combined_state_dict, output_path)</span><br><span class="line">print(f&quot;Combined model saved successfully at &#123;output_path&#125;&quot;)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>제 경우에는 병합된 모델(<code>combined_model.safetensors</code>)이 있으면 이 스크립트를 실행하여 아키텍처를 텍스트 파일에 저장하세요. 스크립트는 변환기 모델의 일반적인 순차 흐름을 출력합니다.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">import safetensors.torch</span><br><span class="line">import re</span><br><span class="line">import json</span><br><span class="line">from collections import defaultdict</span><br><span class="line"></span><br><span class="line">def group_keys(keys):</span><br><span class="line">    groups = defaultdict(list)</span><br><span class="line">    for key in keys:</span><br><span class="line">        if &#x27;transformer_blocks&#x27; in key:</span><br><span class="line">            block_num = int(re.search(r&#x27;transformer_blocks\.(\d+)&#x27;, key).group(1))</span><br><span class="line">            groups[f&#x27;transformer_block_&#123;block_num&#125;&#x27;].append(key)</span><br><span class="line">        elif &#x27;embed&#x27; in key:</span><br><span class="line">            groups[&#x27;embedding&#x27;].append(key)</span><br><span class="line">        elif &#x27;pos_embed&#x27; in key:</span><br><span class="line">            groups[&#x27;positional_embedding&#x27;].append(key)</span><br><span class="line">        elif &#x27;time_text_embed&#x27; in key:</span><br><span class="line">            groups[&#x27;time_text_embedding&#x27;].append(key)</span><br><span class="line">        elif &#x27;norm_out&#x27; in key:</span><br><span class="line">            groups[&#x27;output_normalization&#x27;].append(key)</span><br><span class="line">        elif &#x27;proj_out&#x27; in key:</span><br><span class="line">            groups[&#x27;output_projection&#x27;].append(key)</span><br><span class="line">        else:</span><br><span class="line">            groups[&#x27;other&#x27;].append(key)</span><br><span class="line">    return groups</span><br><span class="line"></span><br><span class="line">def order_groups(groups):</span><br><span class="line">    order = [</span><br><span class="line">        &#x27;embedding&#x27;,</span><br><span class="line">        &#x27;positional_embedding&#x27;,</span><br><span class="line">        &#x27;time_text_embedding&#x27;,</span><br><span class="line">    ] + [f&#x27;transformer_block_&#123;i&#125;&#x27; for i in range(38)] + [</span><br><span class="line">        &#x27;output_normalization&#x27;,</span><br><span class="line">        &#x27;output_projection&#x27;,</span><br><span class="line">        &#x27;other&#x27;</span><br><span class="line">    ]</span><br><span class="line">    return &#123;k: groups[k] for k in order if k in groups&#125;</span><br><span class="line"></span><br><span class="line">def pretty_print_and_save(ckpt, output_file):</span><br><span class="line">    keys_list = list(ckpt.keys())</span><br><span class="line">    grouped_keys = group_keys(keys_list)</span><br><span class="line">    ordered_groups = order_groups(grouped_keys)</span><br><span class="line">    </span><br><span class="line">    output = []</span><br><span class="line">    for group, keys in ordered_groups.items():</span><br><span class="line">        output.append(f&quot;\n&#123;group.upper()&#125;:&quot;)</span><br><span class="line">        output.extend(sorted(keys))</span><br><span class="line">    </span><br><span class="line">    pretty_output = &#x27;\n&#x27;.join(output)</span><br><span class="line">    </span><br><span class="line">    with open(output_file, &#x27;w&#x27;) as f:</span><br><span class="line">        f.write(pretty_output)</span><br><span class="line">    </span><br><span class="line">    print(f&quot;Grouped keys have been saved to &#123;output_file&#125;&quot;)</span><br><span class="line"></span><br><span class="line"># Load the checkpoint</span><br><span class="line">checkpoint_path = &quot;/weka2/home-yeo/sd3_diffusers/ckpts/35L_1024_rc6b/merged/combined_model.safetensors&quot;</span><br><span class="line">ckpt = safetensors.torch.load_file(checkpoint_path)</span><br><span class="line"></span><br><span class="line"># Pretty-print and save the grouped keys to a file</span><br><span class="line">output_file = &quot;ckpt_keys_grouped_output.txt&quot;</span><br><span class="line">pretty_print_and_save(ckpt, output_file)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="참조"><a href="#참조" class="headerlink" title="참조"></a>참조</h1><hr><ul><li><a href="https://stabilityai.notion.site/Stable-Diffusion-3-5-Large-Fine-tuning-Tutorial-11a61cdcd1968027a15bdbd7c40be8c6">Stable Diffusion 3.5 Large Fine-tuning Tutorial</a></li></ul>]]></content:encoded>
      
      <comments>https://sejoung.github.io/2024/10/2024-10-25-Stable%20Diffusion_3_5_Large_Fine-tuning_Tutorial/#disqus_thread</comments>
    </item>
    
    <item>
      <title>CHAPTER 2 리스트와 딕셔너리</title>
      <link>https://sejoung.github.io/2024/10/2024-10-18-Effective_Python_CHAPTER_2/</link>
      <guid>https://sejoung.github.io/2024/10/2024-10-18-Effective_Python_CHAPTER_2/</guid>
      <pubDate>Fri, 18 Oct 2024 12:27:00 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;2장-리스트와-딕셔너리&quot;&gt;&lt;a href=&quot;#2장-리스트와-딕셔너리&quot; class=&quot;headerlink&quot; title=&quot;2장 리스트와 딕셔너리&quot;&gt;&lt;/a&gt;2장 리스트와 딕셔너리&lt;/h1&gt;&lt;p&gt;리스트는 아주 간편하며 다양한 문제를 해결하는데 사용&lt;
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="2장-리스트와-딕셔너리"><a href="#2장-리스트와-딕셔너리" class="headerlink" title="2장 리스트와 딕셔너리"></a>2장 리스트와 딕셔너리</h1><p>리스트는 아주 간편하며 다양한 문제를 해결하는데 사용<br>리스트를 자연스럽게 보완할수 있는 타입이 딕셔너리 타입이다</p><p>딕셔너리 타입은 일반적으로 해시 테이블이나 연관 배열이라고 부르는 데이터 구조 안에 값을 저장</p><h2 id="Better-way-11-시퀀스를-슬라이싱하는-방법을-익혀라"><a href="#Better-way-11-시퀀스를-슬라이싱하는-방법을-익혀라" class="headerlink" title="Better way 11 시퀀스를 슬라이싱하는 방법을 익혀라"></a>Better way 11 시퀀스를 슬라이싱하는 방법을 익혀라</h2><ul><li>슬라이싱 구문의 기본 형태는 리스트[시작:끝] 이다</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;, &#x27;e&#x27;, &#x27;f&#x27;, &#x27;g&#x27;, &#x27;h&#x27;]</span><br><span class="line">print(&#x27;가운데 2개:&#x27;, a[3:5])</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">assert a[:5] == a[0:5]</span><br><span class="line">assert a[5:] == a[5:len(a)]</span><br></pre></td></tr></table></figure><ul><li><p>슬라이싱한 결과는 완전히 새로운 리스트 원래 리스트는 그대로 유지 된다.</p></li><li><p>슬라이싱한 리스트를 변경해도 원래 리스트는 변경되지 않는다</p></li><li><p>슬라이싱 할때는 간결하게 하라 시작 인덱스에 0을 넣거나, 끝 인덱스에 시퀀스 길이를 넣지 말라</p></li></ul><h2 id="Better-way-12-스트라이드와-슬라이스를-한-식에-함께-사용하지-말라"><a href="#Better-way-12-스트라이드와-슬라이스를-한-식에-함께-사용하지-말라" class="headerlink" title="Better way 12 스트라이드와 슬라이스를 한 식에 함께 사용하지 말라"></a>Better way 12 스트라이드와 슬라이스를 한 식에 함께 사용하지 말라</h2><ul><li><p>파이썬은 리스트[시작:끝:증가값]으로 일정한 간격을 두고 슬라이싱을 할 수 있는 특별한 구문을 제공한다</p></li><li><p>슬라이스에 시작, 끝, 증가값을 함께 지정하면 코드의 의미를 혼동하기 쉽다</p></li><li><p>시작이나 끝 인덱스가 없는 슬라이스를 만들 때는 양수 증가값을 사용하라 가급적 음수 증가값을 피하라</p></li><li><p>한슬라이스 안에서 시작, 끝, 증가값을 함께 사용하지 말라 세 파라미터를 모두 써야 하는 경우 두번 대입을<br>  사용하거나 itertools.islice를 사용하라</p></li></ul><h2 id="Better-way-13-슬라이싱보다는-나머지를-모두-잡아내는-언패킹을-사용하라"><a href="#Better-way-13-슬라이싱보다는-나머지를-모두-잡아내는-언패킹을-사용하라" class="headerlink" title="Better way 13 슬라이싱보다는 나머지를 모두 잡아내는 언패킹을 사용하라"></a>Better way 13 슬라이싱보다는 나머지를 모두 잡아내는 언패킹을 사용하라</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">car_ages = [<span class="number">0</span>, <span class="number">9</span>, <span class="number">4</span>, <span class="number">8</span>, <span class="number">7</span>, <span class="number">20</span>, <span class="number">19</span>, <span class="number">1</span>, <span class="number">6</span>, <span class="number">15</span>]</span><br><span class="line">car_ages_descending = <span class="built_in">sorted</span>(car_ages, reverse=<span class="literal">True</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>아래 코드는 시작적으로 노이즈가 많다<br>그래서 인덱스에 대한 오류를 만들어 내기 쉽다</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">oldest = car_ages_descending[<span class="number">0</span>]</span><br><span class="line">second_oldest = car_ages_descending[<span class="number">1</span>]</span><br><span class="line">ohers = car_ages_descending[<span class="number">2</span>:]</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>이런 상황을 더 잘 다룰 수 있도록 파이썬은 별표식을 사용해 모든 값을 담는 언패킹을 할 수 있게 지원 한다</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">oldest, second_oldest, *others = car_ages_descending</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>별표식은 다른 위치에도 쓸수 있다</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">oldest, *others, youngest = car_ages_descending</span><br><span class="line">*others, second_youngest, youngest = car_ages_descending</span><br></pre></td></tr></table></figure><p>한 수준의 언패킹에 별표식 2개 이상 쓸수 없다</p><p>별표식은 항상 list 인스턴스가 된다</p><h2 id="Better-way-14-복잡한-기준을-사용해-정렬할-때는-key-파라미터를-사용하라"><a href="#Better-way-14-복잡한-기준을-사용해-정렬할-때는-key-파라미터를-사용하라" class="headerlink" title="Better way 14 복잡한 기준을 사용해 정렬할 때는 key 파라미터를 사용하라"></a>Better way 14 복잡한 기준을 사용해 정렬할 때는 key 파라미터를 사용하라</h2><ul><li>리스트 타입에 들어 있는 sort 메서드를 사용하면 원소 타입이 문자열 정수 튜플 등로가 같은 내장 타입인 경우 자연스러운 순서로 리스트의 원소를 정렬할 수 있다</li><li>원소 타입에 특별 메서드를 통해 자연스러운 순서가 정의되 있지 않으면 sort 메서드는 예외를 일으킨다</li><li>sort 메서드에서 key 파라미터를 사용하면 리스트의 각 원소 대신 비교에 사용할 객체를 반환하는 도우미 함수를 제공할 수 있다</li><li>key 함수에서 튜플을 반환하면 여러 정렬 기준을 하나로 역을수 있다</li></ul><h2 id="Better-way-15-딕셔너리-삽입-순서에-의존할-때는-조심하라"><a href="#Better-way-15-딕셔너리-삽입-순서에-의존할-때는-조심하라" class="headerlink" title="Better way 15 딕셔너리 삽입 순서에 의존할 때는 조심하라"></a>Better way 15 딕셔너리 삽입 순서에 의존할 때는 조심하라</h2><ul><li>파이썬 3.6 이전에는 딕셔너리의 순서가 삽입 순서에 의존하지 않는다는 사실을 명시적으로 문서화하지 않았다</li><li>파이썬 3.7부터는 딕셔너리의 순서가 삽입 순서에 의존한다는 사실을 문서화했다</li><li>파이썬은 dict는 아니지만 딕셔너리와 비슷한 객체를 쉽게 만들 수 있게 해준다</li><li>딕셔너리와 비슷한 클래스를 조심스럽게 다루는 방법은 <ul><li>dict 인스턴스의 삽입 순서에 의존하지 않는 방법</li><li>실행 시점에 명시적으로 타입검사를 하는것</li><li>타입 애너테이션과 정적 분석을 사용해 dict 값을 요구하는 법</li></ul></li></ul><h2 id="Better-way-16-in을-사용하고-딕셔너리-키가-없을-때-KeyError를-처리하기보다는-get을-사용하라"><a href="#Better-way-16-in을-사용하고-딕셔너리-키가-없을-때-KeyError를-처리하기보다는-get을-사용하라" class="headerlink" title="Better way 16 in을 사용하고 딕셔너리 키가 없을 때 KeyError를 처리하기보다는 get을 사용하라"></a>Better way 16 in을 사용하고 딕셔너리 키가 없을 때 KeyError를 처리하기보다는 get을 사용하라</h2><ul><li>딕셔너리가 없는 경우를 처리하는 방법으로 in식을 사용하는 방법 keyError를 처리하는 방법으로 get을 사용하는 방법이 있다</li><li>카운터와 같이 기본적인 타입의 값이 들어가는 딕셔너리를 다룰 때는 get 메서드를 사용하는 것이 더 깔끔하다</li><li>setdefault 메서드 대신 defaultdict를 사용하면 더 간결하게 딕셔너리를 다룰 수 있다</li></ul><h2 id="Better-way-17-내부-상태에서-원소가-없는-경우를-처리할-때는-setdefault보다-defaultdict를-사용하라"><a href="#Better-way-17-내부-상태에서-원소가-없는-경우를-처리할-때는-setdefault보다-defaultdict를-사용하라" class="headerlink" title="Better way 17 내부 상태에서 원소가 없는 경우를 처리할 때는 setdefault보다 defaultdict를 사용하라"></a>Better way 17 내부 상태에서 원소가 없는 경우를 처리할 때는 setdefault보다 defaultdict를 사용하라</h2><ul><li>키로 어떤 값이 들어올지 모르는 딕셔너리를 관리해야 하는데 collections.defaultdict를 사용하면 편리하다</li><li>임의의 키가 들어 있는 딕셔너리가 여러분에게 전달됐고 그 딕셔너리가 어떻게 생성됐는지 모르는 경우, defaultdict를 사용하면 편리하다</li></ul><h2 id="Better-way-18-missing-을-사용해-키에-따라-다른-디폴트-값을-생성하는-방법을-알아두라"><a href="#Better-way-18-missing-을-사용해-키에-따라-다른-디폴트-값을-생성하는-방법을-알아두라" class="headerlink" title="Better way 18 __missing__을 사용해 키에 따라 다른 디폴트 값을 생성하는 방법을 알아두라"></a>Better way 18 __missing__을 사용해 키에 따라 다른 디폴트 값을 생성하는 방법을 알아두라</h2><ul><li>디폴드 값을 만드는 계산 비용이 높거나 만드는 과정에서 예외가 발생할 수 있는 상황에서는 dict의 setdefault 메서드를 사용하지 말라</li><li>디폴트 키를 만들때 어떤 키를 사용했는지 반드시 알아야 하는 상황이라면 직접 dict의 하위 클래스와 <strong>missing</strong> 메서드를 정의하라</li></ul><h1 id="참조"><a href="#참조" class="headerlink" title="참조"></a>참조</h1><hr><ul><li><a href="https://www.yes24.com/Product/Goods/94197582">Effective Python 2nd 파이썬 코딩의 기술(개정2판) 똑똑하게 코딩하는 법</a></li></ul>]]></content:encoded>
      
      <comments>https://sejoung.github.io/2024/10/2024-10-18-Effective_Python_CHAPTER_2/#disqus_thread</comments>
    </item>
    
    <item>
      <title>CHAPTER 1 파이썬다운 생각</title>
      <link>https://sejoung.github.io/2024/10/2024-10-15-Effective_Python_CHAPTER_1/</link>
      <guid>https://sejoung.github.io/2024/10/2024-10-15-Effective_Python_CHAPTER_1/</guid>
      <pubDate>Tue, 15 Oct 2024 13:40:00 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;1장-파이썬답게-생각하기&quot;&gt;&lt;a href=&quot;#1장-파이썬답게-생각하기&quot; class=&quot;headerlink&quot; title=&quot;1장 파이썬답게 생각하기&quot;&gt;&lt;/a&gt;1장 파이썬답게 생각하기&lt;/h1&gt;&lt;p&gt;가장 파이썬 다운 방식을 알아야 된다&lt;/p&gt;
&lt;
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="1장-파이썬답게-생각하기"><a href="#1장-파이썬답게-생각하기" class="headerlink" title="1장 파이썬답게 생각하기"></a>1장 파이썬답게 생각하기</h1><p>가장 파이썬 다운 방식을 알아야 된다</p><h2 id="Better-way-1-사용-중인-파이썬의-버전을-알아두라"><a href="#Better-way-1-사용-중인-파이썬의-버전을-알아두라" class="headerlink" title="Better way 1 사용 중인 파이썬의 버전을 알아두라"></a>Better way 1 사용 중인 파이썬의 버전을 알아두라</h2><p>파이썬 2는 수명이 다됨 백포팅이 이루어지지 않음</p><ul><li>backporting: 새로운 기능을 이전 버전에서도 사용할 수 있게 하는 것</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">import sys</span><br><span class="line"></span><br><span class="line">print(sys.version_info)</span><br><span class="line">print(sys.version)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="Better-way-2-PEP-8-스타일-가이드를-따르라"><a href="#Better-way-2-PEP-8-스타일-가이드를-따르라" class="headerlink" title="Better way 2 PEP 8 스타일 가이드를 따르라"></a>Better way 2 PEP 8 스타일 가이드를 따르라</h2><p>파이썬 개선 제안(Python Enhancement Proposal) 8은 파이썬 코드를 어떻게 구성할지에 대한 스타일 가이드를 제공한다.</p><h3 id="공백-Whitespace"><a href="#공백-Whitespace" class="headerlink" title="공백(Whitespace)"></a>공백(Whitespace)</h3><ul><li>탭 대신 스페이스를 사용하라</li><li>문법적으로 의미 있는 들여쓰기는 4개의 스페이스로 한다</li><li>한 줄의 문자 길이가 79자 이하여야 한다</li><li>긴 식을 다음 줄에 이어서 쓸 때는 일반적인 들여쓰기 보다 4개의 스페이스를 더 들여써야 한다</li><li>파일에서 함수와 클래스는 빈 줄 두개로 구분해야 한다</li><li>딕셔너리(dictionsry)에서 키와 콜론(:) 사이에는 공백을 넣지 않고 한 줄 안에 키와 값을 같이 넣는 경우에는 콜론 다음에 스페이스를 하나 넣는다</li><li>변수 대입에서 &#x3D; 전후에는 스페이스를 하나씩만 넣는다</li><li>타입 표기를 덧붙이는 경우에는 변수 이름과 콜론사이에 공백을 넣지 않도록 주의하고 콜론과 타입 정보 사이에는 스페이스를 하나 넣어라</li></ul><h3 id="명명-Naming"><a href="#명명-Naming" class="headerlink" title="명명(Naming)"></a>명명(Naming)</h3><ul><li>함수, 변수, 속성은 lowercase_underscore 형식을 따른다</li><li>보호(protected) 인스턴스 속성은 _leading_underscore 형식을 따른다</li><li>비공개(private) 인스턴스 속성은 __double_leading_underscore 형식을 따른다</li><li>클래스와 예외는 CapitalizedWord 형식을 따른다</li><li>모듈 수준 상수는 ALL_CAPS 형식을 따른다</li><li>클래스의 인스턴스 메서드에서 첫 번째 파라미터의 이름은 self를 사용한다</li><li>클래스 메서드에서 첫 번째 파라미터의 이름은 cls를 사용한다</li></ul><h3 id="표현식과-문장-Expressions-and-Statements"><a href="#표현식과-문장-Expressions-and-Statements" class="headerlink" title="표현식과 문장(Expressions and Statements)"></a>표현식과 문장(Expressions and Statements)</h3><ul><li>긍정적인 표현식을 부정하지 말고(if not a is b) 부정을 내부에 넣어라 (if a is not b)</li><li>빈 컨테이너(container)나 시퀀스(sequence)를 검사할 때 길이를 (if len(somelist)&#x3D;&#x3D;0)와 비교하지 말고 if not somelist 와 같이 사용하라<ul><li>빈 값은 암시적으로 False로 평가된다</li></ul></li><li>비어 있지 않을때로 길이로 비교하지 말라<ul><li>비어 있지 않은 값은 암시적으로 True로 평가된다</li></ul></li><li>한줄로 된 if 문, for와 while 루프, except 복합문을 쓰지 말고 여러 줄로 나눠서 쓰라</li><li>식을 한 줄에 넣을 때는 식을 괄호로 둘러싸고 줄바꿈과 들여쓰기를 추가해서 읽기 쉽게 만들어라</li><li>여러줄에 걸쳐 식을 쓸 때는 줄이 계속된다는 표시로 \ 문자보단 괄호를 사용하라</li></ul><h3 id="임포트-Imports"><a href="#임포트-Imports" class="headerlink" title="임포트(Imports)"></a>임포트(Imports)</h3><ul><li>import 문은 항상 파일 맨 위에 위치해야 한다</li><li>모듈을 임포트할 때는 항상 모듈의 절대 이름을 사용하고 현재 모듈의 경로를 기준으로 상대 경로로 된 이름을 사용하지 않는다<ul><li>from bar import foo 라고 해야 되며 import foo 라고 하면 안된다</li></ul></li><li>반듯이 상대적인 경로로 임포트해야 하는 경우에는 from . import foo 라고 해야 한다</li><li>임포트는 ‘표준 라이브러리 모듈, 서드파티 모듈, 자신이 만든 모듈’ 순으로 구분해야 한다</li></ul><h2 id="Better-way-3-bytes와-str의-차이를-알아두라"><a href="#Better-way-3-bytes와-str의-차이를-알아두라" class="headerlink" title="Better way 3 bytes와 str의 차이를 알아두라"></a>Better way 3 bytes와 str의 차이를 알아두라</h2><p>문자열 데이터의 시퀀스를 표현하는 두 가지 타입</p><ul><li>bytes: 8비트 값을 연속된 시퀀스로 나타낸다</li><li>str: 유니코드 문자를 연속된 시퀀스로 나타낸다</li></ul><p>str 인스턴스에는 직접 대응하는 이진 인코딩이 없고 bytes 인스턴스에는 직접 대응하는 텍스트 인코딩이 없다</p><p>유니코드 샌드위치 : 유니코드 데이터를 인코딩 하거나 디코딩하는 부분을 인터페이스의 가장 먼 경계에 두는 것</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">def to_str(bytes_or_str):</span><br><span class="line">    if isinstance(bytes_or_str, bytes):</span><br><span class="line">        value = bytes_or_str.decode(&#x27;utf-8&#x27;)</span><br><span class="line">    else:</span><br><span class="line">        value = bytes_or_str</span><br><span class="line">    return value</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="Better-way-4-C-스타일-형식-문자열을-str-format과-쓰기보다는-f-문자열을-통한-인터폴레이션을-사용하라"><a href="#Better-way-4-C-스타일-형식-문자열을-str-format과-쓰기보다는-f-문자열을-통한-인터폴레이션을-사용하라" class="headerlink" title="Better way 4 C 스타일 형식 문자열을 str.format과 쓰기보다는 f-문자열을 통한 인터폴레이션을 사용하라"></a>Better way 4 C 스타일 형식 문자열을 str.format과 쓰기보다는 f-문자열을 통한 인터폴레이션을 사용하라</h2><ul><li>f-문자열: 문자열 앞에 f를 붙이면 문자열 안에 중괄호로 변수를 감싸면 변수의 값을 참조할 수 있다</li><li>f-문자열은 가독성이 좋고 str.format보다 간결하다</li><li>% 연산자를 사용한 C 스타일 형식 문자열은 가독성이 떨어지고 f-문자열보다 더 복잡하다</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">place = 3</span><br><span class="line">number = 1.23456</span><br><span class="line"></span><br><span class="line">print(f&#x27;내가 고른 숫자? &#123;number:.&#123;place&#125;f&#125;&#x27;)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="Better-way-5-복잡한-식을-쓰는-대신-도우미-함수를-작성하라"><a href="#Better-way-5-복잡한-식을-쓰는-대신-도우미-함수를-작성하라" class="headerlink" title="Better way 5 복잡한 식을 쓰는 대신 도우미 함수를 작성하라"></a>Better way 5 복잡한 식을 쓰는 대신 도우미 함수를 작성하라</h2><ul><li>복잡한 식을 작성할 때는 식을 작성하는 도우미 함수를 작성하라</li><li>boolean 연산자나 or, and를 식에 사용하는 것 보다 if&#x2F;else 문을 사용하는 것이 가독성이 좋다</li></ul><h2 id="Better-way-6-인덱스를-사용하는-대신-대입을-사용해-데이터를-언패킹하라"><a href="#Better-way-6-인덱스를-사용하는-대신-대입을-사용해-데이터를-언패킹하라" class="headerlink" title="Better way 6 인덱스를 사용하는 대신 대입을 사용해 데이터를 언패킹하라"></a>Better way 6 인덱스를 사용하는 대신 대입을 사용해 데이터를 언패킹하라</h2><p>파이썬에는 값으로 이뤄진 불변 순서쌍을 만들어낼 수 있는 tuple이 있다</p><p>튜플이 만들어지면 인덱스를 통해 새 값을 대입해서 튜플을 변경할수는 없다</p><p>언패킹</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">item = (&#x27;apple&#x27;, 5)</span><br><span class="line">name, count = item</span><br><span class="line">print(name, count)</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">def bubble_sort(a):</span><br><span class="line">    for _ in range(len(a)):</span><br><span class="line">        for i in range(1, len(a)):</span><br><span class="line">            if a[i] &lt; a[i-1]:</span><br><span class="line">                a[i-1], a[i] = a[i], a[i-1]</span><br><span class="line">                </span><br><span class="line">names = [&#x27;pretzels&#x27;, &#x27;carrots&#x27;, &#x27;arugula&#x27;, &#x27;bacon&#x27;]</span><br><span class="line">bubble_sort(names)</span><br><span class="line">print(names)</span><br><span class="line"># [&#x27;arugula&#x27;, &#x27;bacon&#x27;, &#x27;carrots&#x27;, &#x27;pretzels&#x27;]</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">for rank, (name, count) in enumerate(results, 1):</span><br><span class="line">    print(f&#x27;&#123;rank&#125;: &#123;name&#125; -&gt; &#123;count&#125;&#x27;)</span><br></pre></td></tr></table></figure><h2 id="Better-way-7-range보다는-enumerate를-사용하라"><a href="#Better-way-7-range보다는-enumerate를-사용하라" class="headerlink" title="Better way 7 range보다는 enumerate를 사용하라"></a>Better way 7 range보다는 enumerate를 사용하라</h2><p>range 함수는 어떤 정수의 집합을 이터레이션 하는 루프가 필요 할 때 유용하다</p><p>enumerate 함수는 이터레이터를 감싸서 이터레이터가 생성하는 각 아이템의 값과 인덱스를 함께 반환한다</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">flavors = [&#x27;one&#x27;, &#x27;two&#x27;, &#x27;three&#x27;]</span><br><span class="line"></span><br><span class="line">it = enumerate(flavors)</span><br><span class="line">print(next(it))</span><br><span class="line">print(next(it))</span><br><span class="line">print(next(it))</span><br><span class="line"></span><br><span class="line">for i, flavor in enumerate(flavors):</span><br><span class="line">    print(f&#x27;&#123;i+1&#125;: &#123;flavor&#125;&#x27;)</span><br><span class="line">    </span><br><span class="line">for i, flavor in enumerate(flavors, 1):</span><br><span class="line">    print(f&#x27;&#123;i&#125;: &#123;flavor&#125;&#x27;)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="Better-way-8-여러-이터레이터에-대해-나란히-루프를-수행하려면-zip을-사용하라"><a href="#Better-way-8-여러-이터레이터에-대해-나란히-루프를-수행하려면-zip을-사용하라" class="headerlink" title="Better way 8 여러 이터레이터에 대해 나란히 루프를 수행하려면 zip을 사용하라"></a>Better way 8 여러 이터레이터에 대해 나란히 루프를 수행하려면 zip을 사용하라</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">for name, count in zip(names, counts):</span><br><span class="line">    print(name, count)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>zip 제너레이션은 각 이터레이터의 다음값이 있는 튜플을 반환한다</p><p>zip은 입력 이터레이터들 중 가장 짧은 이터레이터가 끝날 때 멈춘다</p><h2 id="Better-way-9-for나-while-루프-뒤에-else-블록을-사용하지-말라"><a href="#Better-way-9-for나-while-루프-뒤에-else-블록을-사용하지-말라" class="headerlink" title="Better way 9 for나 while 루프 뒤에 else 블록을 사용하지 말라"></a>Better way 9 for나 while 루프 뒤에 else 블록을 사용하지 말라</h2><p>파이썬은 루프가 완전히 실행되고 나면 else 블록을 실행한다</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">for i in range(3):</span><br><span class="line">    print(&#x27;Loop&#x27;, i)</span><br><span class="line">else:</span><br><span class="line">    print(&#x27;Else block!&#x27;)    </span><br></pre></td></tr></table></figure><p>하지만 break 문을 사용하면 else 블록은 실행되지 않는다</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">for i in range(3):</span><br><span class="line">    print(&#x27;Loop&#x27;, i)</span><br><span class="line">    if i == 1:</span><br><span class="line">        break</span><br><span class="line">else:</span><br><span class="line">    print(&#x27;Else block!&#x27;)</span><br><span class="line">    </span><br></pre></td></tr></table></figure><p>또 빈 시퀀스에 대한 루프를 실행할 때도 else 블록이 실행된다</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">for x in []:</span><br><span class="line">    print(&#x27;Never runs&#x27;)</span><br><span class="line">else:</span><br><span class="line">    print(&#x27;For Else block!&#x27;)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>while 루프에도 값이 false면 바로 else 블록을 실행한다</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">while False:</span><br><span class="line">    print(&#x27;Never runs&#x27;)</span><br><span class="line">else:</span><br><span class="line">    print(&#x27;While Else block!&#x27;)</span><br></pre></td></tr></table></figure><p>위처럼 동작이 직관적이지 않고 혼동을 야기 할수 있다</p><h2 id="Better-way-10-대입식을-사용해-반복을-피하라"><a href="#Better-way-10-대입식을-사용해-반복을-피하라" class="headerlink" title="Better way 10 대입식을 사용해 반복을 피하라"></a>Better way 10 대입식을 사용해 반복을 피하라</h2><p>assignment expression이며 walrus operator라고도 한다</p><ul><li>대입식에서는 왈러스 연산자(:&#x3D;)를 사용해서 변수에 값을 대입하면서 동시에 이 값을 평가할 수 있고 중복을 줄일수 있다</li><li>대입식이 더 큰 식의 일부분으로 쓰일 때는 괄호로 둘러싸야 한다</li><li>파이썬에서는 switch&#x2F;case 문이나 do&#x2F;while 루프가 없지만 대입식을 활용해서 이방법을 깔끔하게 흉내 낼수 있다</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bottles = []</span><br><span class="line">while fresh_fruit := pick_fruit():</span><br><span class="line">    bottles.append(fresh_fruit.make_juice())</span><br></pre></td></tr></table></figure><h1 id="참조"><a href="#참조" class="headerlink" title="참조"></a>참조</h1><hr><ul><li><a href="https://www.yes24.com/Product/Goods/94197582">Effective Python 2nd 파이썬 코딩의 기술(개정2판) 똑똑하게 코딩하는 법</a></li><li><a href="https://peps.python.org/pep-0008/">PEP 8 – Style Guide for Python Code</a></li></ul>]]></content:encoded>
      
      <comments>https://sejoung.github.io/2024/10/2024-10-15-Effective_Python_CHAPTER_1/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Flux Lora 훈련하기</title>
      <link>https://sejoung.github.io/2024/10/2024-10-11-train_lora_flux/</link>
      <guid>https://sejoung.github.io/2024/10/2024-10-11-train_lora_flux/</guid>
      <pubDate>Fri, 11 Oct 2024 01:30:00 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;Flux-Lora-훈련하기&quot;&gt;&lt;a href=&quot;#Flux-Lora-훈련하기&quot; class=&quot;headerlink&quot; title=&quot;Flux Lora 훈련하기&quot;&gt;&lt;/a&gt;Flux Lora 훈련하기&lt;/h1&gt;&lt;p&gt;관찮은 글 모음&lt;/p&gt;
&lt;h1 id=&quot;참
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Flux-Lora-훈련하기"><a href="#Flux-Lora-훈련하기" class="headerlink" title="Flux Lora 훈련하기"></a>Flux Lora 훈련하기</h1><p>관찮은 글 모음</p><h1 id="참조"><a href="#참조" class="headerlink" title="참조"></a>참조</h1><hr><ul><li><a href="https://github.com/bghira/SimpleTuner">SimpleTuner</a></li><li><a href="https://github.com/ostris/ai-toolkit">ai-toolkit</a></li><li><a href="https://www.youtube.com/watch?v=se3qpLkJnrk">Kasucast #26 - FLUX.1 [dev]: Training LoRA with SimpleTuner and AI-Toolkit</a></li><li><a href="https://stability.ai/learning-hub/stable-diffusion-3-medium-fine-tuning-tutorial">Stable Diffusion 3 Medium Fine-tuning Tutorial</a></li><li><a href="https://github.com/Nerogar/OneTrainer">OneTrainer</a></li></ul>]]></content:encoded>
      
      <comments>https://sejoung.github.io/2024/10/2024-10-11-train_lora_flux/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Lora 훈련하기</title>
      <link>https://sejoung.github.io/2024/09/2024-09-09-train_lora/</link>
      <guid>https://sejoung.github.io/2024/09/2024-09-09-train_lora/</guid>
      <pubDate>Mon, 09 Sep 2024 04:51:00 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;Lora-훈련하기&quot;&gt;&lt;a href=&quot;#Lora-훈련하기&quot; class=&quot;headerlink&quot; title=&quot;Lora 훈련하기&quot;&gt;&lt;/a&gt;Lora 훈련하기&lt;/h1&gt;&lt;p&gt;괜찮은 스레드들의 모음&lt;/p&gt;
&lt;h1 id=&quot;참조&quot;&gt;&lt;a href=&quot;#참조&quot;
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Lora-훈련하기"><a href="#Lora-훈련하기" class="headerlink" title="Lora 훈련하기"></a>Lora 훈련하기</h1><p>괜찮은 스레드들의 모음</p><h1 id="참조"><a href="#참조" class="headerlink" title="참조"></a>참조</h1><hr><ul><li><a href="https://civitai.com/articles/3921/this-is-how-i-create-and-train-loras">This is how I create and train LoRAs</a></li><li><a href="https://civitai.com/articles/6824/training-a-flux-character-lora-on-civitai">Training a Flux Character LoRA on Civitai</a></li><li><a href="https://civitai.com/articles/6792/flux-style-captioning-differences-training-diary">Flux Style Captioning Differences - Training Diary</a></li><li><a href="https://civitai.com/articles/7097/flux-complete-lora-settings-and-dataset-guide-post-mortem-of-two-weeks-of-learning">Flux complete Lora settings and dataset guide - post-mortem of two weeks of learning</a></li><li><a href="https://civitai.com/articles/6868/flux-character-caption-differences-training-diary">Flux Character Caption Differences - Training Diary</a></li><li><a href="https://civitai.com/articles/7146/flux-style-captioning-differences-pt2-4-new-caption-tools-training-diary">Flux Style Captioning Differences pt2. - 4 new caption tools - Training Diary</a></li><li></li></ul>]]></content:encoded>
      
      <comments>https://sejoung.github.io/2024/09/2024-09-09-train_lora/#disqus_thread</comments>
    </item>
    
    <item>
      <title>CHAPTER 19 Critique: 구글의 코드 리뷰 도구</title>
      <link>https://sejoung.github.io/2024/08/2024-08-22-Software_Engineering_at_Google_CHAPTER_19/</link>
      <guid>https://sejoung.github.io/2024/08/2024-08-22-Software_Engineering_at_Google_CHAPTER_19/</guid>
      <pubDate>Thu, 22 Aug 2024 00:21:00 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;Part-IV-도구&quot;&gt;&lt;a href=&quot;#Part-IV-도구&quot; class=&quot;headerlink&quot; title=&quot;Part IV 도구&quot;&gt;&lt;/a&gt;Part IV 도구&lt;/h1&gt;&lt;h2 id=&quot;CHAPTER-19-Critique-구글의-코드-리뷰-도구&quot;
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Part-IV-도구"><a href="#Part-IV-도구" class="headerlink" title="Part IV 도구"></a>Part IV 도구</h1><h2 id="CHAPTER-19-Critique-구글의-코드-리뷰-도구"><a href="#CHAPTER-19-Critique-구글의-코드-리뷰-도구" class="headerlink" title="CHAPTER 19 Critique: 구글의 코드 리뷰 도구"></a>CHAPTER 19 Critique: 구글의 코드 리뷰 도구</h2><p>코드 리뷰는 소프트웨어 개발에서 없어서는 안 될 요소입니다.<br>특히 성장하기 위해 매우 중요한 요소입니다.</p><h3 id="코드-리뷰-도구-원칙"><a href="#코드-리뷰-도구-원칙" class="headerlink" title="코드 리뷰 도구 원칙"></a>코드 리뷰 도구 원칙</h3><ul><li>간결성<ul><li>가장 큰 영향을 준 원칙</li></ul></li><li>신뢰 제공</li><li>익숙한 소통 방식</li><li>워크플로 통합</li></ul><h3 id="코드-리뷰-흐름"><a href="#코드-리뷰-흐름" class="headerlink" title="코드 리뷰 흐름"></a>코드 리뷰 흐름</h3><ul><li>변경 생성</li><li>리뷰 요청</li><li>변경 이해하고 댓글 달기</li><li>변경 수정 및 댓글에 답하기</li><li>변경 승인</li><li>변경 커밋</li></ul><h3 id="1단계-변경-생성"><a href="#1단계-변경-생성" class="headerlink" title="1단계: 변경 생성"></a>1단계: 변경 생성</h3><ul><li>디프, 차이점 보여주기</li><li>분석 결과</li><li>긴밀한 도구 통합<h3 id="2단계-리뷰-요청"><a href="#2단계-리뷰-요청" class="headerlink" title="2단계: 리뷰 요청"></a>2단계: 리뷰 요청</h3>리뷰 요청 할때 리뷰어 선정이 어려운데 별칭으로 리뷰어를 선정하는 방법이 있다.</li></ul><h3 id="3-4단계-변경-이해하고-댓글-달기"><a href="#3-4단계-변경-이해하고-댓글-달기" class="headerlink" title="3~4단계: 변경 이해하고 댓글 달기"></a>3~4단계: 변경 이해하고 댓글 달기</h3><ul><li><p>댓글달기</p></li><li><p>변경의 상태 이해하기</p><ul><li>누구 차례 기능</li><li>대시보드 와 검색 시스템<h3 id="5단계-변경-승인-변경에-점수-매기기"><a href="#5단계-변경-승인-변경에-점수-매기기" class="headerlink" title="5단계: 변경 승인(변경에 점수 매기기)"></a>5단계: 변경 승인(변경에 점수 매기기)</h3>구글에서 변경에 점수를 매길 때 고려하는 요소</li></ul></li><li><p>LGTM</p></li><li><p>승인</p></li><li><p>미해결 댓글 개수</p></li></ul><h3 id="6단계-변경-커밋"><a href="#6단계-변경-커밋" class="headerlink" title="6단계: 변경 커밋"></a>6단계: 변경 커밋</h3><ul><li>커밋 후 : 뱐걍 이력 추적</li></ul><h1 id="참조"><a href="#참조" class="headerlink" title="참조"></a>참조</h1><hr><ul><li><a href="https://www.yes24.com/Product/Goods/109182479">구글 엔지니어는 이렇게 일한다</a></li></ul>]]></content:encoded>
      
      <comments>https://sejoung.github.io/2024/08/2024-08-22-Software_Engineering_at_Google_CHAPTER_19/#disqus_thread</comments>
    </item>
    
    <item>
      <title>CHAPTER 18 빌드 시스템과 빌드 철학</title>
      <link>https://sejoung.github.io/2024/08/2024-08-19-Software_Engineering_at_Google_CHAPTER_18/</link>
      <guid>https://sejoung.github.io/2024/08/2024-08-19-Software_Engineering_at_Google_CHAPTER_18/</guid>
      <pubDate>Mon, 19 Aug 2024 00:42:00 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;Part-IV-도구&quot;&gt;&lt;a href=&quot;#Part-IV-도구&quot; class=&quot;headerlink&quot; title=&quot;Part IV 도구&quot;&gt;&lt;/a&gt;Part IV 도구&lt;/h1&gt;&lt;h2 id=&quot;CHAPTER-18-빌드-시스템과-빌드-철학&quot;&gt;&lt;a href
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Part-IV-도구"><a href="#Part-IV-도구" class="headerlink" title="Part IV 도구"></a>Part IV 도구</h1><h2 id="CHAPTER-18-빌드-시스템과-빌드-철학"><a href="#CHAPTER-18-빌드-시스템과-빌드-철학" class="headerlink" title="CHAPTER 18 빌드 시스템과 빌드 철학"></a>CHAPTER 18 빌드 시스템과 빌드 철학</h2><p>구글 엔지니어에게 빌드시스템은 사랑이다</p><h3 id="빌드-시스템의-목적"><a href="#빌드-시스템의-목적" class="headerlink" title="빌드 시스템의 목적"></a>빌드 시스템의 목적</h3><p>빌드 시스템의 목적</p><ul><li>속도 : 개발자가 명령 하나로 빌드를 수행하고 몇 초안에 결과 바이너리를 얻을 수 있어야 한다.</li><li>정확성 : 소스 파일과 기타 입력 데이터가 같다면 모든 개발자가 어떤 컴퓨터에서 빌드하더라고 항상 동일한 결과를 내어야 한다</li></ul><h3 id="빌드-시스템이-없다면"><a href="#빌드-시스템이-없다면" class="headerlink" title="빌드 시스템이 없다면?"></a>빌드 시스템이 없다면?</h3><p>빌드 환경 없이 프로젝트 규모를 확장하려 들면 온갖 난관에 부딪히게 된다</p><h4 id="컴파일러로-충분하지-않나"><a href="#컴파일러로-충분하지-않나" class="headerlink" title="컴파일러로 충분하지 않나?"></a>컴파일러로 충분하지 않나?</h4><p>의존 관계가 조금만 복잡해져도 귀찮고 오류가 잦은 작업이다</p><h4 id="쉘-스크립트가-출동한다면"><a href="#쉘-스크립트가-출동한다면" class="headerlink" title="쉘 스크립트가 출동한다면?"></a>쉘 스크립트가 출동한다면?</h4><ul><li>지루해진다</li><li>느리다</li></ul><h3 id="모던-빌드-시스템"><a href="#모던-빌드-시스템" class="headerlink" title="모던 빌드 시스템"></a>모던 빌드 시스템</h3><ul><li>핵심은 의존성</li><li>태스크 기반 빌드 시스템<ul><li>단점<ul><li>빌드 단계들을 병렬로 싱행하기 어렵다</li><li>증분 빌드를 수행하기 어렵다</li><li>스크립트를 유지보수하고 디버깅하기 어렵다</li></ul></li></ul></li><li>아티 팩트 기반 빌드 시스템<ul><li>도구도 의존성으로 취급</li><li>빌드 시스템 확장하기</li><li>외부 의존성 명확히 드러내기<h3 id="모듈과-의존성-다루기"><a href="#모듈과-의존성-다루기" class="headerlink" title="모듈과 의존성 다루기"></a>모듈과 의존성 다루기</h3></li></ul></li><li>작은 모듈 사용과 1:1:1 규칙</li><li>모듈 가시성 최소화</li><li>의존성관리<ul><li>내부 의존성</li><li>외부 의존성<ul><li>원-버전 규칙</li><li>전이 외부 의존성</li><li>외부 의존성을 이용해 빌드 결과 캐시</li><li>외부 의존성의 보안과 안정성</li></ul></li></ul></li></ul><h1 id="참조"><a href="#참조" class="headerlink" title="참조"></a>참조</h1><hr><ul><li><a href="https://www.yes24.com/Product/Goods/109182479">구글 엔지니어는 이렇게 일한다</a></li></ul>]]></content:encoded>
      
      <comments>https://sejoung.github.io/2024/08/2024-08-19-Software_Engineering_at_Google_CHAPTER_18/#disqus_thread</comments>
    </item>
    
    <item>
      <title>CHAPTER 17 Code Search</title>
      <link>https://sejoung.github.io/2024/08/2024-08-16-Software_Engineering_at_Google_CHAPTER_17/</link>
      <guid>https://sejoung.github.io/2024/08/2024-08-16-Software_Engineering_at_Google_CHAPTER_17/</guid>
      <pubDate>Fri, 16 Aug 2024 00:27:00 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;Part-IV-도구&quot;&gt;&lt;a href=&quot;#Part-IV-도구&quot; class=&quot;headerlink&quot; title=&quot;Part IV 도구&quot;&gt;&lt;/a&gt;Part IV 도구&lt;/h1&gt;&lt;h2 id=&quot;CHAPTER-17-Code-Search&quot;&gt;&lt;a href=&quot;
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Part-IV-도구"><a href="#Part-IV-도구" class="headerlink" title="Part IV 도구"></a>Part IV 도구</h1><h2 id="CHAPTER-17-Code-Search"><a href="#CHAPTER-17-Code-Search" class="headerlink" title="CHAPTER 17 Code Search"></a>CHAPTER 17 Code Search</h2><p>구글이 이용하는 코드 브라우징 및 검색 도구</p><h3 id="Code-Search-UI"><a href="#Code-Search-UI" class="headerlink" title="Code Search UI"></a>Code Search UI</h3><p>핵심요소는 검색창</p><p>파일 하나를 들여다 볼때 대부분은 토큰을 바로 클릭하여 관련 정보로 빠르게 이동 할수 있다</p><ul><li>이슈 트래커</li><li>코드 참조 클래스</li></ul><h3 id="구글-개발자가-Code-Search를-이용하는-방법"><a href="#구글-개발자가-Code-Search를-이용하는-방법" class="headerlink" title="구글 개발자가 Code Search를 이용하는 방법"></a>구글 개발자가 Code Search를 이용하는 방법</h3><p>코드에 대한 답을 찾고 코드의 의도를 분명하게 이해하는것</p><ul><li>어디에?</li><li>무엇을</li><li>어떻게</li><li>왜?</li><li>누가 언제?</li></ul><h3 id="독립된-웹-도구로-만든-이유"><a href="#독립된-웹-도구로-만든-이유" class="headerlink" title="독립된 웹 도구로 만든 이유"></a>독립된 웹 도구로 만든 이유</h3><ul><li>대규모 코드베이스 지원</li><li>설정 없이 모든 코드 보기</li><li>기능 특화</li><li>다른 도구에 통합</li><li>API 제공</li></ul><h3 id="규모가-설계에-미치는-영향"><a href="#규모가-설계에-미치는-영향" class="headerlink" title="규모가 설계에 미치는 영향"></a>규모가 설계에 미치는 영향</h3><ul><li>검색 쿼리 지연시간</li><li>인덱싱 지연시간</li></ul><h3 id="구글은-어떻게-구현했나"><a href="#구글은-어떻게-구현했나" class="headerlink" title="구글은 어떻게 구현했나?"></a>구글은 어떻게 구현했나?</h3><ul><li>검색 인덱스<ul><li>초기엔 트라이그램 기반의 방식</li><li>커스텀한 접미사 배열</li></ul></li><li>랭킹<ul><li>쿼리 독립적 시그널<ul><li>파일 조회수</li><li>파일로의 참조량</li></ul></li><li>쿼리 의존적 시그널</li><li>검출</li><li>결과 다양성<h3 id="구글이-선택한-트레이드오프"><a href="#구글이-선택한-트레이드오프" class="headerlink" title="구글이 선택한 트레이드오프"></a>구글이 선택한 트레이드오프</h3></li></ul></li><li>완벽성<ul><li>헤드 리포지터리</li><li>전부 vs 가장 관련성 높은 결과만</li><li>헤드 vs 브랜치 vs 모든 변경 이력 vs 작업 공간</li></ul></li><li>표현력<ul><li>토큰 vs 부분 문자열 vs 정규 표현식</li></ul></li></ul><h1 id="참조"><a href="#참조" class="headerlink" title="참조"></a>참조</h1><hr><ul><li><a href="https://www.yes24.com/Product/Goods/109182479">구글 엔지니어는 이렇게 일한다</a></li></ul>]]></content:encoded>
      
      <comments>https://sejoung.github.io/2024/08/2024-08-16-Software_Engineering_at_Google_CHAPTER_17/#disqus_thread</comments>
    </item>
    
    <item>
      <title>CHAPTER 16 버전 관리와 브랜치 관리</title>
      <link>https://sejoung.github.io/2024/08/2024-08-12-Software_Engineering_at_Google_CHAPTER_16/</link>
      <guid>https://sejoung.github.io/2024/08/2024-08-12-Software_Engineering_at_Google_CHAPTER_16/</guid>
      <pubDate>Mon, 12 Aug 2024 00:35:00 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;Part-IV-도구&quot;&gt;&lt;a href=&quot;#Part-IV-도구&quot; class=&quot;headerlink&quot; title=&quot;Part IV 도구&quot;&gt;&lt;/a&gt;Part IV 도구&lt;/h1&gt;&lt;h2 id=&quot;CHAPTER-16-버전-관리와-브랜치-관리&quot;&gt;&lt;a href
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Part-IV-도구"><a href="#Part-IV-도구" class="headerlink" title="Part IV 도구"></a>Part IV 도구</h1><h2 id="CHAPTER-16-버전-관리와-브랜치-관리"><a href="#CHAPTER-16-버전-관리와-브랜치-관리" class="headerlink" title="CHAPTER 16 버전 관리와 브랜치 관리"></a>CHAPTER 16 버전 관리와 브랜치 관리</h2><p>버전 관리 시스템은 가장 널리 쓰이는 소프트웨어 엔지니어링 도구</p><p>트렁크 기반 개발(Trunk-Based Development)이 확장성이 뛰어나기에 그 이유와 함깨 몇가지 제안</p><h3 id="버전-관리란"><a href="#버전-관리란" class="headerlink" title="버전 관리란?"></a>버전 관리란?</h3><p>VCS(Version Control System)은 파일의 시간에 따른 변경 기록을 추적하는 시스템<br>합의된 단일 진실 공급원(Single Source of Truth)을 제공</p><h4 id="버전관리가-중요한-이유"><a href="#버전관리가-중요한-이유" class="headerlink" title="버전관리가 중요한 이유"></a>버전관리가 중요한 이유</h4><p>버전관리는 디지털 협업이라는 새로운 업무방싱을 발전시키는 과정에서 함께 진화했다</p><p>소프트웨어 엔지니어링은 프로그래밍에 시간의 흐름을 통합한 개념이다<br>소스 코드 생성과 제품을 장기간 지속 관리하는것은 다르게 보고 있다</p><p>버전을 관리하려면 비용이 든다 하지만 이 비용은 아주 저렴하다</p><h4 id="중앙집중형-VCS-vs-분산형-VCS"><a href="#중앙집중형-VCS-vs-분산형-VCS" class="headerlink" title="중앙집중형 VCS vs 분산형 VCS"></a>중앙집중형 VCS vs 분산형 VCS</h4><ul><li>중앙집중형 VCS<ul><li>단 하나의 중앙 리포지터리를 이용하는 모델</li><li>CVS, Subversion</li></ul></li><li>분산형 VCS<ul><li>각 개발자가 자신의 로컬 리포지터리를 가지고 중앙 리포지터리와 동기화하는 모델</li><li>Git, Mercurial</li></ul></li><li>진실 공급원<ul><li>중앙집중형 VCS는 진싱 공급원이라는 개념을 사용한다</li><li>분산형 VCS는 진실 공급원이라는 개념을 사용하지 않는다<h4 id="버전-관리-VS-의존성-관리"><a href="#버전-관리-VS-의존성-관리" class="headerlink" title="버전 관리 VS 의존성 관리"></a>버전 관리 VS 의존성 관리</h4>차이점</li></ul></li><li>VCS는 주로 코드를 어떻게 관리할지를 다루고 대체로 훨씬 세세하게 관리</li><li>의존성 관리는 훨씬 어렵다 다른 조직에서 통제하는 프로젝트들을 관리해야 하기 때문</li></ul><h3 id="브랜치-관리"><a href="#브랜치-관리" class="headerlink" title="브랜치 관리"></a>브랜치 관리</h3><p>상이한 버전들을 관리하는 방식을 통틀어 관리 방식을 통틀어 브랜치 관리가고 한다</p><ul><li>진행 중인 작업은 브랜치와 비슷하다</li><li>개발 브랜치<ul><li>구현은 다했지만 커멋하지 않았어요 와 이제부터 이코드 기준으로 개발하세요의 중간단계</li><li>개발 브랜치에 의존하는 방식은 확장하는 한계가 있다</li></ul></li><li>릴리즈 브랜치<ul><li>하루에도 몇번씩 릴리스할 수 있는 지속적 배포가 잘 자리 잡은 조직에서는 대체로 릴리스 브랜치를 건너 뛴다</li></ul></li></ul><h3 id="버전-관리-구글"><a href="#버전-관리-구글" class="headerlink" title="버전 관리 @ 구글"></a>버전 관리 @ 구글</h3><p>구글의 소스 코드 대부분은 하나의 리포지터리 즉 모노리포에서 관리 됨</p><ul><li>원 버전<ul><li>모든 의존성의 우리 리포지터리에 담겨 있고 각 의존성은 단하나의 안정된 버전만 존재해야 됨</li></ul></li><li>시나리오 여러 버전을 허용한다면<ul><li>여러 버전에 의존하더라고 실행 파일이 올바르게 작동되도록 해주는 트릭이 사용된다(쉐이딩)</li></ul></li><li>원버전 규칙<ul><li>개발자가 이 구성요소는 어떤 버전을 사용해야 하죠?라고 묻는 상황을 만들지 않아야 된다</li></ul></li><li>장수 브랜치는 웬만하면 금지<ul><li>빌드 호라이즌 정책</li><li>프로덕션 환경에서 구동 중인 모든 제품은 최대 6개월 안에 다시 빌드해야 재배포 해야 됨</li></ul></li><li>릴리즈 브런치는?<ul><li>많은 팀이 릴리즈 브랜치를 이용하고 최소한의 수정만 반영한다</li></ul></li></ul><h3 id="모노리포-단일-리포지터리"><a href="#모노리포-단일-리포지터리" class="headerlink" title="모노리포(단일 리포지터리)"></a>모노리포(단일 리포지터리)</h3><p>모노리포의 장점</p><ul><li>원-버전을 고수하기가 쉽다.</li><li>공식버전이나 중심 역할을 하는 리포지터리를 찾는 과정이 불필요하다</li><li>한 마디로 우리가 따르는 모노리포 방식이 모든 이에게 정답일 수는 없다<h3 id="버전-관리의-미래"><a href="#버전-관리의-미래" class="headerlink" title="버전 관리의 미래"></a>버전 관리의 미래</h3>선택에는 대가가 따른다</li></ul><h1 id="참조"><a href="#참조" class="headerlink" title="참조"></a>참조</h1><hr><ul><li><a href="https://www.yes24.com/Product/Goods/109182479">구글 엔지니어는 이렇게 일한다</a></li></ul>]]></content:encoded>
      
      <comments>https://sejoung.github.io/2024/08/2024-08-12-Software_Engineering_at_Google_CHAPTER_16/#disqus_thread</comments>
    </item>
    
    <item>
      <title>CHAPTER 15 폐기</title>
      <link>https://sejoung.github.io/2024/08/2024-08-09-Software_Engineering_at_Google_CHAPTER_15/</link>
      <guid>https://sejoung.github.io/2024/08/2024-08-09-Software_Engineering_at_Google_CHAPTER_15/</guid>
      <pubDate>Fri, 09 Aug 2024 00:50:00 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;Part-III-프로세스&quot;&gt;&lt;a href=&quot;#Part-III-프로세스&quot; class=&quot;headerlink&quot; title=&quot;Part III 프로세스&quot;&gt;&lt;/a&gt;Part III 프로세스&lt;/h1&gt;&lt;h2 id=&quot;CHAPTER-15-폐기&quot;&gt;&lt;a hre
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Part-III-프로세스"><a href="#Part-III-프로세스" class="headerlink" title="Part III 프로세스"></a>Part III 프로세스</h1><h2 id="CHAPTER-15-폐기"><a href="#CHAPTER-15-폐기" class="headerlink" title="CHAPTER 15 폐기"></a>CHAPTER 15 폐기</h2><p>모든 시스템은 나이를 먹습니다.<br>소프트웨어는 디지털 자산이라서 물리적인 비트들 자체가 늙지 않는다.</p><p>이주를 순차적으로 시켜서 낡은 시스템을 완전히 걷어내는 과정은 폐기라 한다</p><h3 id="폐기시키는-이유"><a href="#폐기시키는-이유" class="headerlink" title="폐기시키는 이유"></a>폐기시키는 이유</h3><p>기본전재는 코드는 자산이 아니라 부채다 라는 기본 전재에서 시작함<br>코드가 부채가 아니라 자산이면 폐기 시킬이유가 어디 있을까?</p><p>코드는 자체는 가치를 창출하지 않는다 가치를 만들어내는 건 바로 기능<br>사용자 요구사항에 부합하는 기능은 자산이다</p><p>폐기대상을 신중하게 선택한 다음 집중해서 빠르게 완료하는게 중요</p><h3 id="폐기는-왜-그리-어려운가"><a href="#폐기는-왜-그리-어려운가" class="headerlink" title="폐기는 왜 그리 어려운가?"></a>폐기는 왜 그리 어려운가?</h3><p>하이럼의 법칙에 의해 시스템은 사용자 수가 늘수록 설계자가 예상하지 못한 전에 본 적 없는 방식으로 이용될 가능성이 높음</p><p>되니깐 쓰는 기능과 함께 이를 잘 활용하던 수많은 사용자까지 한꺼번에 떼어내어버린다</p><p>옛시스템에 대한 애착이 의외의 저항이 될수 도 있다</p><p>정치라는 관문도 통과 신기능 개발이 지연된다면 폐기시키는 편이 오히려 이득임을 이해관계자들에게 납득시키기가 더욱 어렵다</p><ul><li>설계 단계에서의 폐기<ul><li>내 제품의 고객이 잠재적인 대체품으로 이주하기가 얼마나 쉬울까?</li><li>내 시스템을 한 부분씩 점진적으로 교체하려면 어떻게 해야 할까?</li></ul></li></ul><h3 id="폐기-유형"><a href="#폐기-유형" class="headerlink" title="폐기 유형"></a>폐기 유형</h3><ul><li>권고 폐기<ul><li>희망 폐기</li></ul></li><li>강제 폐기</li><li>폐기 경고<ul><li>실행 가능성 과 적시성 <h3 id="폐기-프로세스-관리"><a href="#폐기-프로세스-관리" class="headerlink" title="폐기 프로세스 관리"></a>폐기 프로세스 관리</h3></li></ul></li><li>프로세스 소유자</li><li>마일스톤</li><li>폐기 도구<ul><li>발견</li><li>마이그레이션</li><li>퇴행 방지</li></ul></li></ul><h1 id="참조"><a href="#참조" class="headerlink" title="참조"></a>참조</h1><hr><ul><li><a href="https://www.yes24.com/Product/Goods/109182479">구글 엔지니어는 이렇게 일한다</a></li></ul>]]></content:encoded>
      
      <comments>https://sejoung.github.io/2024/08/2024-08-09-Software_Engineering_at_Google_CHAPTER_15/#disqus_thread</comments>
    </item>
    
    <item>
      <title>CHAPTER 14 더 큰 테스트</title>
      <link>https://sejoung.github.io/2024/07/2024-07-24-Software_Engineering_at_Google_CHAPTER_14/</link>
      <guid>https://sejoung.github.io/2024/07/2024-07-24-Software_Engineering_at_Google_CHAPTER_14/</guid>
      <pubDate>Wed, 24 Jul 2024 00:50:00 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;Part-III-프로세스&quot;&gt;&lt;a href=&quot;#Part-III-프로세스&quot; class=&quot;headerlink&quot; title=&quot;Part III 프로세스&quot;&gt;&lt;/a&gt;Part III 프로세스&lt;/h1&gt;&lt;h2 id=&quot;CHAPTER-14-더-큰-테스트&quot;&gt;&lt;
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Part-III-프로세스"><a href="#Part-III-프로세스" class="headerlink" title="Part III 프로세스"></a>Part III 프로세스</h1><h2 id="CHAPTER-14-더-큰-테스트"><a href="#CHAPTER-14-더-큰-테스트" class="headerlink" title="CHAPTER 14 더 큰 테스트"></a>CHAPTER 14 더 큰 테스트</h2><p>테스트들이 자원 낭비가 아닌 값진 자산이 되게끔 하려면 또 다른 난관을 극복해야 된다</p><h3 id="더-큰-테스트란"><a href="#더-큰-테스트란" class="headerlink" title="더 큰 테스트란?"></a>더 큰 테스트란?</h3><p>더 큰 테스트의 특징</p><ul><li>느릴 수 있다</li><li>밀폐되지 않을 수 있다</li><li>비결정적일 수 있다</li></ul><h4 id="충실성"><a href="#충실성" class="headerlink" title="충실성"></a>충실성</h4><p>테스트가 대상의 실제 행위를 얼마나 충실하게 반영했는냐를 나타내는 속성</p><h4 id="단위-테스트가-손-대기-어려운-영역"><a href="#단위-테스트가-손-대기-어려운-영역" class="headerlink" title="단위 테스트가 손 대기 어려운 영역"></a>단위 테스트가 손 대기 어려운 영역</h4><ul><li>부적확한 테스트 대역</li><li>설정 문제</li><li>과부하 시 나타나는 문제</li><li>예기치 못한 동작 입력 부작용</li><li>창발적 행위와 진공 효과</li></ul><h4 id="더-큰-테스트를-만들지-않는-이유"><a href="#더-큰-테스트를-만들지-않는-이유" class="headerlink" title="더 큰 테스트를 만들지 않는 이유"></a>더 큰 테스트를 만들지 않는 이유</h4><ul><li>높은 신뢰성</li><li>빠른 속도</li><li>높은 확장성</li></ul><h3 id="더-큰-테스트-구글"><a href="#더-큰-테스트-구글" class="headerlink" title="더 큰 테스트 @ 구글"></a>더 큰 테스트 @ 구글</h3><ul><li>더 큰 테스트와 수명<ul><li>아이스크림콘 테스트 안티패턴</li></ul></li><li>구글 규모에서의 더 큰 테스트<ul><li>통합 테스트라 하더라도 가능한 작을수록 좋습니다<h3 id="큰-테스트의-구조"><a href="#큰-테스트의-구조" class="headerlink" title="큰 테스트의 구조"></a>큰 테스트의 구조</h3></li></ul></li></ul><ol><li>테스트 대상 시스템 확보</li><li>필요한 테스트 데이터 준비</li><li>대상 시스템을 이용해 동작수행</li><li>행위 검증</li></ol><ul><li>테스트 대상 시스템<ul><li>밀폐성</li><li>충실성</li><li>단일 프로세스 SUT</li><li>단일 머신 SUT</li><li>다중 머신 SUT</li><li>공유환경</li><li>하이브리드</li></ul></li><li>밀폐된 SUT의 이점<ul><li>큰 테스트에서 SUT는 테스트 신뢰성을 떨어뜨리고 피드백 시간을 늘리는 주범이 될 수 있습니다</li></ul></li><li>쿤제 경계에서 SUT 크기 줄이기<ul><li>테스트 하다 보면 웬만해서는 피해야할 고통스러운 경계가 존재함</li></ul></li><li>기록&#x2F;재생 프록시<ul><li>비결정성을 없애기 위해 매칭기를 이용하여 요청을 보고 기대하는 응답과 일치시킨다</li></ul></li><li>테스트 데이터<ul><li>시드 데이터</li><li>테스트 트래픽</li><li>도메인 데이터</li><li>현실적인 기준선</li><li>데이터 기록 API</li><li>손수 가공한 데이터</li><li>복사한 데이터</li><li>샘플링한 데이터</li></ul></li><li>검증<ul><li>수동 검증</li><li>단정문</li><li>A&#x2F;B 테스트</li></ul></li></ul><h3 id="더-큰-테스트-유형"><a href="#더-큰-테스트-유형" class="headerlink" title="더 큰 테스트 유형"></a>더 큰 테스트 유형</h3><ul><li>하나 이상의 바이너리에 대한 기능 테스트<ul><li>SUT : 밀폐된 단일 머신 혹은 격리된 클라우드 배포</li><li>데이터 : 수동 생성</li><li>검증 방식 : 단정문</li></ul></li><li>브라우저와 기기 테스트</li><li>성능, 부하, 스트레스 테스트<ul><li>SUT : 격리된 클라우드에 배포</li><li>데이터 : 수동 생성 혹은 프로덕션 환경에서 복사</li><li>검증 방식 : 차이 비교</li></ul></li><li>배포 설정 테스트<ul><li>SUT : 밀폐된 단일 머신 혹은 격리된 클라우드 배포</li><li>데이터 : 없음</li><li>검증 방식 : 단정문(비정상 종료는 하지 않음)</li><li>스모크 테스트</li></ul></li><li>탐색적 테스팅<ul><li>한계</li><li>버그 파티</li></ul></li><li>A&#x2F;B 차이(회귀) 테스트</li><li>사용자 인수 테스트</li><li>프로버와 카나리 분석</li><li>재해 복구와 카오스 엔지니어링</li><li>사용자 평가</li></ul><h3 id="큰-테스트와-개발자-워크플로"><a href="#큰-테스트와-개발자-워크플로" class="headerlink" title="큰 테스트와 개발자 워크플로"></a>큰 테스트와 개발자 워크플로</h3><ul><li>큰테스트 작성하기</li><li>큰테스트 수행하기<ul><li>테스트 속도 개선하기</li><li>불규칙한 결과에서 벗어나기</li><li>이해되는 테스트 만들기</li></ul></li><li>큰 테스트의 소유권<ul><li>반듯이 소유자가 문서로 기록되어 있어야 함</li></ul></li></ul><h1 id="참조"><a href="#참조" class="headerlink" title="참조"></a>참조</h1><hr><ul><li><a href="https://www.yes24.com/Product/Goods/109182479">구글 엔지니어는 이렇게 일한다</a></li></ul>]]></content:encoded>
      
      <comments>https://sejoung.github.io/2024/07/2024-07-24-Software_Engineering_at_Google_CHAPTER_14/#disqus_thread</comments>
    </item>
    
    <item>
      <title>CHAPTER 13 테스트 대역</title>
      <link>https://sejoung.github.io/2024/07/2024-07-09-Software_Engineering_at_Google_CHAPTER_13/</link>
      <guid>https://sejoung.github.io/2024/07/2024-07-09-Software_Engineering_at_Google_CHAPTER_13/</guid>
      <pubDate>Tue, 09 Jul 2024 00:45:00 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;Part-III-프로세스&quot;&gt;&lt;a href=&quot;#Part-III-프로세스&quot; class=&quot;headerlink&quot; title=&quot;Part III 프로세스&quot;&gt;&lt;/a&gt;Part III 프로세스&lt;/h1&gt;&lt;h2 id=&quot;CHAPTER-13-테스트-대역&quot;&gt;&lt;a
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="Part-III-프로세스"><a href="#Part-III-프로세스" class="headerlink" title="Part III 프로세스"></a>Part III 프로세스</h1><h2 id="CHAPTER-13-테스트-대역"><a href="#CHAPTER-13-테스트-대역" class="headerlink" title="CHAPTER 13 테스트 대역"></a>CHAPTER 13 테스트 대역</h2><p>단순한 코드라면 단위 테스트 작성이 전혀 부담되지 않습니다 하지만 대상 코드가 복잡해질수록 테스트를 작성하기도 어려워진다</p><p>테스트 대역은 실제 구현 대신 사용 할 수 있는 객체나 함수를 말한다</p><h3 id="테스트-대역이-소프트웨어-개발에-미치는-영향"><a href="#테스트-대역이-소프트웨어-개발에-미치는-영향" class="headerlink" title="테스트 대역이 소프트웨어 개발에 미치는 영향"></a>테스트 대역이 소프트웨어 개발에 미치는 영향</h3><ul><li>테스트 용이성</li><li>적용 가능성</li><li>충실성</li></ul><h3 id="테스트-대역-구글"><a href="#테스트-대역-구글" class="headerlink" title="테스트 대역 @ 구글"></a>테스트 대역 @ 구글</h3><p>품질을 높은 예도 많지만 잘못 할용하여 역효과를 낸 예도 못지 않다</p><ul><li>엔지니어가 관행들에 익숙하지 않는다</li><li>코드베이스가 관행을 따르기에 적합하지 않게 작성되어 있기도 한다</li></ul><h3 id="기본-개념"><a href="#기본-개념" class="headerlink" title="기본 개념"></a>기본 개념</h3><ul><li>테스트 대역 예</li><li>이어주기<ul><li>테스트 하기 쉽다</li><li>의존성 주입</li></ul></li><li>모의 객체 프레임 워크</li></ul><h3 id="테스트-대역-활용-기법"><a href="#테스트-대역-활용-기법" class="headerlink" title="테스트 대역 활용 기법"></a>테스트 대역 활용 기법</h3><ul><li>속이기(가짜 객체)</li><li>뭉개기(스텁)</li><li>상호작용 테스트하기</li></ul><h3 id="실제-구현"><a href="#실제-구현" class="headerlink" title="실제 구현"></a>실제 구현</h3><ul><li>실제 구현을 선호하는 테스트 방식을 고전적 테스트</li><li>모의 객체 프레임워크를 선호하는 테스트 방식은 모의 객체 중심주의 테스트</li><li>갹리 보단 현실성을 우선하자</li><li>실제 구현을 사용할지 결정하기<ul><li>실행시간</li><li>결정성</li><li>의존성 생성</li></ul></li></ul><h3 id="속이기-가짜-객체"><a href="#속이기-가짜-객체" class="headerlink" title="속이기(가짜 객체)"></a>속이기(가짜 객체)</h3><ul><li>가짜 객체가 중요한 이유</li><li>가짜 객체를 작성해야 할때</li><li>가자 객체의 충실성</li><li>가짜 객체도 테스트 해야</li><li>가짜 객체를 이용할 수 없다면<h3 id="뭉개기-스텁"><a href="#뭉개기-스텁" class="headerlink" title="뭉개기(스텁)"></a>뭉개기(스텁)</h3></li><li>스텁 과용의 위험성<ul><li>불명확해진다</li><li>깨지기 쉬워진다</li><li>테스트 효과가 감소한다</li></ul></li><li>스텁이 적합한경우<ul><li>대상 시스템을 원하는 상태로 변경하려 할 때 제격</li></ul></li></ul><h3 id="상호작용-테스트하기"><a href="#상호작용-테스트하기" class="headerlink" title="상호작용 테스트하기"></a>상호작용 테스트하기</h3><ul><li>상호작용 테스트보다 상태 테스트를 우선하자<ul><li>변경 검충 테스트</li></ul></li><li>상호작용 테스트가 적합한 경우<ul><li>상태 변경 함수일 경우에만 상호작용 테스트를 우선 고려하자</li><li>너무 상세한 테스트는 피하자</li></ul></li></ul><h1 id="참조"><a href="#참조" class="headerlink" title="참조"></a>참조</h1><hr><ul><li><a href="https://www.yes24.com/Product/Goods/109182479">구글 엔지니어는 이렇게 일한다</a></li></ul>]]></content:encoded>
      
      <comments>https://sejoung.github.io/2024/07/2024-07-09-Software_Engineering_at_Google_CHAPTER_13/#disqus_thread</comments>
    </item>
    
  </channel>
</rss>
