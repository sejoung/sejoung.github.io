<!DOCTYPE html><html lang="lang"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="Diffusion Models 이란"><meta name="keywords" content="Diffusion"><meta name="author" content="sejoung"><meta name="copyright" content="sejoung"><title>Diffusion Models 이란 | 폭간의 기술블로그</title><link rel="shortcut icon" href="../../../my-favicon.ico"><link rel="stylesheet" href="../../../css/index.css?version=1.7.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css?version=1.7.0"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><script async src="https://www.googletagmanager.com/gtag/js?id=G-NVRTGLD8RZ"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-NVRTGLD8RZ');</script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script><meta name="generator" content="Hexo 5.4.2"></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="true"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Diffusion-Models-%EC%9D%B4%EB%9E%80"><span class="toc-number">1.</span> <span class="toc-text">Diffusion Models 이란?</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%ED%99%95%EC%82%B0-%EB%AA%A8%EB%8D%B8%EC%9D%B4%EB%9E%80"><span class="toc-number">1.1.</span> <span class="toc-text">확산 모델이란?</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%EC%88%9C%EB%B0%A9%ED%96%A5-%ED%99%95%EC%82%B0-%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4-Forward-diffusion-process"><span class="toc-number">1.1.1.</span> <span class="toc-text">순방향 확산 프로세스 (Forward diffusion process)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%ED%99%95%EB%A5%A0%EC%A0%81-%EA%B2%BD%EC%82%AC-Langevin-%EC%97%AD%ED%95%99%EA%B3%BC%EC%9D%98-%EC%97%B0%EA%B2%B0"><span class="toc-number">1.1.2.</span> <span class="toc-text">확률적 경사 Langevin 역학과의 연결</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EC%97%AD%ED%99%95%EC%82%B0-%EA%B3%BC%EC%A0%95-Reverse-diffusion-process"><span class="toc-number">1.1.3.</span> <span class="toc-text">역확산 과정(Reverse diffusion process)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%ED%99%95%EC%82%B0-%EB%AA%A8%EB%8D%B8-%EC%83%98%ED%94%8C%EB%A7%81-%EC%86%8D%EB%8F%84-%ED%96%A5%EC%83%81"><span class="toc-number">1.2.</span> <span class="toc-text">확산 모델 샘플링 속도 향상</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Conditioned-Generation"><span class="toc-number">1.3.</span> <span class="toc-text">Conditioned Generation</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Classifier-Guided-Diffusion"><span class="toc-number">1.3.1.</span> <span class="toc-text">Classifier Guided Diffusion</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Classifier-Free-Guidance"><span class="toc-number">1.3.2.</span> <span class="toc-text">Classifier-Free Guidance</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Scale-up-Generation-Resolution-and-Quality"><span class="toc-number">1.4.</span> <span class="toc-text">Scale up Generation Resolution and Quality</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%EB%B9%A0%EB%A5%B8-%EC%9A%94%EC%95%BD"><span class="toc-number">1.5.</span> <span class="toc-text">빠른 요약</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%EC%B0%B8%EC%A1%B0"><span class="toc-number">2.</span> <span class="toc-text">참조</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="https://avatars0.githubusercontent.com/u/4936005?s=400&amp;u=a679b941fe377418e7e4efcf916c6a636d7178ee&amp;v=4"></div><div class="author-info__name text-center">sejoung</div><div class="author-info__description text-center">잘정리하자</div><div class="follow-button"><a target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/sejoung">Follow Me</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="../../../archives"><span class="pull-left">Articles</span><span class="pull-right">721</span></a><a class="author-info-articles__tags article-meta" href="../../../tags"><span class="pull-left">Tags</span><span class="pull-right">776</span></a><a class="author-info-articles__categories article-meta" href="../../../categories"><span class="pull-left">Categories</span><span class="pull-right">74</span></a></div><hr><div class="author-info-links"><div class="author-info-links__title text-center">Links</div><a class="author-info-links__name text-center" target="_blank" rel="external nofollow noopener noreferrer" href="https://blog.naver.com/sanaes">naverblog</a><a class="author-info-links__name text-center" target="_blank" rel="external nofollow noopener noreferrer" href="https://www.linkedin.com/in/sanaes/">linkedin</a><a class="author-info-links__name text-center" target="_blank" rel="external nofollow noopener noreferrer" href="https://www.slideshare.net/sejoung">slideshare</a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://upload.wikimedia.org/wikipedia/commons/thumb/0/09/Van_Gogh_-_Terrasse_des_Caf%C3%A9s_an_der_Place_du_Forum_in_Arles_am_Abend1.jpeg/1024px-Van_Gogh_-_Terrasse_des_Caf%C3%A9s_an_der_Place_du_Forum_in_Arles_am_Abend1.jpeg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="../../../index.html">폭간의 기술블로그</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span><span class="pull-right"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> Search</span></a></span></div><div id="post-info"><div id="post-title">Diffusion Models 이란</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-10-30</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="../../../categories/Machine-Learning/">Machine Learning</a><span class="post-meta__separator">|</span><i class="fa fa-comment-o post-meta__icon" aria-hidden="true"></i><a href="#disqus_thread"><span class="disqus-comment-count" data-disqus-identifier="2023/10/2023-10-30-What_are_Diffusion_Models/"></span></a></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><h1 id="Diffusion-Models-이란"><a href="#Diffusion-Models-이란" class="headerlink" title="Diffusion Models 이란?"></a>Diffusion Models 이란?</h1><p><a target="_blank" rel="external nofollow noopener noreferrer" href="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/">diffusion-models</a> 이글을 번역한 내용 입니다</p>
<p>지금까지 세 가지 유형의 생성 모델, 즉 GAN, VAE 및 흐름 기반(FLOW-based) 모델에 대해 작성했습니다.<br>이 모델들은 고품질 샘플을 생성하는 데 큰 성공을 거두었지만 각각 몇 가지 한계가 있습니다.<br>GAN 모델은 적대적 훈련 특성으로 인해 잠재적으로 불안정한 훈련과 생성의 다양성이 떨어지는 것으로 알려져 있습니다.<br>VAE는 대리 손실에 의존합니다.<br>FLOW 모델은 가역적 변환을 구축하기 위해 특수 아키텍처를 사용해야 합니다.</p>
<p>확산 모델(Diffusion models)은 비평형 열역학(non-equilibrium thermodynamics)에서 영감을 얻었습니다.<br>확산 단계의 마르코프 체인(Markov chain)을 정의하여 데이터에 무작위 노이즈를 천천히 추가한 다음,<br>확산 과정을 역으로 학습하여 노이즈에서 원하는 데이터 샘플을 구성하는 방법을 학습합니다.<br>확산 모델은 VAE 또는 흐름 모델과 달리 고정된 절차로 학습되며 잠재 변수는 높은 차원(원본 데이터와 동일)을 갖습니다.</p>
<p><img src="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/generative-overview.png" alt="그림 1. 다양한 유형의 생성 모델 개요."></p>
<h2 id="확산-모델이란"><a href="#확산-모델이란" class="headerlink" title="확산 모델이란?"></a>확산 모델이란?</h2><p>Several diffusion-based generative models have been proposed with similar ideas underneath, including diffusion probabilistic models <a target="_blank" rel="external nofollow noopener noreferrer" href="https://arxiv.org/abs/1503.03585">(Sohl-Dickstein et al., 2015)</a>,<br>noise-conditioned score network <a target="_blank" rel="external nofollow noopener noreferrer" href="https://arxiv.org/abs/1907.05600">(NCSN; Yang &amp; Ermon, 2019)</a>,<br>and denoising diffusion probabilistic models <a target="_blank" rel="external nofollow noopener noreferrer" href="https://arxiv.org/abs/2006.11239">(DDPM; Ho et al. 2020)</a>.</p>
<h3 id="순방향-확산-프로세스-Forward-diffusion-process"><a href="#순방향-확산-프로세스-Forward-diffusion-process" class="headerlink" title="순방향 확산 프로세스 (Forward diffusion process)"></a>순방향 확산 프로세스 (Forward diffusion process)</h3><p>실제 데이터 분포에서 샘플링된 데이터 포인트가 주어지면<br>샘플에 소량의 가우시안(Gaussian) 노이즈를 추가하는 순방향 확산 프로세스를 정의해 보겠습니다.<br>T 단계, 시끄러운 샘플 시퀀스 생성  x…x 단계 크기는 분산 일정에 의해 제어됩니다.<br>데이터 샘플 점차적으로 단계적으로 구별되는 특징을 잃습니다. 더 커집니다. 결국 언제 등방성 가우스 분포와 동일합니다.</p>
<p><img src="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/DDPM.png" alt="그림 2. 노이즈를 천천히 추가(제거)하여 샘플을 생성하는 순방향(역방향) 확산 과정의 마르코프 체인. (이미지 출처: Ho et al. 2020, 몇 가지 추가 주석 포함)"></p>
<h3 id="확률적-경사-Langevin-역학과의-연결"><a href="#확률적-경사-Langevin-역학과의-연결" class="headerlink" title="확률적 경사 Langevin 역학과의 연결"></a>확률적 경사 Langevin 역학과의 연결</h3><p>Langevin 역학은 분자 시스템을 통계적으로 모델링하기 위해 개발된 물리학의 개념입니다.<br>확률적 경사하강법과 결합된 Stochastic Gradient Langevin 역학 <a target="_blank" rel="external nofollow noopener noreferrer" href="https://www.stats.ox.ac.uk/~teh/research/compstats/WelTeh2011a.pdf">Bayesian Learning via Stochastic Gradient Langevin Dynamics</a><br>은 확률 밀도에서 샘플을 생성할 수 있습니다.</p>
<h3 id="역확산-과정-Reverse-diffusion-process"><a href="#역확산-과정-Reverse-diffusion-process" class="headerlink" title="역확산 과정(Reverse diffusion process)"></a>역확산 과정(Reverse diffusion process)</h3><p>위의 과정을 반대로 하고 샘플을 추출할 수 있다면 가우스 노이즈 입력에서 실제 샘플을 다시 생성할 수 있습니다. 안타깝게도 쉽게 추정할 수는 없습니다.<br>전체 데이터 세트를 사용해야 하므로 모델을 학습해야 하기 때문입니다. 역확산 프로세스를 실행하기 위해 이러한 조건부 확률을 근사화합니다 .</p>
<p><img src="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/diffusion-example.png" alt="그림 3. 2D 스위스롤 데이터 모델링을 위한 확산 모델 훈련의 예. (이미지 출처: Sohl-Dickstein 외, 2015 )"></p>
<h2 id="확산-모델-샘플링-속도-향상"><a href="#확산-모델-샘플링-속도-향상" class="headerlink" title="확산 모델 샘플링 속도 향상"></a>확산 모델 샘플링 속도 향상</h2><p>역확산 과정의 마르코프 체인을 따라 DDPM에서 샘플을 생성하는 것은 다음과 같이 매우 느립니다.<br>최대 1단계 또는 수천 단계일 수 있습니다. Song et al. 의 한 데이터 포인트 . 2020 :<br>“예를 들어 DDPM에서 32 × 32 크기의 이미지 50,000개를 샘플링하는 데 약 20시간이 걸리지만 Nvidia 2080 Ti GPU의 GAN에서는 1분도 채 걸리지 않습니다.”</p>
<p>간단한 방법 중 하나는 샘플링 업데이트를 매번 수행하여 점진적인 샘플링 일정( Nichol &amp; Dhariwal, 2021 )을 실행하는 것입니다.</p>
<p>DDPM과 비교하여 DDIM은 다음을 수행할 수 있습니다.</p>
<ul>
<li>훨씬 적은 수의 단계를 사용하여 고품질 샘플을 생성합니다.</li>
<li>생성 프로세스는 결정론적이므로 “일관성” 속성을 갖습니다. 즉, 동일한 잠재 변수에 대해 조건화된 여러 샘플이 유사한 상위 수준 특징을 가져야 함을 의미합니다.</li>
<li>일관성으로 인해 DDIM은 잠재 변수에서 의미상 의미 있는 보간을 수행할 수 있습니다.</li>
</ul>
<p>잠재 확산 모델(LDM ; Rombach &amp; Blattmann, et al. 2022 )은 픽셀 공간 대신 잠재 공간에서 확산 프로세스를 실행하므로 훈련 비용이 낮아지고 추론 속도가 빨라집니다.<br>이미지의 대부분의 비트가 지각적 세부 사항에 기여하고 공격적인 압축 후에도 의미론적 및 개념적 구성이 여전히 남아 있다는 관찰에 의해 동기가 부여되었습니다.<br>LDM은 먼저 자동 인코더로 픽셀 수준 중복성을 제거한 다음 학습된 잠재성에 대한 확산 프로세스를 통해 의미론적 개념을 조작&#x2F;생성하여 생성 모델링 학습을 통해 지각 압축과<br>의미론적 압축을 느슨하게 분해합니다.</p>
<p>지각적 압축 프로세스는 오토인코더 모델에 의존합니다. 인코더 입력 이미지를 압축하는 데 사용됩니다.<br>더 작은 2D 잠재 벡터로 여기서 다운샘플링 속도는. 그런 다음 디코더  잠재 벡터로부터 이미지를 재구성합니다.<br>이 논문에서는 잠재 공간에서 임의로 높은 분산을 방지하기 위해 오토인코더 훈련에서 두 가지 유형의 정규화를 탐구했습니다.</p>
<ul>
<li>KL-reg: 학습된 잠재성에 대한 표준 정규 분포에 대한 작은 KL 페널티로, VAE 와 유사합니다 .</li>
<li>VQ-reg: VQVAE 와 같이 디코더 내에서 벡터 양자화 계층을 사용 하지만 양자화 계층은 디코더에 의해 흡수됩니다.</li>
</ul>
<p>확산 및 노이즈 제거 프로세스는 잠재 벡터에서 발생합니다.<br>잡음 제거 모델은 이미지 생성을 위한 유연한 조건화 정보(예: 클래스 레이블, 의미 지도, 이미지의 흐릿한 변형)를<br>처리하기 위해 교차 주의 메커니즘이 강화된 시간 조건화된 U-Net입니다.<br>이 디자인은 교차 주의 메커니즘을 사용하여 다양한 양식의 표현을 모델에 융합하는 것과 동일합니다.<br>각 유형의 조건화 정보는 도메인별 인코더와 쌍을 이룹니다. 조건 입력을 투영하기 위해 교차 주의 구성 요소에 매핑될 수 있는 중간 표현으로,</p>
<p><img src="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/latent-diffusion-arch.png" alt="그림 9. 잠재 확산 모델의 구조. (이미지 출처: Rombach &amp; Blattmann, et al. 2022 )"></p>
<h2 id="Conditioned-Generation"><a href="#Conditioned-Generation" class="headerlink" title="Conditioned Generation"></a>Conditioned Generation</h2><p>ImageNet 데이터세트와 같은 조건부 정보가 있는 이미지에 대해 생성 모델을 훈련하는 동안 클래스 레이블이나 설명 텍스트를 기준으로 조건부 샘플을 생성하는 것이 일반적입니다.</p>
<h3 id="Classifier-Guided-Diffusion"><a href="#Classifier-Guided-Diffusion" class="headerlink" title="Classifier Guided Diffusion"></a>Classifier Guided Diffusion</h3><p>클래스 정보를 확산 프로세스에 명시적으로 통합하기 위해 Dhariwal &amp; Nichol(2021)은 분류기를 교육했습니다.<br>시끄러운 이미지에 그리고 그라디언트를 사용하세요 컨디셔닝 정보에 대한 확산 샘플링 프로세스를 안내합니다.<br>(예: 대상 클래스 레이블) 노이즈 예측을 변경합니다. 그것을 기억해 공동 분포에 대한 점수 함수를 작성할 수 있습니다.  다음과 같이,</p>
<p>따라서 새로운 분류기 안내 예측기는 다음과 같은 형식을 취합니다.</p>
<p>분류자 지침의 강도를 제어하기 위해 가중치를 추가할 수 있습니다.</p>
<p>결과적으로 제거된 확산 모델 ( ADM )과 추가 분류자 지침이 있는 모델( ADM-G )은 SOTA 생성 모델(예: BigGAN)보다 더 나은 결과를 얻을 수 있습니다.</p>
<p>또한 U-Net 아키텍처를 일부 수정하여 <a target="_blank" rel="external nofollow noopener noreferrer" href="https://arxiv.org/abs/2105.05233">Diffusion Models Beat GANs on Image Synthesis</a>은 확산 모델을 사용하는 GAN보다 더 나은 성능을 보여주었습니다.<br>아키텍처 수정에는 더 큰 모델 깊이&#x2F;너비, 더 많은 주의 헤드, 다중 해상도 주의, 업&#x2F;다운샘플링을 위한 BigGAN 잔여 블록, 잔여 연결 재조정이 포함됩니다.</p>
<h3 id="Classifier-Free-Guidance"><a href="#Classifier-Free-Guidance" class="headerlink" title="Classifier-Free Guidance"></a>Classifier-Free Guidance</h3><p>독립적인 분류기가 없는 경우 , 조건부 확산 모델과 무조건 확산 모델의 점수를 통합하여 조건부 확산 단계를 실행하는 것이 여전히 가능합니다( Ho &amp; Salimans, 2021 ).<br>무조건적 노이즈 제거 확산 모델을 보자 점수 추정기를 통해 매개변수화됨 그리고 조건부 모델<br>매개변수화를 통해. 이 두 모델은 단일 신경망을 통해 학습할 수 있습니다. 정확히 말하면 조건부 확산 모델  쌍을 이루는 데이터에 대해 학습됩니다.<br>여기서 조건화 정보는 모델이 무조건 이미지를 생성하는 방법을 알 수 있도록 주기적으로 무작위로 삭제됩니다.</p>
<p>암시적 분류기의 기울기는 조건부 및 무조건 점수 추정기로 표현될 수 있습니다. 분류자가 안내하는 수정된 점수에 연결되면 점수는 별도의 분류자에 대한 종속성을 포함하지 않습니다.</p>
<p>그들의 실험에서는 분류기가 없는 지침이 FID(합성 이미지와 생성된 이미지 구별)와 IS(품질과 다양성) 사이에서 좋은 균형을 이룰 수 있음을 보여주었습니다.</p>
<p>안내 확산 모델인 GLIDE( Nichol, Dhariwal &amp; Ramesh, et al. 2022 )는 안내 전략, CLIP 안내 및 분류자 없는 안내를 모두 탐색한 결과 후자가 더 선호되는 것으로 나타났습니다.<br>그들은 CLIP 지침이 더 잘 일치하는 이미지 생성을 최적화하는 대신 CLIP 모델에 대한 적대적인 예를 사용하여 모델을 활용하기 때문이라고 가정했습니다.</p>
<h2 id="Scale-up-Generation-Resolution-and-Quality"><a href="#Scale-up-Generation-Resolution-and-Quality" class="headerlink" title="Scale up Generation Resolution and Quality"></a>Scale up Generation Resolution and Quality</h2><p>고해상도에서 고품질 이미지를 생성하기 위해 Ho et al. (2021)은 증가하는 해상도에서 다중 확산 모델의 파이프라인을 사용할 것을 제안했습니다.<br>파이프라인 모델 간의 노이즈 조절 증대는 최종 이미지 품질에 매우 중요하며, 이는 조절 입력에 강력한 데이터 증대를 적용하는 것입니다.</p>
<p>각 초해상도 모델의 컨디셔닝 노이즈는 파이프라인 설정의 복합 오류를 줄이는 데 도움이 됩니다.<br>U-net은 고해상도 이미지 생성을 위한 확산 모델링에서 일반적인 모델 아키텍처 선택입니다.</p>
<p>![그림 11. 증가하는 해상도에서 다중 확산 모델의 계단식 파이프라인. (이미지 출처: Ho et al. 2021 ])](<a target="_blank" rel="external nofollow noopener noreferrer" href="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/cascaded-diffusion.png">https://lilianweng.github.io/posts/2021-07-11-diffusion-models/cascaded-diffusion.png</a>)</p>
<p>그들은 가장 효과적인 노이즈가 낮은 해상도에서 가우스 노이즈를 적용하고 고해상도에서 가우시안 블러를 적용하는 것임을 발견했습니다.<br>또한 그들은 훈련 과정에 약간의 수정이 필요한 두 가지 형태의 컨디셔닝 강화도 탐구했습니다. 컨디셔닝 노이즈는 훈련에만 적용되고 추론에는 적용되지 않습니다.</p>
<ul>
<li>Truncated Conditioning Augment는 단계 초기에 확산 프로세스를 중지합니다. 저해상도용.</li>
<li>잘리지 않은 조건화 확대는 0단계까지 전체 저해상도 역 프로세스를 실행하지만 다음과 같이 손상됩니다.</li>
<li>그런 다음 부패한 동물에게 먹이를 줍니다. 초해상도 모델에 들어갑니다.</li>
</ul>
<p>2단계 확산 모델 unCLIP ( Ramesh et al. 2022 )은 CLIP 텍스트 인코더를 많이 활용하여 고품질의 텍스트 안내 이미지를 생성합니다. 사전 훈련된 CLIP 모델이 주어지면<br>확산 모델에 대한 쌍을 이루는 훈련 데이터,, 어디  이미지이고 해당 캡션을 사용하면 CLIP 텍스트 및 이미지 임베딩을 계산할 수 있습니다.<br>그리고, 각각. unCLIP은 두 가지 모델을 병렬로 학습합니다.</p>
<ul>
<li>이전 모델 :CLIP 이미지 임베딩을 출력합니다. 주어진 텍스트</li>
<li>디코더 : 이미지를 생성합니다 주어진 CLIP 이미지 임베딩 선택적으로 원본 텍스트 . 이 두 모델은 조건부 생성을 가능하게 합니다.</li>
</ul>
<p>unCLIP은 2단계 이미지 생성 프로세스를 따릅니다.</p>
<ul>
<li>텍스트가 주어짐 CLIP 모델은 먼저 텍스트 임베딩을 생성하는 데 사용됩니다. CLIP 잠재 공간을 사용하면 텍스트를 통해 제로샷 이미지 조작이 가능해집니다.</li>
<li>확산 또는 자기회귀 사전 이 CLIP 텍스트 임베딩을 처리하여 이미지를 먼저 구성한 다음 확산 디코더를 구성합니다. 사전 조건에 따라 이미지를 생성합니다.<br>이 디코더는 이미지 입력에 따라 이미지 변형을 생성하여 스타일과 의미를 보존할 수도 있습니다.</li>
</ul>
<p>CLIP 모델 대신 Imagen ( Saharia et al. 2022 )은 사전 훈련된 대형 LM(즉, 고정된 T5-XXL 텍스트 인코더)을 사용하여 이미지 생성을 위한 텍스트를 인코딩합니다.<br>모델 크기가 클수록 이미지 품질이 향상되고 텍스트-이미지 정렬이 향상되는 일반적인 경향이 있습니다.<br>그들은 T5-XXL과 CLIP 텍스트 인코더가 MS-COCO에서 유사한 성능을 달성하지만 인간 평가에서는 DrawBench(11개 범주를 다루는 프롬프트 모음)에서 T5-XXL을 선호한다는 것을 발견했습니다.</p>
<p>분류자 없는 지침을 적용하면 증가합니다. 이미지-텍스트 정렬은 향상되지만 이미지 충실도는 저하될 수 있습니다. 그들은 훈련-테스트 불일치, 즉 훈련 데이터 때문에 발생한다는 것을 발견했습니다.<br>범위 내에서 유지됩니다., 테스트 데이터도 그래야 합니다. 두 가지 임계값 전략이 도입되었습니다</p>
<ul>
<li>정적 임계값: 클립 에 대한 예측</li>
<li>동적 임계값: 각 샘플링 단계에서 다음을 계산합니다. 특정 백분위수 절대 픽셀 값으로; 만약에 예측을 다음으로 자릅니다. 그리고 다음으로 나눈다</li>
</ul>
<p>Imagen은 U- net을 효율적으로 만들기 위해 U-net의 여러 디자인을 수정합니다 .</p>
<ul>
<li>낮은 해상도에 더 많은 잔여 잠금(residual locks)을 추가하여 모델 매개변수를 고해상도 블록에서 저해상도로 전환합니다.</li>
<li>건너뛰기 연결 크기 조정</li>
<li>순방향 전달 속도를 향상시키기 위해 다운샘플링(컨볼루션 전에 이동) 및 업샘플링 작업(컨볼루션 후 이동)의 순서를 반대로 바꿉니다.</li>
</ul>
<p>그들은 잡음 조절 증대, 동적 임계값 지정 및 효율적인 U-Net이 이미지 품질에 중요하지만 텍스트 인코더 크기 조정이 U-Net 크기보다 더 중요하다는 것을 발견했습니다.</p>
<h2 id="빠른-요약"><a href="#빠른-요약" class="headerlink" title="빠른 요약"></a>빠른 요약</h2><ul>
<li><p>장점 : 다루기 쉽고 유연성은 생성 모델링에서 두 가지 상충되는 목표입니다.<br>다루기 쉬운 모델은 분석적으로 평가하고 데이터를 저렴하게 맞출 수 있지만(예: Gaussian 또는 Laplace를 통해) 풍부한 데이터세트의 구조를 쉽게 설명할 수는 없습니다.<br>유연한 모델은 데이터의 임의 구조에 적합할 수 있지만 이러한 모델의 평가, 훈련 또는 샘플링에는 일반적으로 비용이 많이 듭니다. 확산 모델은 분석적으로 다루기 쉽고 유연합니다.</p>
</li>
<li><p>단점 : 확산 모델은 샘플을 생성하기 위해 긴 Markov 확산 단계 체인을 사용하므로 시간과 계산 측면에서 상당히 비쌀 수 있습니다.<br>프로세스를 훨씬 빠르게 만들기 위해 새로운 방법이 제안되었지만 샘플링은 여전히 GAN보다 느립니다.</p>
</li>
</ul>
<h1 id="참조"><a href="#참조" class="headerlink" title="참조"></a>참조</h1><hr>
<ul>
<li><a target="_blank" rel="external nofollow noopener noreferrer" href="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/">diffusion-models</a></li>
<li><a target="_blank" rel="external nofollow noopener noreferrer" href="https://ko.wikipedia.org/wiki/%EB%A7%88%EB%A5%B4%EC%BD%94%ED%94%84_%EC%97%B0%EC%87%84">마르코프 연쇄</a></li>
<li><a target="_blank" rel="external nofollow noopener noreferrer" href="https://www.puzzledata.com/blog190423/">마르코프 체인에 관하여</a></li>
<li><a target="_blank" rel="external nofollow noopener noreferrer" href="https://arxiv.org/abs/1503.03585">Deep Unsupervised Learning using Nonequilibrium Thermodynamics</a></li>
<li><a target="_blank" rel="external nofollow noopener noreferrer" href="https://arxiv.org/abs/1907.05600">Generative Modeling by Estimating Gradients of the Data Distribution</a></li>
<li><a target="_blank" rel="external nofollow noopener noreferrer" href="https://arxiv.org/abs/2006.11239">Denoising Diffusion Probabilistic Models</a></li>
<li><a target="_blank" rel="external nofollow noopener noreferrer" href="https://lilianweng.github.io/posts/2018-08-12-vae/#reparameterization-trick">Reparameterization Trick</a></li>
<li><a target="_blank" rel="external nofollow noopener noreferrer" href="https://www.stats.ox.ac.uk/~teh/research/compstats/WelTeh2011a.pdf">Bayesian Learning via Stochastic Gradient Langevin Dynamics</a></li>
<li><a target="_blank" rel="external nofollow noopener noreferrer" href="https://arxiv.org/abs/2105.05233">Diffusion Models Beat GANs on Image Synthesis</a></li>
<li><a target="_blank" rel="external nofollow noopener noreferrer" href="https://process-mining.tistory.com/182">Diffusion model 설명 (Diffusion model이란? Diffusion model 증명)</a></li>
<li><a target="_blank" rel="external nofollow noopener noreferrer" href="https://ffighting.net/deep-learning-paper-review/diffusion-model/diffusion-model-basic/">Diffusion Model 설명 – 기초부터 응용까지</a></li>
</ul>
</div></article><div class="post-meta__tag-list"><a class="post-meta__tags" href="../../../tags/Diffusion/">Diffusion</a></div><nav id="pagination"><div class="prev-post pull-left"><a href="../2023-10-31-Stable_Diffusion_link/"><i class="fa fa-chevron-left">  </i><span>Stable Diffusion 이해를 위한 자료 모음</span></a></div><div class="next-post pull-right"><a href="../2023-10-26-FirebaseError/"><span>FirebaseError Installations: Could not process request. Application offline.</span><i class="fa fa-chevron-right"></i></a></div></nav><div id="disqus_thread"></div><script>var unused = null;
var disqus_config = function () {
  this.page.url = 'https://sejoung.github.io/2023/10/2023-10-30-What_are_Diffusion_Models/';
  this.page.identifier = '2023/10/2023-10-30-What_are_Diffusion_Models/';
  this.page.title = 'Diffusion Models 이란';
}
var d = document, s = d.createElement('script');
s.src = "https://" + 'kimsejoung' +".disqus.com/embed.js";
s.setAttribute('data-timestamp', '' + +new Date());
(d.head || d.body).appendChild(s);</script><script id="dsq-count-scr" src="https://kimsejoung.disqus.com/count.js" async></script></div></div><footer class="footer-bg" style="background-image: url(https://upload.wikimedia.org/wikipedia/commons/thumb/0/09/Van_Gogh_-_Terrasse_des_Caf%C3%A9s_an_der_Place_du_Forum_in_Arles_am_Abend1.jpeg/1024px-Van_Gogh_-_Terrasse_des_Caf%C3%A9s_an_der_Place_du_Forum_in_Arles_am_Abend1.jpeg)"><div class="layout" id="footer"><div class="copyright">&copy;2017 - 2023 By sejoung</div><div class="framework-info"><span>Driven - </span><a target="_blank" rel="external nofollow noopener noreferrer" href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file-o"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="../../../js/third-party/anime.min.js"></script><script src="../../../js/third-party/jquery.min.js"></script><script src="../../../js/third-party/jquery.fancybox.min.js"></script><script src="../../../js/third-party/velocity.min.js"></script><script src="../../../js/third-party/velocity.ui.min.js"></script><script src="../../../js/utils.js?version=1.7.0"></script><script src="../../../js/fancybox.js?version=1.7.0"></script><script src="../../../js/sidebar.js?version=1.7.0"></script><script src="../../../js/copy.js?version=1.7.0"></script><script src="../../../js/fireworks.js?version=1.7.0"></script><script src="../../../js/transition.js?version=1.7.0"></script><script src="../../../js/scroll.js?version=1.7.0"></script><script src="../../../js/head.js?version=1.7.0"></script><script src="../../../js/search/local-search.js"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">Local search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>Powered by</span> <a target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>