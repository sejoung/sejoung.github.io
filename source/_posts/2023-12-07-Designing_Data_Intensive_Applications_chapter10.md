---
layout: post
title: "10장: 일괄 처리"
date: 2023-12-07 10:32 +0900
comments: true
tags : ["데이터 중심 애플리케이션 설계","Designing Data Intensive Applications"]
categories : ["books"]
sitemap :
  changefreq : daily
  priority : 1.0
---

# 파생 데이터
1부와 2부에서는 디스크에 저장된 데이터의 레이아웃부터 결함이 있는 상황에서의 
분산된 일관성의 한계까지 분산 데이터베이스로 가기위해 고려해야 할 모든 주요사항을 밑바닥부터 다뤘다


데이터를 저장하고 처리하는 시스템

* 레코드 시스템 : 데이터를 레코드 단위로 저장하고 읽는다
* 파생 데이터 시스템 : 데이터를 레코드 단위로 저장하지 않고, 다른 데이터를 기반으로 계산된 결과를 저장한다

파생 데이터는 기존 데이터를 복제한다는 의미에서 중복(redundant)이다.

## 10장: 일괄 처리

온라인 시스템은 응답시간 단축에 노력을 많이 기울인다

시스템 유형
* 서비스(온라인 시스템) : 사용자와 상호작용하는 시스템
* 일괄 처리(오프라인 시스템) : 사용자와 상호작용하지 않고, 대량의 데이터를 처리하는 시스템
* 스트림 처리(준 실시간 시스템) : 온라인과 오프라인 처리의 어딘가에 있기 때문에 준 실시간 처리라 불린다

일괄처리는 컴퓨터 연산에 있어서 매우 오래된 형태다
1890년 미국 인구조사에서 사용한 기계는 일괄 처리 시스템이다

### 유닉스 도구로 일괄 처리하기

아래는 엔진엑스 웹 서버의 엑세스 로그 파일이다

```text
222.333.444.555 - - [11/Mar/2016:10:28:49 -0500] "GET / HTTP/1.1" 301 184 "-" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/46.0.2490.86 Safari/537.36" "-"
222.333.444.555 - - [11/Mar/2016:10:28:49 -0500] "GET / HTTP/1.1" 301 184 "-" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/46.0.2490.86 Safari/537.36" "-"
222.333.444.555 - - [11/Mar/2016:10:28:49 -0500] "GET /test-endpoint HTTP/1.1" 301 184 "-" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/46.0.2490.86 Safari/537.36" "-"
222.333.444.555 - - [11/Mar/2016:10:28:50 -0500] "GET /test-endpoint HTTP/1.1" 301 184 "-" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/46.0.2490.86 Safari/537.36" "-"
```

```text
log_format main  '$remote_addr - $remote_user [$time_local] "$request" '
                 '$status $body_bytes_sent "$http_referer" '
                 '"$http_user_agent" "$http_x_forwarded_for"';

log_format notes '$remote_addr "$request" $status';
```

* 단순 로그 분석

```shell
cat access.log | awk '{print $7}' | sort | uniq -c | sort -r -n | head -n 5
```

* 연쇄 명령 대 맞춤형 프로그램

```ruby
counts = Hash.new(0)
File.foreach('access.log') do |line|
  url = line.split[6]
  counts[url] += 1
end

top5 = counts.map {|url, count| [count, url]}.sort.reverse[0..5]
top5.each {|count, url| puts "#{count} #{url}"}

```

위 루비 프로그램은 단순 로그 분석 명령보다 읽기 더 쉽다

* 정렬 대 인메모리 집계

데이터 양이 작으면 정렬이던 인메모리 집계던 문제가 없지만 데이터 양이 많아지면 문제가 발생한다

* 유닉스 철학

유닉스 파이프를 발명한 더그 맥일로이(Doug McIlroy)는 "다른 방법으로 데이터 처리가 필요할 때 정원 호스와 같이 여러 다른 프로그램을 연결하는 방법이 필요하다 이것은 I/O 방식이기도 하다"

1. 각 프로그램은 한가지 일만 하도록 작성하라. 새 작업이 필요하면 기존 프로그램을 고치지 말고 새로운 프로그램을 작성하라
2. 모든 프로그램의 출력은 아직 알려지지 않은 프로그램의 출력에 쓰일수 있다
3. 소프트웨어를 빠르게 써볼 수 있게 설계하고 구축하라
4. 프로그램 작업을 줄이려면 미숙한 도움보단 도구를 사용하라


동일 인터페이스 : 각 프로그램은 표준 입력을 읽고 표준 출력을 쓴다

로직과 연결의 분리 : 느슨한 결합, 지연 바인딩, 제어의 반전

투명성과 실험 : 유닉스 도구가 성공적인 이유 중 하나는 진행 사항을 파악하기가 쉽다

1. 입력 파일은 일반적으로 불변으로 처리된다
2. 어느 시점이든 파이프라인을 중단하고 출력을 파이프를 통해 less로 보내 원하는 형태의 출력이 나오는지 확인 할 수 있다
3. 특정 파이프라인 단계의 출력을 파일에 쓰고 그 파일을 다음 단계의 입력으로 사용할 수 있다

### 맵리듀스와 분산 파일 시스템

맵리듀스는 유닉스 도구와 비슷한 면이 있지만 수천 대의 장비로 분산해서 실행이 가능하다는 점에서 차이가 있다

맵리듀스는 분산파일시스템(HDFS)에서 데이터를 읽고 쓴다

HDFS는 비공유 원칙 NAS, SAN과 다르다

네임노드 : 파일 시스템의 메타데이터를 관리하는 서버

* 맵리듀스 작업 실행하기
  * 매퍼(mapper) : 입력 데이터를 읽어서 키-값 쌍을 생성한다
  * 리듀서(reducer) : 매퍼의 출력을 입력으로 받아서 집계를 수행한다
  * 맵리듀스의 분산실행 : 맵리듀스 적업은 여러 개의 맵 태스크와 리듀스 태스크로 나뉜다
  * 맵리듀스의 워크플로 : 맵리듀스 작업을 연결해 워크플로를 구성하는 방식은 꽤 일반적이다 
* 리듀스 사이드 조인과 그룹화
  * 일괄처리 관점에서 조인은 데이터셋 내 모든 연관 관계를 다룬다는 뜻
  * 사용자 활동 이벤트 분석 예제 : 사용자 활동 이벤트와 사용자 레코드를 조인해 사용자의 이름을 알아내는 것
  * 정렬 병합 조인 : 키로 맴퍼의 출력을 파티셔닝해 키-값 쌍으로 정렬하면 같은 사용자의 활동이벤트와 사용자 레코드는 리듀서의 입력으로 서로 인접해서 간다
  * 같은 곳으로 연관된 데이터 가져오기 : 데이터를 한곳에 모으면 조인이 쉽다
  * 그룹화 : 매퍼의 키-값 쌍을 생성할때 그룹화할 대상을 키로 하는 것이다
  * 쏠림 다루기 : 린치핀 객체, 핫 키, 핫스팟, 유명인사 문제
* 맵 사이드 조인
  * 리듀스 사이드 조인(reduce-side join) : 조인을 리듀서에서 수행하는 것
  * 맵 사이드 조인(map-side join) : 조인을 매퍼에서 수행하는 것
  * 브로드캐스트 해시 조인(broadcast hash join) : 작은 데이터셋을 모든 맵 태스크에 복제해 놓는다
  * 파티션 해시 조인(partitioned hash join) : 조인 키를 해시해서 파티션을 할당한다
  * 맵 사이드 병합 조인(map-side merge join) : 조인 키를 정렬해서 파티셔닝한다
  * 맵 사이드 조인을 사용하는 맵리듀스 워크플로 : Hcatalog, Hive 메타스토어를 사용하기도 한다
* 일괄 처리 워크플로의 출력
  * 검색 색인 구축 
  * 일괄 처리의 출력으로 키-값을 저장
  * 일괄 처리 출력에 관한 철학
    * 인적 내결함성(human fault tolerance)
    * 비가역성 최소화(minimizing irreversibility)
    * 입력은 불변
* 하둡과 분산 데이터베이스의 비교
  * 대규모 병렬 처리(massively parallel processing, MPP) 에 모두 구현되어 있다
  * MPP는 분석 질의를 병렬로 수행하는데 중점, 맵리듀스은 아무 프로그램이나 실행 운영체제랑 비슷
  * 저장소의 다양성
    * 데이터 레이크
    * 데이터 덤핑
  * 처리 모델의 다양성
    * MPP 데이터베이스는 일체식 구조
  * 빈번하게 발생하는 결함을 줄이는 설계
    * 맵리듀스는 태스크 종료가 자주 발생해도 견딜수 있는구조

### 맵리듀스를 넘어
맵리듀스는 단순함 사용하기 쉽지 않음

* 중간 상태 구체화
  * 모든 맵리듀스 작업은 다른 작업과 모두 독립적
  * 중간단계(Intermidiate state) : 맵리듀스 작업의 중간 단계의 출력
  * 중간단계를 파일로 기록하는 과정을 구체화(materialization)라고 한다
  * 데이터플로 엔진 : 스파크
  * 내결함성 : 스파크는 아직 유효한 데이터로 부터 계산을 다시 해서 복구한다
  * 구체화에 대한 논의
    * 데이터플로 엔진을 사용할 때 HDFS상에 구체화된 데이터 셋은 보통 작업의 입력과 최종 출력이다 
* 그래프와 반복 처리
  * 그래프 분석 알고리즘 : 페이지랭크
  * 이행적 패쇄(transitive closure) : 그래프의 각 노드가 다른 노드에 도달할 수 있는지 여부를 나타내는 그래프
  * 맵리듀스는 알고리즘의 반복적 속성을 고려하지 않음
  * 프리글 처리 모델 : 벌크 동기식 병렬(bulk synchronous parallel, BSP) 모델
  * 내결함성
    * 정확히 한번 수행
  * 병렬 실행
* 고수준 API와 언어
  * 하이브, 피그, 캐스캐이딩과 크런치 같은 고수준 언어나 API가 인기를 끌었다
  * 선언형 질의 언어로 변환
    * 임팔라
  * 다양한 분야를 지원하기 위한 전문화
    * 통계학과 수치 알고리즘
    * K 최근접 이웃 알고리즘(K-nearest neighbors, KNN)

### 정리

분산 일괄 처리 프레임워크가 해결해야할 두가지 문제

* 파티셔닝
* 내결함성

맵리듀스 조인 알고리즘

* 정렬 병합 조인
* 브로드캐스트 해시 조인
* 파티션 해시 조인

입력 데이터는 고정된 크기로 한정된다

스트림 처리는 입력이 한정되지 않는다

# 참조
-----

* [데이터 중심 애플리케이션 설계](https://wikibook.co.kr/data-intensive-applications-ebook/)
