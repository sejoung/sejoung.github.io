---
layout: post
title: "Video"
date: 2024-02-27 14:50 +0900
comments: true
tags: [ "Video" ]
categories: [ "Machine Learning" ]
sitemap:
changefreq: daily
priority: 1.0
---

# Video

* Optical Flow
  * pixel correspondences problem
  * using local window
  * Lucas-Kanade flow
  * FlowNet
    * CNN은 classification 분야에서 성공적이였으나, optical flow estimation에서는 적용된 사례가 없었음
    * End-to-end optical flow estimation CNN 구조와 학습방법 제안
    * Two Architectures (FlowNet-C, FlowNet-S)
  * FlowNet2
    * FlowNet을 faster and more accurate하게 하자
  * PWC-Net
    * Feature pyramid 와 warping, Correlation volme 을 활용한 optical flow estimation
    * Compare but effective CNN for optical flow
    * Pyramidal features의 사용
  * RAFT
    * All-pairs correlation volume 계산과, recurrent optical flow update
    * Multi-scale 3D correla)on volumes 을 만든다
    * Correlation volum을 전체 pixel에 대해 다 만듬

## Video Recognition with Sparse Points

* Video Recognition with Space-Time Interest Points
  * Space-time interest point (STIP)
    * STIP detector
    * Corner point in a spatio-temporal domain
    * Bag of visual words

## Video Recognition with Dense Trajectory Descriptors
* Dense Trajectory
  * Sparse -> Dense
  * Point -> Trajectory
  * Trajectory extraction

## Video Recognition with 3D CNN
* 3D Convolutional Neural Network
* C3D
  * A modern 3D CNN architecture 
  * VGGNet style network
* Visual Information Fusion Across Time
  * A video = A bag of short fixed-sized clips
* Time Information Fusion
  * early fusion
  * late fusion
  * slow fusion
* Explicit Motion Estimation and Utilization
  * Two-Stream Convolutional Network
    * spatial stream
      * ImageNet pretrained network, whose architecture is similar to ZFNet
    * temporal stream
      * Multi-task learning

## Video Understanding: Modern Approaches
* Video Representation Learning
* SlowFast Networks
  * Low frame rate branch와 high frame rate branch를 나누어서 action recognition
  * Time axis 에 대한 탐구
  * Slow pathway
  * Fast pathway
* MoViNet
  * Video를 좀 더 efficient하게 처리하기 위한 구조 탐구.
  * Video recognition에서의 efficientNet (ICML 2019) 와 같은 논문
* MaskFeat
  * ransformer 와 self-supervised representation learning 을 통한 video recognition 의 최신 기법
  * Action recognition 을 위한 representation learning을 할 때 꼭 temporal sequence 가 필요할까?
  * Pretext task로 masked input으로 HOG를 prediction 해보자
  * HOG 는 이미지의 pixel intensity 등의 정보를 없애서 motion 그 자체의 학습에 좀 더 집중하게 도움을 줌


* Self-supervised learning 기반의 representation learning 방식이 video recognition 쪽에서 현재 가장 잘 동작한다. (MaskFeat)
* Transformer architecture를 활용한 구조.
* Video 를 이해하는 데에 꼭 sequential 한 information 이 필요하지 않을 수 있다
* Single key frame 으로도 일부의 action 정보 학습/파악 가능

## Visual Object Tracking

* MDNet
  * 당시 CNN이 높은 성능을 내고 있으나, classification 과 tracking은 다른 문제여서 다르게 적용되어야 한다
  * Occlusion, deforma)on, mo)on blur 와 같은 문제를 처리해야함
  * 같은 targe이여도 동영상/배경에 따라 다르게 인식될 수 있음.
  * 여러 동영상으로부터 target의 domain-independent shared representation 학습
  * Domain-specific branch를 두어 서로 다른 도메인 학습
  * VOT를 위한 CNN 구조 제안; Domain-independent shared layers / Domain- specific branches.
  * Offline에서 pre-training되고, online으로 fine-tuning된다


# 참조
-----
